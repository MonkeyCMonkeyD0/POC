{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f18f1c8",
   "metadata": {},
   "source": [
    "# Setting up Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70d95cbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T04:27:25.184504Z",
     "start_time": "2023-04-10T04:27:25.180813Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "negative_mining = False\n",
    "soft_labels = False\n",
    "nb_augment = 0\n",
    "load_data_on_GPU = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e025a36c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T04:27:25.409952Z",
     "start_time": "2023-04-10T04:27:25.406136Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6c5dbd",
   "metadata": {},
   "source": [
    "### Selecting the correct device for training (CPU or GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab658774",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T04:27:28.102869Z",
     "start_time": "2023-04-10T04:27:26.358990Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9ab775",
   "metadata": {},
   "source": [
    "# Importing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7184cc2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T04:27:30.884893Z",
     "start_time": "2023-04-10T04:27:28.910880Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87c35a471ede42479c86db4750eec8d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset into RAM:   0%|          | 0/2744 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t- Loading done, RAM used: 1.49GiB / free: 59.08GiB / total: 62.73GiB\n",
      "\t- Got a total of 100 images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piai/Documents/POC-Project/src/dataset/POC_dataset.py:36: UserWarning: Need a strictly positive integer for n for data augmentation. Will skip augmentation.\n",
      "  warnings.warn(\"Need a strictly positive integer for n for data augmentation. Will skip augmentation.\")\n"
     ]
    }
   ],
   "source": [
    "from dataset import POCDataReader, data_augment_\n",
    "\n",
    "data_reader = POCDataReader(root_dir=\"../data/POC\", load_on_gpu=False, limit=100, verbose=True)\n",
    "\n",
    "train_data, val_data, test_data = data_reader.split([0.7, 0.1, 0.2])\n",
    "\n",
    "data_augment_(train_data, n=nb_augment, load_on_gpu=False, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b4ee494",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T04:27:43.957339Z",
     "start_time": "2023-04-10T04:27:43.194827Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.nn import Sequential\n",
    "from torchvision.transforms.functional import invert\n",
    "from torch.nn.functional import normalize\n",
    "\n",
    "from pipelines import InputPipeline, SumFilters\n",
    "from pipelines.filters import *\n",
    "\n",
    "\n",
    "sumFilter = SumFilters(FrangiFilter(), SatoFilter())\n",
    "crackBinFilter = Sequential(FrangiFilter(), CrackBinaryFilter())\n",
    "bgBinFilter = Sequential(FrangiFilter(), BGBinaryFilter(60.))\n",
    "skeletonFilter = SkeletonFilter(crackBinFilter)\n",
    "watershedFilter = WatershedFilter(background_filter=bgBinFilter, foreground_filter=skeletonFilter)\n",
    "\n",
    "inpip = InputPipeline(\n",
    "    transformer=None,\n",
    "    layer_transformer=[\n",
    "#         FrangiFilter(),\n",
    "#         SatoFilter(),\n",
    "#         sumFilter,\n",
    "#         crackBinFilter,\n",
    "#         bgBinFilter,\n",
    "        skeletonFilter,\n",
    "#         watershedFilter,\n",
    "    ]\n",
    ")\n",
    "\n",
    "inpip = inpip.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b402242d",
   "metadata": {},
   "source": [
    "### Creating Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "177e26e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T04:27:47.180903Z",
     "start_time": "2023-04-10T04:27:44.874041Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t- Loading done, GPU memory used: 0.08GiB / free: 6.99GiB / total: 7.78GiB\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.functional import normalize\n",
    "from torchvision.transforms import GaussianBlur\n",
    "\n",
    "from dataset import POCDataset\n",
    "\n",
    "train_dataset = POCDataset(\n",
    "    train_data,\n",
    "    transform=inpip,\n",
    "    target_transform= GaussianBlur(kernel_size=3, sigma=0.7) if soft_labels else None,\n",
    "    negative_mining=negative_mining,\n",
    "    load_on_gpu=load_data_on_GPU,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# train_dataset.precompute_transform(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "332cf718",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T04:27:51.401089Z",
     "start_time": "2023-04-10T04:27:51.396142Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "if load_data_on_GPU:\n",
    "    training_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        sampler=train_dataset.sampler,\n",
    "        shuffle= True if train_dataset.sampler is None else None,\n",
    "    )\n",
    "else:\n",
    "    training_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        sampler=train_dataset.sampler,\n",
    "        shuffle= True if train_dataset.sampler is None else None,\n",
    "        num_workers=8,\n",
    "        pin_memory=True,\n",
    "        pin_memory_device=device,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19a94f7",
   "metadata": {},
   "source": [
    "### Creating Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55249f0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T07:05:12.629602Z",
     "start_time": "2023-04-05T07:05:12.614719Z"
    }
   },
   "outputs": [],
   "source": [
    "from dataset import POCDataset\n",
    "\n",
    "val_dataset = POCDataset(val_data, transform=inpip, target_transform=None, negative_mining=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f992abc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T07:05:12.635554Z",
     "start_time": "2023-04-05T07:05:12.631585Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "if load_data_on_GPU:\n",
    "    validation_dataloader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size= 2 * batch_size,\n",
    "        shuffle=True,\n",
    "    )\n",
    "else:\n",
    "    validation_dataloader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size= 2 * batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=8,\n",
    "        pin_memory=True,\n",
    "        pin_memory_device=device,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7536e0f",
   "metadata": {},
   "source": [
    "### Creating Evaluation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4e2170",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T07:05:12.650916Z",
     "start_time": "2023-04-05T07:05:12.637690Z"
    }
   },
   "outputs": [],
   "source": [
    "from dataset import POCDataset\n",
    "\n",
    "test_dataset = POCDataset(test_data, transform=inpip, target_transform=None, negative_mining=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f44a8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T07:05:12.659077Z",
     "start_time": "2023-04-05T07:05:12.652514Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "if load_data_on_GPU:\n",
    "    evaluation_dataloader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=1,\n",
    "        shuffle=True,\n",
    "    )\n",
    "else:\n",
    "    evaluation_dataloader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=1,\n",
    "        shuffle=True,\n",
    "        num_workers=8,\n",
    "        pin_memory=True,\n",
    "        pin_memory_device=device,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed05c5a",
   "metadata": {},
   "source": [
    "### Testing the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b476340b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T07:05:15.318346Z",
     "start_time": "2023-04-05T07:05:12.661757Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from my_utils import show_img\n",
    "\n",
    "features, masks, files, indexes = next(iter(training_dataloader))\n",
    "print(features.size(), masks.size())\n",
    "\n",
    "show_img(features)\n",
    "show_img(masks)\n",
    "print(files, indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf6798c",
   "metadata": {},
   "source": [
    "### Testing Dataset for proportion between classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c611ea45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T07:05:15.842547Z",
     "start_time": "2023-04-05T07:05:15.319651Z"
    }
   },
   "outputs": [],
   "source": [
    "_,train_labels,_,_ = next(iter(training_dataloader))\n",
    "\n",
    "nb_pixel = torch.unique(train_labels, return_counts=True)[1]\n",
    "print(\"Proportion of class 1 in this batch: {}%\".format(nb_pixel[1] * 100 / (nb_pixel[0] + nb_pixel[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9df2f7",
   "metadata": {},
   "source": [
    "Result is usually around 1.1% which may be too low for cross_entropy_loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44c00dd",
   "metadata": {},
   "source": [
    "# Building the differents modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fce906",
   "metadata": {},
   "source": [
    "## Creating the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb606b98",
   "metadata": {},
   "source": [
    "#### Using Unet with bilinear upsampling and cropping to generate 2 classes (background and crack)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a00f39a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T04:28:42.535805Z",
     "start_time": "2023-04-10T04:28:42.465830Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'SubUNet' from 'models' (/home/piai/Documents/POC-Project/src/models/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UNet, DeepCrack, SubUNet\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# model = UNet(n_channels=1, n_classes=2, bilinear=True, crop=False).to(device)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# model = DeepCrack(n_channels=inpip.nb_channel, n_classes=2).to(device)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m SubUNet(n_channels\u001b[38;5;241m=\u001b[39minpip\u001b[38;5;241m.\u001b[39mnb_channel, n_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, deeply_supervised\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, avg_pooling\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'SubUNet' from 'models' (/home/piai/Documents/POC-Project/src/models/__init__.py)"
     ]
    }
   ],
   "source": [
    "from models import UNet, DeepCrack, SubUNet\n",
    "\n",
    "# model = UNet(n_channels=1, n_classes=2, bilinear=True, crop=False).to(device)\n",
    "# model = DeepCrack(n_channels=inpip.nb_channel, n_classes=2).to(device)\n",
    "model = SubUNet(n_channels=inpip.nb_channel, n_classes=2, deeply_supervised=False, avg_pooling=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f89ee3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T07:05:16.101074Z",
     "start_time": "2023-04-05T07:05:16.097479Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Total number of parameters: {0:,}\".format(sum(p.numel() for p in model.parameters() if p.requires_grad)))\n",
    "print(f\"Model structure: {model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3363b1",
   "metadata": {},
   "source": [
    "## Creating the loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ba3dec",
   "metadata": {},
   "source": [
    "#### Cross Entropy Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cee49e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "weight = torch.tensor([.9, .1])  # class weight : 98% for background and 2% for the cracks\n",
    "loss_fn = CrossEntropyLoss(weight=weight).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91245ab0",
   "metadata": {},
   "source": [
    "#### Dice Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc040e5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "from loss import DiceLoss\n",
    "\n",
    "loss_fn = DiceLoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d918b4ce",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "#### Focal Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790cf410",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from loss import FocalLoss\n",
    "\n",
    "weight = torch.tensor([.9, .1])  # class weight : 90% for background and 10% for the cracks\n",
    "loss_fn = FocalLoss(weight=weight, gamma=2).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f7f426",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "#### Jaccard Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d146ea6a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "from loss import JaccardLoss\n",
    "\n",
    "loss_fn = JaccardLoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8131df51",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "#### Tversky Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661aa4c9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from loss import TverskyLoss\n",
    "\n",
    "loss_fn = TverskyLoss(alpha=0.3, beta=0.7).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b05d77",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "#### Focal Tversky Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f717c2ba",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from loss import FocalTverskyLoss\n",
    "\n",
    "loss_fn = FocalTverskyLoss(alpha=0.3, beta=0.7, gamma=2).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fae902c",
   "metadata": {},
   "source": [
    "#### Combined (Focal + Tversky) Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6dc114",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from loss import CombinedLoss, TverskyLoss, FocalLoss\n",
    "\n",
    "weight = torch.tensor([.3, .7])\n",
    "\n",
    "loss_fn = CombinedLoss(\n",
    "    FocalLoss(weight=weight, gamma=2),\n",
    "    TverskyLoss(alpha=0.3, beta=0.7),\n",
    "    ratio=0.75).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7a0ca9",
   "metadata": {},
   "source": [
    "#### Bordered (Focal + Tversky) Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303d9ce6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T07:05:16.339264Z",
     "start_time": "2023-04-05T07:05:16.102392Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from loss import BorderedLoss, TverskyLoss, FocalLoss\n",
    "\n",
    "weight = torch.tensor([.3, .7])\n",
    "\n",
    "loss_fn = BorderedLoss(\n",
    "    border_loss=FocalLoss(weight=weight, gamma=2),\n",
    "    volume_loss=TverskyLoss(alpha=0.3, beta=0.7),\n",
    "    ratio=0.5).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e1d2d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T07:05:16.344444Z",
     "start_time": "2023-04-05T07:05:16.341529Z"
    }
   },
   "outputs": [],
   "source": [
    "from loss import MultiscaleLoss\n",
    "\n",
    "loss_fn = MultiscaleLoss(loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318ef5aa",
   "metadata": {},
   "source": [
    "## Creating the Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7c330c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T07:05:16.357875Z",
     "start_time": "2023-04-05T07:05:16.346201Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.99))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bcfca8",
   "metadata": {},
   "source": [
    "## Setting up the Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dcf657",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T07:05:16.368337Z",
     "start_time": "2023-04-05T07:05:16.359763Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "lr_scheduler = CosineAnnealingLR(optimizer, T_max=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e4dd19",
   "metadata": {},
   "source": [
    "## Creating the Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89695f2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T07:05:16.384046Z",
     "start_time": "2023-04-05T07:05:16.370153Z"
    }
   },
   "outputs": [],
   "source": [
    "from metrics import Metrics, EvaluationMetrics\n",
    "\n",
    "loss_names = loss_fn.get_names()\n",
    "pipe_names = inpip.get_names()\n",
    "\n",
    "train_metrics = Metrics(\n",
    "    buffer_size=len(training_dataloader),\n",
    "    mode=\"Training\",\n",
    "    hyperparam={\n",
    "        'Network': model.__class__,\n",
    "        'Optimizer': optimizer.__class__,\n",
    "        'Loss Function': loss_fn,\n",
    "        'Input Filter': pipe_names[1],\n",
    "        'Input Layer': pipe_names[2],\n",
    "        'Batch Size': batch_size,\n",
    "        'Learning Rate': learning_rate,\n",
    "        'Negative Mining': negative_mining,\n",
    "        'Smooth Labeling': soft_labels,\n",
    "    },\n",
    "    device=device)\n",
    "\n",
    "val_metrics = Metrics(\n",
    "    buffer_size=len(validation_dataloader),\n",
    "    mode=\"Validation\",\n",
    "    hyperparam={\n",
    "        'Network': model.__class__,\n",
    "        'Optimizer': optimizer.__class__,\n",
    "        'Loss Function': loss_fn,\n",
    "        'Input Filter': pipe_names[1],\n",
    "        'Input Layer': pipe_names[2],\n",
    "        'Batch Size': batch_size,\n",
    "        'Learning Rate': learning_rate,\n",
    "        'Negative Mining': negative_mining,\n",
    "        'Smooth Labeling': soft_labels,\n",
    "    },\n",
    "    device=device)\n",
    "\n",
    "test_metrics = EvaluationMetrics(\n",
    "    buffer_size=len(evaluation_dataloader),\n",
    "    hyperparam={\n",
    "        'Network': model.__class__,\n",
    "        'Optimizer': optimizer.__class__,\n",
    "        'Loss Function': loss_fn,\n",
    "        'Input Filter': pipe_names[1],\n",
    "        'Input Layer': pipe_names[2],\n",
    "        'Batch Size': batch_size,\n",
    "        'Learning Rate': learning_rate,\n",
    "        'Negative Mining': negative_mining,\n",
    "        'Smooth Labeling': soft_labels,\n",
    "    },\n",
    "    epochs=epochs,\n",
    "    device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4500456",
   "metadata": {},
   "source": [
    "# Training, testing and validating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5fee5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-05T07:07:36.719095Z",
     "start_time": "2023-04-05T07:05:16.385402Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from train_tqdm import training_loop, validation_loop, evaluation_loop\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    training_loop(epoch, training_dataloader, model, loss_fn, optimizer, lr_scheduler, train_metrics, device)\n",
    "    validation_loop(epoch, validation_dataloader, model, loss_fn, val_metrics, device)\n",
    "\n",
    "evaluation_loop(evaluation_dataloader, model, test_metrics, device)\n",
    "\n",
    "train_metrics.close_tensorboard()\n",
    "val_metrics.close_tensorboard()\n",
    "test_metrics.close_tensorboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443f6984",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f1c6f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "POC-env",
   "language": "python",
   "name": "poc-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
