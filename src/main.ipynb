{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f18f1c8",
   "metadata": {},
   "source": [
    "# Setting up Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d95cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "negative_mining = True\n",
    "soft_labels = True\n",
    "nb_augment = 0\n",
    "load_data_on_GPU = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e025a36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "learning_rate = 5e-4\n",
    "loss_fn = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6c5dbd",
   "metadata": {},
   "source": [
    "### Selecting the correct device for training (CPU or GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab658774",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9ab775",
   "metadata": {},
   "source": [
    "# Importing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7184cc2b",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from dataset import POCDataReader, data_augment_\n",
    "\n",
    "data_reader = POCDataReader(root_dir=\"../data/POC\", load_on_gpu=False, limit=50, verbose=True)\n",
    "\n",
    "train_data, val_data, test_data = data_reader.split([0.7, 0.1, 0.2])\n",
    "\n",
    "data_augment_(train_data, n=nb_augment, load_on_gpu=False, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffda110",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms.functional import invert\n",
    "from torch.nn.functional import normalize\n",
    "\n",
    "from pipelines import InputPipeline, SumFilters\n",
    "from pipelines.filters import LaplacianFilter, SobelFilter, DINOFilter, FrangiFilter, SatoFilter, WatershedFilter\n",
    "\n",
    "inpip = InputPipeline(\n",
    "    transformer=None, #[invert, normalize],\n",
    "#     layer_transformer=SumFilters(FrangiFilter(), SatoFilter())\n",
    "    layer_transformer=[\n",
    "#         LaplacianFilter(),\n",
    "#         SobelFilter(),\n",
    "#         DINOFilter(),\n",
    "        FrangiFilter(),\n",
    "        SatoFilter(),\n",
    "        SumFilters(FrangiFilter(), SatoFilter()),\n",
    "        WatershedFilter(FrangiFilter()),\n",
    "        WatershedFilter(SatoFilter()),\n",
    "        WatershedFilter(SumFilters(FrangiFilter(), SatoFilter())),\n",
    "#         WatershedFilter(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "inpip = inpip.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b402242d",
   "metadata": {},
   "source": [
    "### Creating Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177e26e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import normalize\n",
    "from torchvision.transforms import GaussianBlur\n",
    "\n",
    "from dataset import POCDataset\n",
    "\n",
    "train_dataset = POCDataset(\n",
    "    train_data,\n",
    "    transform=inpip,\n",
    "    target_transform= GaussianBlur(kernel_size=3, sigma=0.7) if soft_labels else None,\n",
    "    negative_mining=negative_mining,\n",
    "    load_on_gpu=load_data_on_GPU,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# train_dataset.precompute_transform(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332cf718",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "if load_data_on_GPU:\n",
    "    training_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        sampler=train_dataset.sampler,\n",
    "    )\n",
    "else:\n",
    "    training_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        sampler=train_dataset.sampler,\n",
    "        num_workers=8,\n",
    "        pin_memory=True,\n",
    "        pin_memory_device=device,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19a94f7",
   "metadata": {},
   "source": [
    "### Creating Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55249f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import normalize\n",
    "\n",
    "from dataset import POCDataset\n",
    "\n",
    "val_dataset = POCDataset(val_data, transform=normalize, target_transform=None, negative_mining=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f992abc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "if load_data_on_GPU:\n",
    "    validation_dataloader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size= 2 * batch_size,\n",
    "        shuffle=True,\n",
    "    )\n",
    "else:\n",
    "    validation_dataloader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size= 2 * batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=8,\n",
    "        pin_memory=True,\n",
    "        pin_memory_device=device,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7536e0f",
   "metadata": {},
   "source": [
    "### Creating Evaluation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4e2170",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import normalize\n",
    "\n",
    "from dataset import POCDataset\n",
    "\n",
    "test_dataset = POCDataset(test_data, transform=normalize, target_transform=None, negative_mining=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f44a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "if load_data_on_GPU:\n",
    "    evaluation_dataloader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=1,\n",
    "        shuffle=True,\n",
    "    )\n",
    "else:\n",
    "    evaluation_dataloader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=1,\n",
    "        shuffle=True,\n",
    "        num_workers=8,\n",
    "        pin_memory=True,\n",
    "        pin_memory_device=device,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed05c5a",
   "metadata": {},
   "source": [
    "### Testing the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b476340b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from my_utils import show_img\n",
    "\n",
    "features, masks, files, indexes = next(iter(training_dataloader))\n",
    "print(features.size(), masks.size())\n",
    "\n",
    "show_img(features)\n",
    "show_img(masks)\n",
    "print(files, indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf6798c",
   "metadata": {},
   "source": [
    "### Testing Dataset for proportion between classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c611ea45",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,train_labels,_,_ = next(iter(training_dataloader))\n",
    "\n",
    "nb_pixel = torch.unique(train_labels, return_counts=True)[1]\n",
    "print(\"Proportion of class 1 in this batch: {}%\".format(nb_pixel[1] * 100 / (nb_pixel[0] + nb_pixel[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9df2f7",
   "metadata": {},
   "source": [
    "Result is usually around 1.1% which may be too low for cross_entropy_loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44c00dd",
   "metadata": {},
   "source": [
    "# Building the differents modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fce906",
   "metadata": {},
   "source": [
    "## Creating the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb606b98",
   "metadata": {},
   "source": [
    "#### Using Unet with bilinear upsampling and cropping to generate 2 classes (background and crack)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a00f39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import UNet\n",
    "\n",
    "model = UNet(n_channels=1, n_classes=2, bilinear=True, crop=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f89ee3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Total number of parameters: {0:,}\".format(sum(p.numel() for p in model.parameters() if p.requires_grad)))\n",
    "print(f\"Model structure: {model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3363b1",
   "metadata": {},
   "source": [
    "## Creating the loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ba3dec",
   "metadata": {},
   "source": [
    "#### Cross Entropy Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cee49e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "weight = torch.tensor([.9, .1])  # class weight : 98% for background and 2% for the cracks\n",
    "loss_fn = CrossEntropyLoss(weight=weight).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91245ab0",
   "metadata": {},
   "source": [
    "#### Dice Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc040e5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "from loss import DiceLoss\n",
    "\n",
    "loss_fn = DiceLoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d918b4ce",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "#### Focal Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790cf410",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from loss import FocalLoss\n",
    "\n",
    "weight = torch.tensor([.9, .1])  # class weight : 90% for background and 10% for the cracks\n",
    "loss_fn = FocalLoss(weight=weight, gamma=2).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f7f426",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "#### Jaccard Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d146ea6a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "from loss import JaccardLoss\n",
    "\n",
    "loss_fn = JaccardLoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8131df51",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "#### Tversky Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661aa4c9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from loss import TverskyLoss\n",
    "\n",
    "loss_fn = TverskyLoss(alpha=0.3, beta=0.7).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b05d77",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "#### Focal Tversky Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f717c2ba",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from loss import FocalTverskyLoss\n",
    "\n",
    "loss_fn = FocalTverskyLoss(alpha=0.3, beta=0.7, gamma=2).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fae902c",
   "metadata": {},
   "source": [
    "#### Combined (Focal + Tversky) Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6dc114",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from loss import CombinedLoss, TverskyLoss, FocalLoss\n",
    "\n",
    "weight = torch.tensor([.3, .7])\n",
    "\n",
    "loss_fn = CombinedLoss(\n",
    "    FocalLoss(weight=weight, gamma=2),\n",
    "    TverskyLoss(alpha=0.3, beta=0.7),\n",
    "    ratio=0.75).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7a0ca9",
   "metadata": {},
   "source": [
    "#### Bordered (Focal + Tversky) Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303d9ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from loss import BorderedLoss, TverskyLoss, FocalLoss\n",
    "\n",
    "weight = torch.tensor([.3, .7])\n",
    "\n",
    "loss_fn = BorderedLoss(\n",
    "    border_loss=FocalLoss(weight=weight, gamma=2),\n",
    "    volume_loss=TverskyLoss(alpha=0.3, beta=0.7),\n",
    "    ratio=0.5).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318ef5aa",
   "metadata": {},
   "source": [
    "## Creating the Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7c330c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.99))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bcfca8",
   "metadata": {},
   "source": [
    "## Setting up the Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dcf657",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "lr_scheduler = CosineAnnealingLR(optimizer, T_max=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e4dd19",
   "metadata": {},
   "source": [
    "## Creating the Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89695f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import Metrics, EvaluationMetrics\n",
    "\n",
    "loss_names = repr(loss_fn)\n",
    "pipe_names = repr(inpip)\n",
    "\n",
    "train_metrics = Metrics(\n",
    "    buffer_size=len(training_dataloader),\n",
    "    mode=\"Training\",\n",
    "    hyperparam={\n",
    "        'Network': model.__class__.__name__,\n",
    "        'Optimizer': optimizer.__class__.__name__,\n",
    "        'Combine Loss': loss_names[0],\n",
    "        'Pixel Loss': loss_names[1],\n",
    "        'Volume Loss': loss_names[2],\n",
    "        'Input Filter': pipe_names[1],\n",
    "        'Input Layer': pipe_names[2],\n",
    "        'Batch Size': batch_size,\n",
    "        'Learning Rate': learning_rate,\n",
    "        'Negative Mining': negative_mining,\n",
    "        'Smooth Labeling': soft_labels,\n",
    "    },\n",
    "    device=device)\n",
    "\n",
    "val_metrics = Metrics(\n",
    "    buffer_size=len(validation_dataloader),\n",
    "    mode=\"Validation\",\n",
    "    hyperparam={\n",
    "        'Network': model.__class__.__name__,\n",
    "        'Optimizer': optimizer.__class__.__name__,\n",
    "        'Combine Loss': loss_names[0],\n",
    "        'Pixel Loss': loss_names[1],\n",
    "        'Volume Loss': loss_names[2],\n",
    "        'Input Filter': None,\n",
    "        'Input Layer': \"LaplacianFilter\",\n",
    "        'Batch Size': batch_size,\n",
    "        'Learning Rate': learning_rate,\n",
    "        'Negative Mining': negative_mining,\n",
    "        'Smooth Labeling': soft_labels,\n",
    "    },\n",
    "    device=device)\n",
    "\n",
    "test_metrics = EvaluationMetrics(\n",
    "    buffer_size=len(evaluation_dataloader),\n",
    "    hyperparam={\n",
    "        'Network': model.__class__.__name__,\n",
    "        'Optimizer': optimizer.__class__.__name__,\n",
    "        'Combine Loss': loss_names[0],\n",
    "        'Pixel Loss': loss_names[1],\n",
    "        'Volume Loss': loss_names[2],\n",
    "        'Input Filter': None,\n",
    "        'Input Layer': \"LaplacianFilter\",\n",
    "        'Batch Size': batch_size,\n",
    "        'Learning Rate': learning_rate,\n",
    "        'Negative Mining': negative_mining,\n",
    "        'Smooth Labeling': soft_labels,\n",
    "    },\n",
    "    epochs=epochs,\n",
    "    device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4500456",
   "metadata": {},
   "source": [
    "# Training, testing and validating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5fee5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from train_tqdm import training_loop, validation_loop, evaluation_loop\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    training_loop(epoch, training_dataloader, model, loss_fn, optimizer, lr_scheduler, train_metrics, device)\n",
    "    validation_loop(epoch, validation_dataloader, model, loss_fn, val_metrics, device)\n",
    "\n",
    "evaluation_loop(evaluation_dataloader, model, test_metrics, device)\n",
    "\n",
    "train_metrics.close_tensorboard()\n",
    "val_metrics.close_tensorboard()\n",
    "test_metrics.close_tensorboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443f6984",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c4f6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms.functional import rgb_to_grayscale\n",
    "\n",
    "img = rgb_to_grayscale(features)[0,0].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c941c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_img = frangi(img)\n",
    "f_marker = np.full_like(f_img, 0)\n",
    "threshold_up = np.percentile(f_img, q=99.3)\n",
    "threshold_down = np.percentile(f_img, q=98)\n",
    "f_marker[f_img >= threshold_up] = 2\n",
    "f_marker[f_img <= threshold_down] = 1\n",
    "\n",
    "result = torch.from_numpy(f_marker).expand(1, 1, -1, -1)\n",
    "show_img(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5ab179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.filters import frangi\n",
    "\n",
    "#watershed(image, markers=None, connectivity=1, offset=None, mask=None, compactness=0, watershed_line=False)\n",
    "\n",
    "w_img = watershed(img, markers=f_marker)\n",
    "result = torch.from_numpy(w_img).expand(1, 1, -1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3648b4b4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_img(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c636ac9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0f76f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfabde6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed94e789",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8773bcf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d27b1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c787e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926a14fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "POC-env",
   "language": "python",
   "name": "poc-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
