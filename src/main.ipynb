{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f18f1c8",
   "metadata": {},
   "source": [
    "# Setting up Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70d95cbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T02:28:19.852995Z",
     "start_time": "2023-05-08T02:28:19.848500Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "negative_mining = False\n",
    "soft_labels = False\n",
    "nb_augment = 1\n",
    "load_data_on_GPU = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e025a36c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T02:28:19.867763Z",
     "start_time": "2023-05-08T02:28:19.855803Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6c5dbd",
   "metadata": {},
   "source": [
    "### Selecting the correct device for training (CPU or GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab658774",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T02:28:20.918418Z",
     "start_time": "2023-05-08T02:28:19.885832Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9ab775",
   "metadata": {},
   "source": [
    "# Importing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7184cc2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T02:29:07.425162Z",
     "start_time": "2023-05-08T02:28:20.920996Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "293c5df0163244f3bf1ecbb5c4d9ad0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset into RAM:   0%|          | 0/2744 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t- Loading done, RAM used: 12.04GiB / free: 9.82GiB / total: 62.73GiB\n",
      "\t- Got a total of 2744 images.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b9b8ea0ecd6402cb970803de6838a29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Expending the dataset 1 more times:   0%|          | 0/1920 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t- Augmentation done, RAM used: 14.76GiB / free: 7.10GiB / total: 62.73GiB\n",
      "\t- Got 1920 new images and a total of 3840 images.\n"
     ]
    }
   ],
   "source": [
    "from dataset import POCDataReader, data_augment_\n",
    "\n",
    "data_reader = POCDataReader(root_dir=\"../data/POC\", load_on_gpu=False, limit=None, verbose=True)\n",
    "\n",
    "train_data, val_data, test_data = data_reader.split([0.7, 0.1, 0.2])\n",
    "\n",
    "data_augment_(train_data, n=nb_augment, load_on_gpu=False, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b4ee494",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T02:29:09.196075Z",
     "start_time": "2023-05-08T02:29:07.426938Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.nn import Sequential\n",
    "from torchvision.transforms.functional import invert\n",
    "from torch.nn.functional import normalize\n",
    "\n",
    "from pipelines import InputPipeline, SumFilters\n",
    "from pipelines.filters import *\n",
    "\n",
    "\n",
    "sumFilter = SumFilters(FrangiFilter(), SatoFilter())\n",
    "crackBinFilter = Sequential(FrangiFilter(), CrackBinaryFilter(0.75))\n",
    "bgBinFilter = Sequential(FrangiFilter(), BGBinaryFilter(60.))\n",
    "skeletonFilter = SkeletonFilter(crackBinFilter)\n",
    "watershedFilter = WatershedFilter(background_filter=bgBinFilter, foreground_filter=skeletonFilter)\n",
    "\n",
    "inpip = InputPipeline(\n",
    "    transformer=None,\n",
    "    layer_transformer=[\n",
    "        LaplacianFilter(),\n",
    "#         FrangiFilter(),\n",
    "#         SatoFilter(),\n",
    "#         sumFilter,\n",
    "#         crackBinFilter,\n",
    "#         bgBinFilter,\n",
    "#         skeletonFilter,\n",
    "#         watershedFilter,\n",
    "   ]\n",
    ")\n",
    "\n",
    "inpip = inpip.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b402242d",
   "metadata": {},
   "source": [
    "### Creating Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "177e26e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T02:29:10.008813Z",
     "start_time": "2023-05-08T02:29:09.200411Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t- Loading done, RAM used: 19.68GiB / free: 2.17GiB / total: 62.73GiB\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.functional import normalize\n",
    "from torchvision.transforms import CenterCrop, Resize, GaussianBlur\n",
    "\n",
    "from dataset import POCDataset\n",
    "\n",
    "train_dataset = POCDataset(\n",
    "    train_data,\n",
    "    transform=inpip,\n",
    "    target_transform=Sequential(CenterCrop(size=(480, 480)), Resize(size=(384, 384))),\n",
    "    negative_mining=negative_mining,\n",
    "    load_on_gpu=load_data_on_GPU,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# train_dataset.precompute_transform(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "332cf718",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T02:29:10.013872Z",
     "start_time": "2023-05-08T02:29:10.010388Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "if load_data_on_GPU:\n",
    "    training_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        sampler=train_dataset.sampler,\n",
    "        shuffle= True if train_dataset.sampler is None else None,\n",
    "    )\n",
    "else:\n",
    "    training_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        sampler=train_dataset.sampler,\n",
    "        shuffle= True if train_dataset.sampler is None else None,\n",
    "        num_workers=8,\n",
    "        pin_memory=True,\n",
    "        pin_memory_device=device,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19a94f7",
   "metadata": {},
   "source": [
    "### Creating Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55249f0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T02:29:10.079736Z",
     "start_time": "2023-05-08T02:29:10.015441Z"
    }
   },
   "outputs": [],
   "source": [
    "from dataset import POCDataset\n",
    "\n",
    "val_dataset = POCDataset(val_data, transform=inpip, target_transform=Sequential(CenterCrop(size=(480, 480)), Resize(size=(384, 384))), negative_mining=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f992abc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T02:29:10.084780Z",
     "start_time": "2023-05-08T02:29:10.081444Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "if load_data_on_GPU:\n",
    "    validation_dataloader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size= 2 * batch_size,\n",
    "        shuffle=True,\n",
    "    )\n",
    "else:\n",
    "    validation_dataloader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size= 2 * batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=8,\n",
    "        pin_memory=True,\n",
    "        pin_memory_device=device,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7536e0f",
   "metadata": {},
   "source": [
    "### Creating Evaluation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a4e2170",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T02:29:10.220443Z",
     "start_time": "2023-05-08T02:29:10.086064Z"
    }
   },
   "outputs": [],
   "source": [
    "from dataset import POCDataset\n",
    "\n",
    "test_dataset = POCDataset(test_data, transform=inpip, target_transform=Sequential(CenterCrop(size=(480, 480)), Resize(size=(384, 384))), negative_mining=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7f44a8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T02:29:10.224483Z",
     "start_time": "2023-05-08T02:29:10.221735Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "if load_data_on_GPU:\n",
    "    evaluation_dataloader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=1,\n",
    "        shuffle=True,\n",
    "    )\n",
    "else:\n",
    "    evaluation_dataloader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=1,\n",
    "        shuffle=True,\n",
    "        num_workers=8,\n",
    "        pin_memory=True,\n",
    "        pin_memory_device=device,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed05c5a",
   "metadata": {},
   "source": [
    "### Testing the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b476340b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T02:29:11.927539Z",
     "start_time": "2023-05-08T02:29:10.226778Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/tim/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/tim/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/tim/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/tim/Documents/POC-Project/src/dataset/POC_dataset.py\", line 126, in __getitem__\n    img = self.transform(img)\n  File \"/home/tim/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/tim/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n    return func(*args, **kwargs)\n  File \"/home/tim/Documents/POC-Project/src/pipelines/input_pipeline.py\", line 31, in forward\n    new_channel = transform(img[0:n_channel])\n  File \"/home/tim/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/tim/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n    return func(*args, **kwargs)\n  File \"/home/tim/Documents/POC-Project/src/pipelines/filters/laplacian.py\", line 26, in forward\n    img = self.laplacian_filter(img)\n  File \"/home/tim/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/tim/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 463, in forward\n    return self._conv_forward(input, self.weight, self.bias)\n  File \"/home/tim/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 459, in _conv_forward\n    return F.conv2d(input, weight, bias, self.stride,\nRuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmy_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_img\n\u001b[0;32m----> 3\u001b[0m features, masks, files, indexes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtraining_dataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(features\u001b[38;5;241m.\u001b[39msize(), masks\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m      6\u001b[0m show_img(features)\n",
      "File \u001b[0;32m~/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1333\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1333\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1359\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1357\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1359\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/_utils.py:543\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    540\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m--> 543\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/tim/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/tim/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/tim/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/tim/Documents/POC-Project/src/dataset/POC_dataset.py\", line 126, in __getitem__\n    img = self.transform(img)\n  File \"/home/tim/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/tim/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n    return func(*args, **kwargs)\n  File \"/home/tim/Documents/POC-Project/src/pipelines/input_pipeline.py\", line 31, in forward\n    new_channel = transform(img[0:n_channel])\n  File \"/home/tim/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/tim/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n    return func(*args, **kwargs)\n  File \"/home/tim/Documents/POC-Project/src/pipelines/filters/laplacian.py\", line 26, in forward\n    img = self.laplacian_filter(img)\n  File \"/home/tim/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/tim/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 463, in forward\n    return self._conv_forward(input, self.weight, self.bias)\n  File \"/home/tim/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 459, in _conv_forward\n    return F.conv2d(input, weight, bias, self.stride,\nRuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor\n"
     ]
    }
   ],
   "source": [
    "from my_utils import show_img\n",
    "\n",
    "features, masks, files, indexes = next(iter(training_dataloader))\n",
    "print(features.size(), masks.size())\n",
    "\n",
    "show_img(features)\n",
    "show_img(masks)\n",
    "print(files, indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf6798c",
   "metadata": {},
   "source": [
    "### Testing Dataset for proportion between classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c611ea45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T02:29:11.929877Z",
     "start_time": "2023-05-08T02:29:11.929865Z"
    }
   },
   "outputs": [],
   "source": [
    "_,train_labels,_,_ = next(iter(training_dataloader))\n",
    "\n",
    "nb_pixel = torch.unique(train_labels, return_counts=True)[1]\n",
    "print(\"Proportion of class 1 in this batch: {}%\".format(nb_pixel[1] * 100 / (nb_pixel[0] + nb_pixel[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9df2f7",
   "metadata": {},
   "source": [
    "Result is usually around 1.1% which may be too low for cross_entropy_loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44c00dd",
   "metadata": {},
   "source": [
    "# Building the differents modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fce906",
   "metadata": {},
   "source": [
    "## Creating the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb606b98",
   "metadata": {},
   "source": [
    "#### Using Unet with bilinear upsampling and cropping to generate 2 classes (background and crack)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a00f39a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T02:29:11.931370Z",
     "start_time": "2023-05-08T02:29:11.931358Z"
    }
   },
   "outputs": [],
   "source": [
    "from models import UNet, DeepCrack, SubUNet, DenSubUNet\n",
    "\n",
    "# model = UNet(n_channels=1, n_classes=2, bilinear=True, crop=False).to(device)\n",
    "# model = DeepCrack(n_channels=inpip.nb_channel, n_classes=2).to(device)\n",
    "# model = SubUNet(n_channels=inpip.nb_channel, n_classes=2).to(device)\n",
    "model = DenSubUNet(n_channels=inpip.nb_channel, n_classes=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f89ee3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T02:29:11.932495Z",
     "start_time": "2023-05-08T02:29:11.932484Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Total number of parameters: {0:,}\".format(sum(p.numel() for p in model.parameters() if p.requires_grad)))\n",
    "print(f\"Model structure: {model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3363b1",
   "metadata": {},
   "source": [
    "## Creating the loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ba3dec",
   "metadata": {},
   "source": [
    "#### Cross Entropy Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cee49e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "weight = torch.tensor([.9, .1])  # class weight : 98% for background and 2% for the cracks\n",
    "loss_fn = CrossEntropyLoss(weight=weight).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91245ab0",
   "metadata": {},
   "source": [
    "#### Dice Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc040e5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "from loss import DiceLoss\n",
    "\n",
    "loss_fn = DiceLoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d918b4ce",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "#### Focal Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790cf410",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from loss import FocalLoss\n",
    "\n",
    "weight = torch.tensor([.9, .1])  # class weight : 90% for background and 10% for the cracks\n",
    "loss_fn = FocalLoss(weight=weight, gamma=2).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f7f426",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "#### Jaccard Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d146ea6a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "from loss import JaccardLoss\n",
    "\n",
    "loss_fn = JaccardLoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8131df51",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "#### Tversky Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661aa4c9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from loss import TverskyLoss\n",
    "\n",
    "loss_fn = TverskyLoss(alpha=0.3, beta=0.7).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b05d77",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "#### Focal Tversky Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f717c2ba",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from loss import FocalTverskyLoss\n",
    "\n",
    "loss_fn = FocalTverskyLoss(alpha=0.3, beta=0.7, gamma=2).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fae902c",
   "metadata": {},
   "source": [
    "#### Combined (Focal + Tversky) Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6dc114",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from loss import CombinedLoss, TverskyLoss, FocalLoss\n",
    "\n",
    "weight = torch.tensor([.3, .7])\n",
    "\n",
    "loss_fn = CombinedLoss(\n",
    "    FocalLoss(weight=weight, gamma=2),\n",
    "    TverskyLoss(alpha=0.3, beta=0.7),\n",
    "    ratio=0.75).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7a0ca9",
   "metadata": {},
   "source": [
    "#### Bordered (Focal + Tversky) Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303d9ce6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T02:29:11.933273Z",
     "start_time": "2023-05-08T02:29:11.933262Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from loss import BorderedLoss, JaccardLoss, FocalLoss\n",
    "\n",
    "weight = torch.tensor([.5, .5])\n",
    "\n",
    "loss_fn = BorderedLoss(\n",
    "    border_loss=FocalLoss(weight=weight, gamma=2),\n",
    "    volume_loss=JaccardLoss(),\n",
    "    ratio=0.7).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e1d2d4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "from loss import MultiscaleLoss\n",
    "\n",
    "loss_fn = MultiscaleLoss(loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318ef5aa",
   "metadata": {},
   "source": [
    "## Creating the Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7c330c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T02:29:11.934153Z",
     "start_time": "2023-05-08T02:29:11.934142Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.99))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bcfca8",
   "metadata": {},
   "source": [
    "## Setting up the Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dcf657",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T02:29:11.934976Z",
     "start_time": "2023-05-08T02:29:11.934965Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "lr_scheduler = CosineAnnealingLR(optimizer, T_max=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e4dd19",
   "metadata": {},
   "source": [
    "## Creating the Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89695f2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T02:29:11.936694Z",
     "start_time": "2023-05-08T02:29:11.936682Z"
    }
   },
   "outputs": [],
   "source": [
    "from metrics import Metrics, EvaluationMetrics\n",
    "\n",
    "\n",
    "train_metrics = Metrics(\n",
    "    buffer_size=len(training_dataloader),\n",
    "    mode=\"Training\",\n",
    "    hyperparam={\n",
    "        \"Network\": model.__class__,\n",
    "        \"Optimizer\": optimizer.__class__,\n",
    "\n",
    "        \"Learning Rate\": learning_rate,\n",
    "        \"Batch Size\": batch_size,\n",
    "\n",
    "        \"Loss Combiner\": BorderedLoss,\n",
    "        \"Loss Combiner_ratio\": 0.7,\n",
    "        \"Loss Volume\": JaccardLoss,\n",
    "        \"Loss Pixel\": FocalLoss,\n",
    "        \"Loss Pixel_gamma\": 2,\n",
    "        \"Loss Pixel_weight\": .5,\n",
    "\n",
    "        \"Negative Mining\": negative_mining,\n",
    "        \"Smooth Labeling\": soft_labels,\n",
    "\n",
    "        \"Pipe Filter\": normalize,\n",
    "        \"Pipe Layer\": LaplacianFilter,\n",
    "        \"Pipe Layer_threshold\": 0.75,\n",
    "    },\n",
    "    device=device)\n",
    "\n",
    "val_metrics = Metrics(\n",
    "    buffer_size=len(validation_dataloader),\n",
    "    mode=\"Validation\",\n",
    "    hyperparam={\n",
    "        \"Network\": model.__class__,\n",
    "        \"Optimizer\": optimizer.__class__,\n",
    "\n",
    "        \"Learning Rate\": learning_rate,\n",
    "        \"Batch Size\": batch_size,\n",
    "\n",
    "        \"Loss Combiner\": BorderedLoss,\n",
    "        \"Loss Combiner_ratio\": 0.7,\n",
    "        \"Loss Volume\": JaccardLoss,\n",
    "        \"Loss Pixel\": FocalLoss,\n",
    "        \"Loss Pixel_gamma\": 2,\n",
    "        \"Loss Pixel_weight\": .5,\n",
    "\n",
    "        \"Negative Mining\": negative_mining,\n",
    "        \"Smooth Labeling\": soft_labels,\n",
    "\n",
    "        \"Pipe Filter\": normalize,\n",
    "        \"Pipe Layer\": LaplacianFilter,\n",
    "        \"Pipe Layer_threshold\": 0.75,\n",
    "    },\n",
    "    device=device)\n",
    "\n",
    "test_metrics = EvaluationMetrics(\n",
    "    buffer_size=len(evaluation_dataloader),\n",
    "    hyperparam={\n",
    "        \"Network\": model.__class__,\n",
    "        \"Optimizer\": optimizer.__class__,\n",
    "\n",
    "        \"Learning Rate\": learning_rate,\n",
    "        \"Batch Size\": batch_size,\n",
    "\n",
    "        \"Loss Combiner\": BorderedLoss,\n",
    "        \"Loss Combiner_ratio\": 0.7,\n",
    "        \"Loss Volume\": JaccardLoss,\n",
    "        \"Loss Pixel\": FocalLoss,\n",
    "        \"Loss Pixel_gamma\": 2,\n",
    "        \"Loss Pixel_weight\": .5,\n",
    "\n",
    "        \"Negative Mining\": negative_mining,\n",
    "        \"Smooth Labeling\": soft_labels,\n",
    "\n",
    "        \"Pipe Filter\": normalize,\n",
    "        \"Pipe Layer\": LaplacianFilter,\n",
    "        \"Pipe Layer_threshold\": 0.75,\n",
    "    },\n",
    "    epochs=epochs,\n",
    "    device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4500456",
   "metadata": {},
   "source": [
    "# Training, testing and validating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5fee5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T02:29:11.937677Z",
     "start_time": "2023-05-08T02:29:11.937665Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from torch import autograd\n",
    "\n",
    "from train_tqdm import training_loop, validation_loop, evaluation_loop\n",
    "\n",
    "autograd.set_detect_anomaly(True)\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    training_loop(epoch, training_dataloader, model, loss_fn, optimizer, lr_scheduler, train_metrics, device)\n",
    "    validation_loop(epoch, validation_dataloader, model, loss_fn, val_metrics, device)\n",
    "\n",
    "evaluation_loop(evaluation_dataloader, model, test_metrics, device)\n",
    "\n",
    "train_metrics.close_tensorboard()\n",
    "val_metrics.close_tensorboard()\n",
    "test_metrics.close_tensorboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443f6984",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdff66c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e45d13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T07:26:13.304924Z",
     "start_time": "2023-04-27T07:26:10.608209Z"
    }
   },
   "outputs": [],
   "source": [
    "from my_utils import show_img\n",
    "\n",
    "features, masks, files, _ = next(iter(training_dataloader))\n",
    "print(features.size(), masks.size())\n",
    "\n",
    "show_img(features)\n",
    "show_img(masks)\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296dd457",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T07:27:45.197581Z",
     "start_time": "2023-04-27T07:27:45.186085Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision.transforms.functional import rgb_to_grayscale\n",
    "\n",
    "image1 = features[1,0:3]   # (3, 480, 640)\n",
    "image1 = rgb_to_grayscale(image1)   #(1, 480, 640)\n",
    "skel1 = features[1,3]   #(480, 640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5d798b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T07:27:45.364652Z",
     "start_time": "2023-04-27T07:27:45.358244Z"
    }
   },
   "outputs": [],
   "source": [
    "numpy_img = image1.squeeze(0).cpu().numpy()\n",
    "numpy_skel = skel1.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839d2a70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T07:27:45.534625Z",
     "start_time": "2023-04-27T07:27:45.524282Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "pts_list = np.nonzero(numpy_skel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834fce8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T07:27:45.836428Z",
     "start_time": "2023-04-27T07:27:45.676126Z"
    }
   },
   "outputs": [],
   "source": [
    "from skimage.segmentation import flood\n",
    "\n",
    "flood_mask = np.zeros_like(numpy_img, dtype=bool)\n",
    "for x,y in zip(pts_list[0], pts_list[1]):\n",
    "    flood_mask = flood_mask | flood(image=numpy_img, seed_point=(x,y), connectivity=200, tolerance=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931d1907",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T07:27:45.844291Z",
     "start_time": "2023-04-27T07:27:45.840927Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "flood_tensor = torch.from_numpy(flood_mask).float().unsqueeze(0).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a90a89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T07:27:46.032508Z",
     "start_time": "2023-04-27T07:27:46.010880Z"
    }
   },
   "outputs": [],
   "source": [
    "flood_tensor.unique(return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df6087d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T07:27:46.386266Z",
     "start_time": "2023-04-27T07:27:46.201200Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_img(flood_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017ea37d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d798c417",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df453aca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bfbc5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdf10dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f1c6f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "POC-env",
   "language": "python",
   "name": "poc-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
