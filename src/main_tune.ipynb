{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25a1ac32",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Setting-up-imports\" data-toc-modified-id=\"Setting-up-imports-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Setting up imports</a></span></li><li><span><a href=\"#Setting-up-Constant-Hyperparameters\" data-toc-modified-id=\"Setting-up-Constant-Hyperparameters-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Setting up Constant Hyperparameters</a></span></li><li><span><a href=\"#Setting-up-Parameters-and-Functions-for-Training\" data-toc-modified-id=\"Setting-up-Parameters-and-Functions-for-Training-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Setting up Parameters and Functions for Training</a></span><ul class=\"toc-item\"><li><span><a href=\"#Hyperparameters-Search-Space\" data-toc-modified-id=\"Hyperparameters-Search-Space-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Hyperparameters Search Space</a></span></li><li><span><a href=\"#Creating-the-training-function\" data-toc-modified-id=\"Creating-the-training-function-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Creating the training function</a></span></li><li><span><a href=\"#Creating-the-evaluation-function\" data-toc-modified-id=\"Creating-the-evaluation-function-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Creating the evaluation function</a></span></li></ul></li><li><span><a href=\"#Running-the-training\" data-toc-modified-id=\"Running-the-training-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Running the training</a></span><ul class=\"toc-item\"><li><span><a href=\"#Loading-data-for-training\" data-toc-modified-id=\"Loading-data-for-training-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Loading data for training</a></span></li><li><span><a href=\"#Configuring-the-Tuner-with-a-Scheduler-and-a-Search-Algorithm\" data-toc-modified-id=\"Configuring-the-Tuner-with-a-Scheduler-and-a-Search-Algorithm-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Configuring the Tuner with a Scheduler and a Search Algorithm</a></span></li><li><span><a href=\"#Running-the-Tuner\" data-toc-modified-id=\"Running-the-Tuner-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Running the Tuner</a></span></li></ul></li><li><span><a href=\"#Evaluating-the-best-Results\" data-toc-modified-id=\"Evaluating-the-best-Results-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Evaluating the best Results</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035da606",
   "metadata": {},
   "source": [
    "# Setting up imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af16e0d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-21T01:43:17.919617Z",
     "start_time": "2023-03-21T01:43:15.467012Z"
    },
    "cell_style": "center",
    "init_cell": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn.functional import normalize\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import GaussianBlur\n",
    "from torchvision.transforms.functional import invert\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.air import session\n",
    "from ray.air.checkpoint import Checkpoint\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.search.hyperopt import HyperOptSearch\n",
    "\n",
    "\n",
    "from Dataset import POCDataReader, data_augment_, POCDataset\n",
    "from metrics import Metrics, EvaluationMetrics\n",
    "from models import UNet\n",
    "from loss import *\n",
    "from pipelines import *\n",
    "from train import training_loop, validation_loop\n",
    "from train_tqdm import evaluation_loop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9951dd",
   "metadata": {},
   "source": [
    "# Setting up Constant Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "beb97ae7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-21T01:43:40.819862Z",
     "start_time": "2023-03-21T01:43:40.815370Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 15\n",
    "NUM_SAMPLES = 30\n",
    "NUM_MODEL_TEST = 10\n",
    "\n",
    "NUM_AUGMENT = 1\n",
    "\n",
    "LOAD_DATA_ON_GPU = True\n",
    "GPUS_PER_TRIAL = 1\n",
    "CPUS_PER_TRIAL = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d48f809",
   "metadata": {},
   "source": [
    "##### Selecting Cuda device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd6be70b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-21T01:43:41.734817Z",
     "start_time": "2023-03-21T01:43:41.639955Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9687c3e3",
   "metadata": {},
   "source": [
    "# Setting up Parameters and Functions for Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580710fe",
   "metadata": {},
   "source": [
    "##### Setting up the loss function sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b7f919",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-20T01:41:49.244166Z",
     "start_time": "2023-03-20T01:41:49.236565Z"
    },
    "code_folding": [],
    "deletable": false,
    "editable": false,
    "init_cell": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "def loss_fn_sampler():\n",
    "    pixel_losses_list = [\n",
    "        CrossEntropyLoss(weight=torch.tensor([.3, .7])), \n",
    "        FocalLoss(weight=torch.tensor([.3, .7]), gamma=2)\n",
    "    ]\n",
    "    volume_losses_list = [\n",
    "        JaccardLoss(),\n",
    "        TverskyLoss(alpha=0.3, beta=0.7),\n",
    "        FocalTverskyLoss(alpha=0.3, beta=0.7, gamma=2)\n",
    "    ]\n",
    "    loss_combinators_list = [ CombinedLoss, BorderedLoss ]\n",
    "\n",
    "    complete_list = pixel_losses_list + volume_losses_list\n",
    "\n",
    "    for combinator in loss_combinators_list:\n",
    "        complete_list += [combinator(loss1, loss2) for loss1 in pixel_losses_list for loss2 in volume_losses_list]\n",
    "\n",
    "    return complete_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215c221d",
   "metadata": {},
   "source": [
    "## Hyperparameters Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1e136d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-21T01:43:21.825529Z",
     "start_time": "2023-03-21T01:43:21.317629Z"
    },
    "code_folding": [],
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/pirl/.cache/torch/hub/facebookresearch_dino_main\n"
     ]
    }
   ],
   "source": [
    "search_space = {\n",
    "    \"Network\": UNet,\n",
    "    \"Optimizer\": Adam,\n",
    "    \n",
    "    \"Learning Rate\": 1e-4,   #tune.qloguniform(1e-5, 1e-2, 5e-6),\n",
    "    \"Batch Size\": 4,         #tune.qrandint(2, 8, 2),\n",
    "\n",
    "\n",
    "    \"Pixel Loss\": tune.choice([CrossEntropyLoss(weight=torch.tensor([.3, .7])), FocalLoss(weight=torch.tensor([.3, .7]), gamma=2)]),\n",
    "    \"Volume Loss\": tune.choice([JaccardLoss(), TverskyLoss(alpha=0.3, beta=0.7), FocalTverskyLoss(alpha=0.3, beta=0.7, gamma=2)]),\n",
    "    \"Combine Loss\": tune.choice([CombinedLoss, BorderedLoss, PixelLoss, VolumeLoss]),\n",
    "    \n",
    "    \"Negative Mining\": tune.choice([True, False]),\n",
    "    \"Smooth Labeling\": tune.choice([True, False]),\n",
    "\n",
    "    \"Input Filter\": tune.choice([None, invert]),\n",
    "    \"Input Layer\": tune.choice([None, LaplacianFilter(), SobelFilter()]),   #, DINOFilter()]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc521e6",
   "metadata": {},
   "source": [
    "## Creating the training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "626acb32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-21T01:43:47.889106Z",
     "start_time": "2023-03-21T01:43:47.873539Z"
    },
    "code_folding": [
     0
    ],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def train(config, train_data, val_data):\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    inpip = InputPipeline(\n",
    "        transformer=[normalize, config[\"Input Filter\"]] if config[\"Input Filter\"] is not None else normalize, \n",
    "        layer_transformer=config[\"Input Layer\"])\n",
    "    if LOAD_DATA_ON_GPU:\n",
    "        inpip = inpip.to(device)\n",
    "\n",
    "    train_dataset = POCDataset(\n",
    "        train_data,\n",
    "        transform=inpip,\n",
    "        target_transform= GaussianBlur(kernel_size=3, sigma=0.7) if config[\"Smooth Labeling\"] else None,\n",
    "        negative_mining=config[\"Negative Mining\"])\n",
    "#     train_dataset.precompute_transform(LOAD_DATA_ON_GPU)\n",
    "\n",
    "    if LOAD_DATA_ON_GPU:\n",
    "        training_dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=int(config[\"Batch Size\"]),\n",
    "            sampler=train_dataset.sampler)\n",
    "    else:\n",
    "        training_dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=int(config[\"Batch Size\"]),\n",
    "            sampler=train_dataset.sampler,\n",
    "            num_workers=CPUS_PER_TRIAL//2,\n",
    "            pin_memory=True,\n",
    "            pin_memory_device=device)\n",
    "\n",
    "    val_dataset = POCDataset(val_data, transform=inpip, target_transform=None, negative_mining=False)\n",
    "#     val_dataset.precompute_transform(LOAD_DATA_ON_GPU)\n",
    "    \n",
    "    if LOAD_DATA_ON_GPU:\n",
    "        validation_dataloader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=int(config[\"Batch Size\"]),\n",
    "            shuffle=True)\n",
    "    else:\n",
    "        validation_dataloader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=int(config[\"Batch Size\"]),\n",
    "            shuffle=True,\n",
    "            num_workers=CPUS_PER_TRIAL//2,\n",
    "            pin_memory=True,\n",
    "            pin_memory_device=device)\n",
    "\n",
    "    model = config[\"Network\"](n_channels=inpip.nb_channel, n_classes=2, bilinear=True, crop=False)\n",
    "    if torch.cuda.is_available() and torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "\n",
    "    loss_fn = config[\"Combine Loss\"](config[\"Pixel Loss\"], config[\"Volume Loss\"]).to(device)\n",
    "    optimizer = config[\"Optimizer\"](model.parameters(), lr=config[\"Learning Rate\"], betas=(0.9, 0.99))\n",
    "    lr_scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS//2)\n",
    "\n",
    "    # To restore a checkpoint, use `session.get_checkpoint()`.\n",
    "    loaded_checkpoint = session.get_checkpoint()\n",
    "    if loaded_checkpoint:\n",
    "        with loaded_checkpoint.as_directory() as loaded_checkpoint_dir:\n",
    "            model_state, optimizer_state, scheduler_state = torch.load(os.path.join(loaded_checkpoint_dir, \"checkpoint.pt\"))\n",
    "        model.load_state_dict(model_state)\n",
    "        optimizer.load_state_dict(optimizer_state)\n",
    "        lr_scheduler.load_state_dict(scheduler_state)\n",
    "\n",
    "    train_metrics = Metrics(\n",
    "        buffer_size=len(training_dataloader),\n",
    "        mode=\"Training\",\n",
    "        hyperparam=config,\n",
    "        device=device)\n",
    "\n",
    "    val_metrics = Metrics(\n",
    "        buffer_size=len(validation_dataloader),\n",
    "        mode=\"Validation\",\n",
    "        hyperparam=config,\n",
    "        device=device)\n",
    "\n",
    "\n",
    "    for epoch in range(1, EPOCHS+1):  # loop over the dataset multiple times\n",
    "        training_loop(epoch, training_dataloader, model, loss_fn, optimizer, lr_scheduler, train_metrics, device)\n",
    "        validation_loop(epoch, validation_dataloader, model, loss_fn, val_metrics, device)\n",
    "\n",
    "        # Here we save a checkpoint. It is automatically registered with\n",
    "        # Ray Tune and can be accessed through `session.get_checkpoint()`\n",
    "        # API in future iterations.\n",
    "        os.makedirs(\"model\", exist_ok=True)\n",
    "        torch.save((model.state_dict(), optimizer.state_dict(), lr_scheduler.state_dict()), \"model/checkpoint.pt\")\n",
    "        checkpoint = Checkpoint.from_directory(\"model\")\n",
    "        session.report(metrics=val_metrics.get_metrics(epoch), checkpoint=checkpoint)\n",
    "\n",
    "    train_metrics.close_tensorboard()\n",
    "    val_metrics.close_tensorboard()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8a58ec",
   "metadata": {},
   "source": [
    "## Creating the evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da4d17c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-21T01:43:48.592802Z",
     "start_time": "2023-03-21T01:43:48.575183Z"
    },
    "code_folding": [
     0
    ],
    "init_cell": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2132963852.py, line 66)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[9], line 66\u001b[0;36m\u001b[0m\n\u001b[0;31m    device=device)\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def evaluate(test_data, best_result):\n",
    "\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    inpip = InputPipeline(\n",
    "        transformer=[normalize, best_result.config[\"Input Filter\"]] if best_result.config[\"Input Filter\"] is not None else normalize, \n",
    "        layer_transformer=best_result.config[\"Input Layer\"])\n",
    "    if LOAD_DATA_ON_GPU:\n",
    "        inpip = inpip.to(device)\n",
    "\n",
    "    test_dataset = POCDataset(test_data, transform=inpip, target_transform=None, negative_mining=False)\n",
    "    \n",
    "    if LOAD_DATA_ON_GPU:\n",
    "        evaluation_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "    else:\n",
    "        evaluation_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=True, num_workers=20, pin_memory=True, pin_memory_device=device)\n",
    "\n",
    "    best_trained_model = best_result.config[\"Network\"](n_channels=inpip.nb_channel, n_classes=2, bilinear=True, crop=False).to(device)\n",
    "\n",
    "    checkpoint_path = os.path.join(best_result.checkpoint.to_directory(), \"checkpoint.pt\")\n",
    "    model_state, _, _ = torch.load(checkpoint_path)\n",
    "    best_trained_model.load_state_dict(model_state)\n",
    "    \n",
    "    loss_fn = best_result.config[\"Combine Loss\"](best_result.config[\"Pixel Loss\"], best_result.config[\"Volume Loss\"]).to(device)\n",
    "\n",
    "    test_metrics = EvaluationMetrics(\n",
    "        buffer_size=len(evaluation_dataloader),\n",
    "        hyperparam=best_result.config,\n",
    "        device=device)\n",
    "\n",
    "    evaluation_loop(dataloader=evaluation_dataloader, model=best_trained_model, metric=test_metrics, device=device)\n",
    "\n",
    "def evaluate_df(test_data, results_df):\n",
    "\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    results_df.sort_values(\"CrackIoU\", ascending=False, inplace=True)\n",
    "    for index, res in results_df.head(NUM_MODEL_TEST).iterrows():\n",
    "        \n",
    "        inpip = InputPipeline(\n",
    "            transformer=eval(res[\"config/Input Filter\"]),\n",
    "            layer_transformer=eval(res[\"config/Input Layer\"]))\n",
    "        if LOAD_DATA_ON_GPU:\n",
    "            inpip = inpip.to(device)\n",
    "        \n",
    "        test_dataset = POCDataset(test_data, transform=inpip, target_transform=None, negative_mining=False)\n",
    "\n",
    "        if LOAD_DATA_ON_GPU:\n",
    "            evaluation_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "        else:\n",
    "            evaluation_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=True, num_workers=20, pin_memory=True, pin_memory_device=device)\n",
    "\n",
    "        trained_model = eval(res[\"config/Network\"])(n_channels=inpip.nb_channel, n_classes=2, bilinear=True, crop=False).to(device)\n",
    "\n",
    "        checkpoint_path = os.path.join(res[\"logdir\"], \"model/checkpoint.pt\")\n",
    "        model_state, _, _ = torch.load(checkpoint_path)\n",
    "        trained_model.load_state_dict(model_state)\n",
    "\n",
    "        hyperparam = {\n",
    "            \"Network\": str(res[\"config/Network\"]),\n",
    "            \"Optimizer\": str(res[\"config/Optimizer\"]),\n",
    "            \"Learning Rate\": str(res[\"config/Learning Rate\"]),\n",
    "            \"Batch Size\": str(res[\"config/Batch Size\"]),\n",
    "            \"Pixel Loss\": str(res[\"config/Pixel Loss\"]),\n",
    "            \"Volume Loss\": str(res[\"config/Volume Loss\"]),\n",
    "            \"Combine Loss\": str(res[\"config/Combine Loss\"]),\n",
    "            \"Negative Mining\": str(res[\"config/Negative Mining\"]),\n",
    "            \"Smooth Labeling\": str(res[\"config/Smooth Labeling\"]),\n",
    "            \"Input Filter\": str(res[\"config/Input Filter\"]),\n",
    "            \"Input Layer\": str(res[\"config/Input Layer\"]),\n",
    "        }\n",
    "        \n",
    "        test_metrics = EvaluationMetrics(\n",
    "            buffer_size=len(evaluation_dataloader),\n",
    "            hyperparam=hyperparam,\n",
    "            device=device)\n",
    "\n",
    "        evaluation_loop(dataloader=evaluation_dataloader, model=trained_model, metric=test_metrics, device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918e1c03",
   "metadata": {},
   "source": [
    "# Running the training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f955b19",
   "metadata": {},
   "source": [
    "## Loading data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e15a7a2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-21T01:44:27.752633Z",
     "start_time": "2023-03-21T01:43:50.911254Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7efba803f92849b294ce9be15f10e451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset into GPU:   0%|          | 0/2744 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t- Loading done, GPU memory used: 3.14GiB / free: 17.97GiB / total: 22.17GiB\n",
      "\t- Got a total of 2744 images.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfd54016a8d54ea7ab7b1854196a17b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Expending the dataset 1 more times:   0%|          | 0/1920 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t- Augmentation done, GPU memory used: 5.34GiB / free: 15.24GiB / total: 22.17GiB\n",
      "\t- Got 1920 new images and a total of 3840 images.\n"
     ]
    }
   ],
   "source": [
    "data_reader = POCDataReader(root_dir=\"../data\", load_on_gpu=LOAD_DATA_ON_GPU)\n",
    "train_data, val_data, test_data = data_reader.split([0.7, 0.1, 0.2])\n",
    "data_augment_(train_data, n=NUM_AUGMENT, load_on_gpu=LOAD_DATA_ON_GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025b0faa",
   "metadata": {},
   "source": [
    "## Configuring the Tuner with a Scheduler and a Search Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a69701ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-21T01:47:06.855493Z",
     "start_time": "2023-03-21T01:46:58.584157Z"
    }
   },
   "outputs": [],
   "source": [
    "scheduler = ASHAScheduler(max_t=EPOCHS, grace_period=2, reduction_factor=2)\n",
    "search_algo = HyperOptSearch()\n",
    "\n",
    "tune_config = tune.TuneConfig(\n",
    "    metric=\"CrackIoU\",\n",
    "    mode=\"max\",\n",
    "    num_samples=NUM_SAMPLES,\n",
    "    scheduler=scheduler,\n",
    "    search_alg=search_algo)\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    tune.with_resources(\n",
    "        tune.with_parameters(train, train_data=train_data, val_data=val_data),\n",
    "        resources={\"cpu\": CPUS_PER_TRIAL, \"gpu\": GPUS_PER_TRIAL}),\n",
    "    tune_config=tune_config,\n",
    "    param_space=search_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0913de",
   "metadata": {},
   "source": [
    "## Running the Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdfb3720",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-21T01:57:15.388946Z",
     "start_time": "2023-03-21T01:47:08.832202Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 10:47:11,831\tINFO worker.py:1544 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-03-21 10:57:14</td></tr>\n",
       "<tr><td>Running for: </td><td>00:09:46.40        </td></tr>\n",
       "<tr><td>Memory:      </td><td>32.2/125.4 GiB     </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None<br>Resources requested: 40.0/40 CPUs, 2.0/2 GPUs, 0.0/65.04 GiB heap, 0.0/31.87 GiB objects (0.0/1.0 accelerator_type:RTX)\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  \n",
       "  \n",
       "  Number of errored trials: 2<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name    </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                                                       </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_eb3587eb</td><td style=\"text-align: right;\">           1</td><td>/home/pirl/ray_results/train_2023-03-21_10-46-58/train_eb3587eb_1_Batch_Size=4,Combine_Loss=class_loss_loss_BorderedLoss,Input_Filter=None,Input_Layer=None,Learning_Rate=0.0001,Ne_2023-03-21_10-47-28/error.txt</td></tr>\n",
       "<tr><td>train_9424845c</td><td style=\"text-align: right;\">           1</td><td>/home/pirl/ray_results/train_2023-03-21_10-46-58/train_9424845c_2_Batch_Size=4,Combine_Loss=class_loss_loss_BorderedLoss,Input_Filter=function_invert_at_0x7f5ab4363250,Input_Layer_2023-03-21_10-47-31/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name    </th><th>status  </th><th>loc                  </th><th style=\"text-align: right;\">  Batch Size</th><th>Combine Loss        </th><th>Input Filter        </th><th>Input Layer    </th><th style=\"text-align: right;\">  Learning Rate</th><th>Negative Mining  </th><th>Network             </th><th>Optimizer           </th><th>Pixel Loss        </th><th>Smooth Labeling  </th><th>Volume Loss  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_94231a90</td><td>RUNNING </td><td>141.223.108.122:31130</td><td style=\"text-align: right;\">           4</td><td>&lt;class &#x27;loss.lo_9eb0</td><td>&lt;function inver_3250</td><td>LaplacianFilter</td><td style=\"text-align: right;\">         0.0001</td><td>True             </td><td>&lt;class &#x27;models._52b0</td><td>&lt;class &#x27;torch.o_7f60</td><td>FocalLoss         </td><td>False            </td><td>TverskyLoss  </td></tr>\n",
       "<tr><td>train_79af376c</td><td>RUNNING </td><td>141.223.108.122:31214</td><td style=\"text-align: right;\">           4</td><td>&lt;class &#x27;loss.lo_9eb0</td><td>                    </td><td>               </td><td style=\"text-align: right;\">         0.0001</td><td>False            </td><td>&lt;class &#x27;models._52b0</td><td>&lt;class &#x27;torch.o_7f60</td><td>CrossEntropyLoss()</td><td>True             </td><td>TverskyLoss  </td></tr>\n",
       "<tr><td>train_8c59e872</td><td>PENDING </td><td>                     </td><td style=\"text-align: right;\">           4</td><td>&lt;class &#x27;loss.lo_a270</td><td>&lt;function inver_3250</td><td>               </td><td style=\"text-align: right;\">         0.0001</td><td>False            </td><td>&lt;class &#x27;models._52b0</td><td>&lt;class &#x27;torch.o_7f60</td><td>FocalLoss         </td><td>True             </td><td>JaccardLoss  </td></tr>\n",
       "<tr><td>train_eb3587eb</td><td>ERROR   </td><td>141.223.108.122:30760</td><td style=\"text-align: right;\">           4</td><td>&lt;class &#x27;loss.lo_9af0</td><td>                    </td><td>               </td><td style=\"text-align: right;\">         0.0001</td><td>True             </td><td>&lt;class &#x27;models._52b0</td><td>&lt;class &#x27;torch.o_7f60</td><td>FocalLoss         </td><td>True             </td><td>JaccardLoss  </td></tr>\n",
       "<tr><td>train_9424845c</td><td>ERROR   </td><td>141.223.108.122:30848</td><td style=\"text-align: right;\">           4</td><td>&lt;class &#x27;loss.lo_9af0</td><td>&lt;function inver_3250</td><td>SobelFilter    </td><td style=\"text-align: right;\">         0.0001</td><td>True             </td><td>&lt;class &#x27;models._52b0</td><td>&lt;class &#x27;torch.o_7f60</td><td>FocalLoss         </td><td>False            </td><td>TverskyLoss  </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 10:53:57,949\tERROR trial_runner.py:1062 -- Trial train_9424845c: Error processing event.\n",
      "ray.exceptions.RayTaskError(KeyError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=30848, ip=141.223.108.122, repr=train)\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_27215/3378298713.py\", line 81, in train\n",
      "  File \"/home/pirl/POC-Project/src/train.py\", line 30, in training_loop\n",
      "    metric.write_epoch_tensorboard(epoch, lr_scheduler.get_last_lr()[0])\n",
      "  File \"/home/pirl/POC-Project/src/metrics/metrics.py\", line 67, in write_epoch_tensorboard\n",
      "    self.writer.add_scalar(f\"Losses/{self.hyperparameters['Loss function']}\", self.loss, epoch, new_style=True)\n",
      "KeyError: 'Loss function'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name    </th><th>date               </th><th>experiment_id                   </th><th>hostname           </th><th>node_ip        </th><th style=\"text-align: right;\">  pid</th><th style=\"text-align: right;\">  timestamp</th><th>trial_id  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_9424845c</td><td>2023-03-21_10-47-34</td><td>1c1dc2aa18254557b263dcf9664be9fb</td><td>pirl-PowerEdge-T640</td><td>141.223.108.122</td><td style=\"text-align: right;\">30848</td><td style=\"text-align: right;\"> 1679363254</td><td>9424845c  </td></tr>\n",
       "<tr><td>train_eb3587eb</td><td>2023-03-21_10-47-31</td><td>82d5981b5d93461a9d63233e07568837</td><td>pirl-PowerEdge-T640</td><td>141.223.108.122</td><td style=\"text-align: right;\">30760</td><td style=\"text-align: right;\"> 1679363251</td><td>eb3587eb  </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 10:54:13,202\tERROR trial_runner.py:1062 -- Trial train_eb3587eb: Error processing event.\n",
      "ray.exceptions.RayTaskError(KeyError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=30760, ip=141.223.108.122, repr=train)\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_27215/3378298713.py\", line 81, in train\n",
      "  File \"/home/pirl/POC-Project/src/train.py\", line 30, in training_loop\n",
      "    metric.write_epoch_tensorboard(epoch, lr_scheduler.get_last_lr()[0])\n",
      "  File \"/home/pirl/POC-Project/src/metrics/metrics.py\", line 67, in write_epoch_tensorboard\n",
      "    self.writer.add_scalar(f\"Losses/{self.hyperparameters['Loss function']}\", self.loss, epoch, new_style=True)\n",
      "KeyError: 'Loss function'\n",
      "2023-03-21 10:57:12,050\tWARNING tune.py:146 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/tuner.py:292\u001b[0m, in \u001b[0;36mTuner.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_ray_client:\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 292\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_local_tuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TuneError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m TuneError(\n\u001b[1;32m    295\u001b[0m             _TUNER_FAILED_MSG\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    296\u001b[0m                 path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_local_tuner\u001b[38;5;241m.\u001b[39mget_experiment_checkpoint_dir()\n\u001b[1;32m    297\u001b[0m             )\n\u001b[1;32m    298\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/impl/tuner_internal.py:455\u001b[0m, in \u001b[0;36mTunerInternal.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_restored:\n\u001b[1;32m    454\u001b[0m     param_space \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param_space)\n\u001b[0;32m--> 455\u001b[0m     analysis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_space\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    457\u001b[0m     analysis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_resume(trainable)\n",
      "File \u001b[0;32m~/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/impl/tuner_internal.py:572\u001b[0m, in \u001b[0;36mTunerInternal._fit_internal\u001b[0;34m(self, trainable, param_space)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;124;03m\"\"\"Fitting for a fresh Tuner.\"\"\"\u001b[39;00m\n\u001b[1;32m    559\u001b[0m args \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tune_run_arguments(trainable),\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mdict\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tuner_kwargs,\n\u001b[1;32m    571\u001b[0m }\n\u001b[0;32m--> 572\u001b[0m analysis \u001b[38;5;241m=\u001b[39m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclear_remote_string_queue()\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m analysis\n",
      "File \u001b[0;32m~/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/tune.py:762\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, chdir_to_trial_dir, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, reuse_actors, raise_on_failed_trial, callbacks, max_concurrent_trials, trial_executor, _experiment_checkpoint_dir, _remote, _remote_string_queue)\u001b[0m\n\u001b[1;32m    759\u001b[0m tune_taken \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m tune_start\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 762\u001b[0m     \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    763\u001b[0m     \u001b[38;5;66;03m# Wait for the final remote directory sync to finish before exiting\u001b[39;00m\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m runner\u001b[38;5;241m.\u001b[39m_syncer:\n",
      "File \u001b[0;32m~/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/execution/trial_runner.py:752\u001b[0m, in \u001b[0;36mTrialRunner.checkpoint\u001b[0;34m(self, force)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;124;03m\"\"\"Saves execution state to `self._local_checkpoint_dir`.\u001b[39;00m\n\u001b[1;32m    728\u001b[0m \n\u001b[1;32m    729\u001b[0m \u001b[38;5;124;03mOverwrites the current session checkpoint, which starts when self\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;124;03m    force: Forces a checkpoint despite checkpoint_period.\u001b[39;00m\n\u001b[1;32m    737\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warn_if_slow(\n\u001b[1;32m    739\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperiment_checkpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    740\u001b[0m     message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCheckpointing the experiment state took \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    749\u001b[0m     disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_manager\u001b[38;5;241m.\u001b[39mauto_checkpoint_enabled \u001b[38;5;129;01mor\u001b[39;00m force,\n\u001b[1;32m    750\u001b[0m ):\n\u001b[0;32m--> 752\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_checkpoint_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    753\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckpoint_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    754\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial_runner\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    755\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial_executor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrial_executor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    756\u001b[0m \u001b[43m        \u001b[49m\u001b[43msearch_alg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_search_alg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    757\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_callbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    758\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    759\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/execution/trial_runner.py:200\u001b[0m, in \u001b[0;36m_ExperimentCheckpointManager.checkpoint\u001b[0;34m(self, checkpoint_file, trial_runner, trial_executor, search_alg, callbacks, force)\u001b[0m\n\u001b[1;32m    198\u001b[0m checkpoint_time_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m out_of_band_serialize_dataset():\n\u001b[0;32m--> 200\u001b[0m     \u001b[43m_serialize_and_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sync_trial_checkpoints:\n\u001b[1;32m    203\u001b[0m     exclude \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/execution/trial_runner.py:191\u001b[0m, in \u001b[0;36m_ExperimentCheckpointManager.checkpoint.<locals>._serialize_and_write\u001b[0;34m()\u001b[0m\n\u001b[1;32m    188\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(runner_state, f, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39mTuneFunctionEncoder)\n\u001b[1;32m    190\u001b[0m os\u001b[38;5;241m.\u001b[39mreplace(tmp_file_name, checkpoint_file)\n\u001b[0;32m--> 191\u001b[0m \u001b[43msearch_alg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_to_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_local_checkpoint_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msession_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session_str\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m callbacks\u001b[38;5;241m.\u001b[39msave_to_dir(\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_local_checkpoint_dir, session_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session_str\n\u001b[1;32m    196\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/search/search_generator.py:192\u001b[0m, in \u001b[0;36mSearchGenerator.save_to_dir\u001b[0;34m(self, dirpath, session_str)\u001b[0m\n\u001b[1;32m    189\u001b[0m base_searcher \u001b[38;5;241m=\u001b[39m searcher\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# We save the base searcher separately for users to easily\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# separate the searcher.\u001b[39;00m\n\u001b[0;32m--> 192\u001b[0m \u001b[43mbase_searcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_to_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msession_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m _atomic_save(\n\u001b[1;32m    194\u001b[0m     state\u001b[38;5;241m=\u001b[39msearch_alg_state,\n\u001b[1;32m    195\u001b[0m     checkpoint_dir\u001b[38;5;241m=\u001b[39mdirpath,\n\u001b[1;32m    196\u001b[0m     file_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mCKPT_FILE_TMPL\u001b[38;5;241m.\u001b[39mformat(session_str),\n\u001b[1;32m    197\u001b[0m     tmp_file_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.tmp_search_generator_ckpt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    198\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/search/searcher.py:369\u001b[0m, in \u001b[0;36mSearcher.save_to_dir\u001b[0;34m(self, checkpoint_dir, session_str)\u001b[0m\n\u001b[1;32m    367\u001b[0m success \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 369\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtmp_search_ckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m log_once(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuggest:save_to_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/search/hyperopt/hyperopt_search.py:441\u001b[0m, in \u001b[0;36mHyperOptSearch.save\u001b[0;34m(self, checkpoint_path)\u001b[0m\n\u001b[1;32m    439\u001b[0m save_object[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__rstate\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrstate\u001b[38;5;241m.\u001b[39mget_state()\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(checkpoint_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m--> 441\u001b[0m     \u001b[43mcloudpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_object\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/cloudpickle/cloudpickle_fast.py:74\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(obj, file, protocol, buffer_callback)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, buffer_callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;124;03m\"\"\"Serialize obj as bytes streamed into file\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03m    protocol defaults to cloudpickle.DEFAULT_PROTOCOL which is an alias to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m    compatibility with older versions of Python.\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m     \u001b[43mCloudPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_callback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuffer_callback\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/cloudpickle/cloudpickle_fast.py:733\u001b[0m, in \u001b[0;36mCloudPickler.dump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj):\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 733\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    735\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecursion\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m e\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = tuner.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08aabe4",
   "metadata": {},
   "source": [
    "# Evaluating the best Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f9ba97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T05:40:18.913144Z",
     "start_time": "2023-03-10T05:40:18.890272Z"
    }
   },
   "outputs": [],
   "source": [
    "best_result = results.get_best_result(metric=\"CrackIoU\", mode=\"max\", scope=\"all\")  # Get best result object\n",
    "print(\"Best trial config: {}\".format(best_result.config))\n",
    "print(\"Best trial final validation loss: {}\".format(best_result.metrics[\"Loss\"]))\n",
    "print(\"Best trial final validation CrackIoU: {}\".format(best_result.metrics[\"CrackIoU\"]))\n",
    "\n",
    "# evaluate(test_data=test_data, best_result=best_result)\n",
    "\n",
    "results_df = results.get_dataframe(filter_metric=\"CrackIoU\", filter_mode=\"max\")  # Get all trials by CrackIoU\n",
    "results_df.sort_values(\"CrackIoU\", ascending=False, inplace=True)\n",
    "\n",
    "evaluate_df(test_data=test_data, results_df=results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d599c84a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "POC-env",
   "language": "python",
   "name": "poc-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122.844,
   "position": {
    "height": "40px",
    "left": "1576px",
    "right": "20px",
    "top": "120px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
