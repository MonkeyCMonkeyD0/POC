{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25a1ac32",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Setting-up-imports\" data-toc-modified-id=\"Setting-up-imports-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Setting up imports</a></span></li><li><span><a href=\"#Setting-up-Constant-Hyperparameters\" data-toc-modified-id=\"Setting-up-Constant-Hyperparameters-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Setting up Constant Hyperparameters</a></span></li><li><span><a href=\"#Setting-up-Parameters-and-Functions-for-Training\" data-toc-modified-id=\"Setting-up-Parameters-and-Functions-for-Training-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Setting up Parameters and Functions for Training</a></span><ul class=\"toc-item\"><li><span><a href=\"#Hyperparameters-Search-Space\" data-toc-modified-id=\"Hyperparameters-Search-Space-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Hyperparameters Search Space</a></span></li><li><span><a href=\"#Creating-the-training-function\" data-toc-modified-id=\"Creating-the-training-function-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Creating the training function</a></span></li><li><span><a href=\"#Creating-the-evaluation-function\" data-toc-modified-id=\"Creating-the-evaluation-function-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Creating the evaluation function</a></span></li></ul></li><li><span><a href=\"#Running-the-training\" data-toc-modified-id=\"Running-the-training-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Running the training</a></span><ul class=\"toc-item\"><li><span><a href=\"#Loading-data-for-training\" data-toc-modified-id=\"Loading-data-for-training-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Loading data for training</a></span></li><li><span><a href=\"#Configuring-the-Tuner-with-a-Scheduler-and-a-Search-Algorithm\" data-toc-modified-id=\"Configuring-the-Tuner-with-a-Scheduler-and-a-Search-Algorithm-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Configuring the Tuner with a Scheduler and a Search Algorithm</a></span></li><li><span><a href=\"#Running-the-Tuner\" data-toc-modified-id=\"Running-the-Tuner-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Running the Tuner</a></span></li></ul></li><li><span><a href=\"#Evaluating-the-best-Results\" data-toc-modified-id=\"Evaluating-the-best-Results-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Evaluating the best Results</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035da606",
   "metadata": {},
   "source": [
    "# Setting up imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af16e0d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T02:41:01.207928Z",
     "start_time": "2023-04-27T02:40:58.348673Z"
    },
    "cell_style": "center",
    "init_cell": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from itertools import product\n",
    "\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss, Sequential\n",
    "from torch.nn.functional import normalize\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import CenterCrop, Resize, GaussianBlur\n",
    "# from torchvision.transforms.functional import invert\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.air import session, RunConfig, CheckpointConfig\n",
    "from ray.air.checkpoint import Checkpoint\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "# from ray.tune.search.hyperopt import HyperOptSearch\n",
    "from ray.tune.search.optuna import OptunaSearch\n",
    "from ray.tune.search import ConcurrencyLimiter\n",
    "\n",
    "\n",
    "from dataset import POCDataReader, data_augment_, POCDataset\n",
    "from metrics import Metrics, EvaluationMetrics\n",
    "from models import UNet, DeepCrack, SubUNet\n",
    "from loss import *\n",
    "from pipelines import InputPipeline, SequenceFilters, SumFilters\n",
    "from pipelines.filters import *\n",
    "from train import training_loop, validation_loop\n",
    "from train_tqdm import evaluation_loop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9951dd",
   "metadata": {},
   "source": [
    "# Setting up Constant Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "beb97ae7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T02:41:01.214883Z",
     "start_time": "2023-04-27T02:41:01.211342Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "NUM_SAMPLES = 150\n",
    "\n",
    "NUM_AUGMENT = 1\n",
    "\n",
    "LOAD_DATA_ON_GPU = True\n",
    "GPUS_PER_TRIAL = 1\n",
    "CPUS_PER_TRIAL = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d48f809",
   "metadata": {},
   "source": [
    "##### Selecting Cuda device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd6be70b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T02:41:01.279506Z",
     "start_time": "2023-04-27T02:41:01.216838Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9687c3e3",
   "metadata": {},
   "source": [
    "# Setting up Parameters and Functions for Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215c221d",
   "metadata": {},
   "source": [
    "## Hyperparameters Search Space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d931716",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### Preload Losses Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28766a0c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "pixel_loss_list = [\n",
    "    CrossEntropyLoss(weight=torch.tensor([.3, .7])),\n",
    "    FocalLoss(weight=torch.tensor([.3, .7]), gamma=2),\n",
    "]\n",
    "\n",
    "volume_loss_list = [\n",
    "    JaccardLoss(),\n",
    "    TverskyLoss(alpha=0.3, beta=0.7),\n",
    "    FocalTverskyLoss(alpha=0.3, beta=0.7, gamma=2),\n",
    "]\n",
    "\n",
    "loss_list = []\n",
    "for ploss in pixel_loss_list:\n",
    "    loss_list.append(PixelLoss(pixel_loss=ploss, volume_loss=None))\n",
    "for vloss in volume_loss_list:\n",
    "    loss_list.append(VolumeLoss(pixel_loss=None, volume_loss=vloss))\n",
    "for (ploss, vloss) in product(pixel_loss_list, volume_loss_list):\n",
    "    loss_list.append(CombinedLoss(loss1=ploss, loss2=vloss, ratio=0.3))\n",
    "    loss_list.append(BorderedLoss(border_loss=ploss, volume_loss=vloss, ratio=0.7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9939e19b",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### Preload Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e663e37",
   "metadata": {
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "filter_list = [normalize] #, invert]\n",
    "\n",
    "layer_list = [\n",
    "    SobelFilter(),\n",
    "    LaplacianFilter(),\n",
    "    FrangiFilter(),\n",
    "    SatoFilter(),\n",
    "    SumFilters(FrangiFilter(), SatoFilter()),\n",
    "    SkeletonFilter(SequenceFilters(SumFilters(FrangiFilter(), SatoFilter()), CrackBinaryFilter())),\n",
    "]\n",
    "\n",
    "pipeline_list = []\n",
    "for f, l in product(filter_list, layer_list):\n",
    "    pipeline_list.append(InputPipeline(transformer=f, layer_transformer=l))\n",
    "    \n",
    "no_layer_pip = InputPipeline(transformer=[normalize], layer_transformer=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d95e76",
   "metadata": {},
   "source": [
    "##### Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1e136d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T02:41:01.289090Z",
     "start_time": "2023-04-27T02:41:01.283513Z"
    },
    "code_folding": [],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    \"Network\": SubUNet, #tune.grid_search([UNet, DeepCrack, SubUNet]),\n",
    "    \"Optimizer\": Adam,\n",
    "\n",
    "    \"Learning Rate\": tune.loguniform(1e-6, 1e-3),\n",
    "    \"Batch Size\": 4,\n",
    "\n",
    "#     \"Loss Function\": tune.grid_search(loss_list),\n",
    "    \"Loss Combiner\": BorderedLoss,\n",
    "    \"Loss Combiner_ratio\": tune.uniform(0, 1),\n",
    "    \"Loss Volume\": JaccardLoss,\n",
    "    \"Loss Pixel\": FocalLoss,\n",
    "    \"Loss Pixel_gamma\": tune.uniform(0, 5),\n",
    "    \"Loss Pixel_weight\": tune.uniform(0, 1),\n",
    "\n",
    "    \"Negative Mining\": False, #tune.choice([True, False]),\n",
    "    \"Smooth Labeling\": False, #tune.choice([True, False]),\n",
    "\n",
    "#     \"Input Pipeline\": tune.grid_search(pipeline_list),\n",
    "    \"Pipe Filter\": normalize,\n",
    "    \"Pipe Layer\": LaplacianFilter,\n",
    "    \"Pipe Layer_threshold\": tune.loguniform(0.5, 5),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc521e6",
   "metadata": {},
   "source": [
    "## Creating the training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "626acb32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T02:41:01.307729Z",
     "start_time": "2023-04-27T02:41:01.291693Z"
    },
    "code_folding": [
     0
    ],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def train(config, train_data, val_data):\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    inpip = InputPipeline(\n",
    "        transformer=config[\"Pipe Filter\"],\n",
    "        layer_transformer=config[\"Pipe Layer\"](threshold=config[\"Pipe Layer_threshold\"]))\n",
    "    if LOAD_DATA_ON_GPU:\n",
    "        inpip = inpip.to(device)\n",
    "\n",
    "    train_dataset = POCDataset(\n",
    "        train_data,\n",
    "        transform=Sequential(inpip, CenterCrop(size=(480, 480)), Resize(size=(384, 384))),\n",
    "        target_transform= Sequential(\n",
    "            GaussianBlur(kernel_size=3, sigma=0.7),\n",
    "            CenterCrop(size=(480, 480)),\n",
    "            Resize(size=(384, 384)),\n",
    "        ) if config[\"Smooth Labeling\"] else Sequential(\n",
    "            CenterCrop(size=(480, 480)),\n",
    "            Resize(size=(384, 384)),\n",
    "        ),\n",
    "        negative_mining=config[\"Negative Mining\"],\n",
    "        load_on_gpu=LOAD_DATA_ON_GPU)\n",
    "    train_dataset.precompute_transform()\n",
    "\n",
    "    if LOAD_DATA_ON_GPU:\n",
    "        training_dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=int(config[\"Batch Size\"]),\n",
    "            sampler=train_dataset.sampler,\n",
    "            shuffle= True if train_dataset.sampler is None else None,\n",
    "        )\n",
    "    else:\n",
    "        training_dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=int(config[\"Batch Size\"]),\n",
    "            sampler=train_dataset.sampler,\n",
    "            shuffle= True if train_dataset.sampler is None else None,\n",
    "            num_workers=CPUS_PER_TRIAL//2,\n",
    "            pin_memory=True,\n",
    "            pin_memory_device=device)\n",
    "\n",
    "    val_dataset = POCDataset(\n",
    "        val_data, \n",
    "        transform=Sequential(inpip, CenterCrop(size=(480, 480)), Resize(size=(384, 384))),\n",
    "        target_transform=Sequential(CenterCrop(size=(480, 480)), Resize(size=(384, 384))),\n",
    "        negative_mining=False,\n",
    "        load_on_gpu=LOAD_DATA_ON_GPU)\n",
    "    val_dataset.precompute_transform()\n",
    "    \n",
    "    if LOAD_DATA_ON_GPU:\n",
    "        validation_dataloader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=int(config[\"Batch Size\"]),\n",
    "            shuffle=True)\n",
    "    else:\n",
    "        validation_dataloader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=int(config[\"Batch Size\"]),\n",
    "            shuffle=True,\n",
    "            num_workers=CPUS_PER_TRIAL//2,\n",
    "            pin_memory=True,\n",
    "            pin_memory_device=device)\n",
    "\n",
    "    model = config[\"Network\"](n_channels=inpip.nb_channel, n_classes=2)\n",
    "    if torch.cuda.is_available() and torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "\n",
    "    pixel_loss_fn = config[\"Loss Pixel\"](\n",
    "        weight=torch.tensor([config[\"Loss Pixel_weight\"], 1.0 - config[\"Loss Pixel_weight\"]]),\n",
    "        gamma=config[\"Loss Pixel_gamma\"])\n",
    "    volume_loss_fn = config[\"Loss Volume\"]()\n",
    "    loss_fn = config[\"Loss Combiner\"](\n",
    "        border_loss=pixel_loss_fn,\n",
    "        volume_loss=volume_loss_fn,\n",
    "        ratio=config[\"Loss Combiner_ratio\"]).to(device)\n",
    "\n",
    "    optimizer = config[\"Optimizer\"](model.parameters(), lr=config[\"Learning Rate\"], betas=(0.9, 0.99))\n",
    "    lr_scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "\n",
    "    loaded_checkpoint = session.get_checkpoint()\n",
    "    if loaded_checkpoint:\n",
    "        with loaded_checkpoint.as_directory() as loaded_checkpoint_dir:\n",
    "            model_state, optimizer_state, scheduler_state = torch.load(os.path.join(loaded_checkpoint_dir, \"checkpoint.pt\"))\n",
    "        model.load_state_dict(model_state)\n",
    "        optimizer.load_state_dict(optimizer_state)\n",
    "        lr_scheduler.load_state_dict(scheduler_state)\n",
    "\n",
    "    train_metrics = Metrics(\n",
    "        buffer_size=len(training_dataloader),\n",
    "        mode=\"Training\",\n",
    "        hyperparam=config,\n",
    "        device=device)\n",
    "\n",
    "    val_metrics = Metrics(\n",
    "        buffer_size=len(validation_dataloader),\n",
    "        mode=\"Validation\",\n",
    "        hyperparam=config,\n",
    "        device=device)\n",
    "\n",
    "\n",
    "    for epoch in range(1, EPOCHS+1):  # loop over the dataset multiple times\n",
    "        training_loop(epoch, training_dataloader, model, loss_fn, optimizer, lr_scheduler, train_metrics, device)\n",
    "        validation_loop(epoch, validation_dataloader, model, loss_fn, val_metrics, device)\n",
    "\n",
    "        # Here we save a checkpoint. It is automatically registered with\n",
    "        # Ray Tune and can be accessed through `session.get_checkpoint()`\n",
    "        # API in future iterations.\n",
    "        os.makedirs(\"model\", exist_ok=True)\n",
    "        torch.save((model.state_dict(), optimizer.state_dict(), lr_scheduler.state_dict()), \"model/checkpoint.pt\")\n",
    "        checkpoint = Checkpoint.from_directory(\"model\")\n",
    "        session.report(metrics=val_metrics.get_metrics(epoch), checkpoint=checkpoint)\n",
    "\n",
    "    train_metrics.close_tensorboard()\n",
    "    val_metrics.close_tensorboard()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8a58ec",
   "metadata": {},
   "source": [
    "## Creating the evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da4d17c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T02:41:01.316069Z",
     "start_time": "2023-04-27T02:41:01.309727Z"
    },
    "code_folding": [
     0
    ],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def evaluate(test_data, result):\n",
    "\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    inpip = InputPipeline(\n",
    "        transformer=result.config[\"Pipe Filter\"],\n",
    "        layer_transformer=result.config[\"Pipe Layer\"](threshold=result.config[\"Pipe Layer_threshold\"]))\n",
    "    if LOAD_DATA_ON_GPU:\n",
    "        inpip = inpip.to(device)\n",
    "\n",
    "    test_dataset = POCDataset(\n",
    "        test_data,\n",
    "        transform=Sequential(inpip, CenterCrop(size=(480, 480)), Resize(size=(384, 384))),\n",
    "        target_transform=Sequential(CenterCrop(size=(480, 480)), Resize(size=(384, 384))),\n",
    "        negative_mining=False,\n",
    "        load_on_gpu=LOAD_DATA_ON_GPU)\n",
    "    \n",
    "    if LOAD_DATA_ON_GPU:\n",
    "        evaluation_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "    else:\n",
    "        evaluation_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=True, num_workers=2*CPUS_PER_TRIAL, pin_memory=True, pin_memory_device=device)\n",
    "\n",
    "    best_trained_model = result.config[\"Network\"](n_channels=inpip.nb_channel, n_classes=2).to(device)\n",
    "\n",
    "    checkpoint_path = os.path.join(result.checkpoint.to_directory(), \"checkpoint.pt\")\n",
    "    model_state, _, _ = torch.load(checkpoint_path)\n",
    "    best_trained_model.load_state_dict(model_state)\n",
    "\n",
    "    test_metrics = EvaluationMetrics(\n",
    "        buffer_size=len(evaluation_dataloader),\n",
    "        hyperparam=result.config,\n",
    "        epochs=result.metrics[\"Epoch\"],\n",
    "        device=device)\n",
    "\n",
    "    evaluation_loop(dataloader=evaluation_dataloader, model=best_trained_model, metric=test_metrics, device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918e1c03",
   "metadata": {},
   "source": [
    "# Running the training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f955b19",
   "metadata": {},
   "source": [
    "## Loading data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e15a7a2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T02:41:57.444439Z",
     "start_time": "2023-04-27T02:41:01.318027Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d369c9ab86fc429bb56593e53fbb01c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset into RAM:   0%|          | 0/2744 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t- Loading done, RAM used: 4.60GiB / free: 113.33GiB / total: 125.40GiB\n",
      "\t- Got a total of 2744 images.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "777a6b7f33404b8a9fa7448618952862",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Expending the dataset 1 more times:   0%|          | 0/1920 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t- Augmentation done, RAM used: 7.32GiB / free: 110.61GiB / total: 125.40GiB\n",
      "\t- Got 1920 new images and a total of 3840 images.\n"
     ]
    }
   ],
   "source": [
    "data_reader = POCDataReader(root_dir=\"../data/POC\", load_on_gpu=False, verbose=True)\n",
    "train_data, val_data, test_data = data_reader.split([0.7, 0.1, 0.2])\n",
    "data_augment_(train_data, n=NUM_AUGMENT, load_on_gpu=False, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025b0faa",
   "metadata": {},
   "source": [
    "## Configuring the Tuner with a Scheduler and a Search Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a69701ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T02:42:05.735490Z",
     "start_time": "2023-04-27T02:41:57.447039Z"
    }
   },
   "outputs": [],
   "source": [
    "scheduler = ASHAScheduler(max_t=EPOCHS, grace_period=2, reduction_factor=2)\n",
    "# search_algo = HyperOptSearch()\n",
    "search_algo = OptunaSearch()\n",
    "\n",
    "tune_config = tune.TuneConfig(\n",
    "    metric=\"CrackIoU\",\n",
    "    mode=\"max\",\n",
    "    num_samples=NUM_SAMPLES,\n",
    "    scheduler=scheduler,\n",
    "    search_alg=search_algo,\n",
    "    max_concurrent_trials=4,\n",
    ")\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    tune.with_resources(\n",
    "        tune.with_parameters(train, train_data=train_data, val_data=val_data),\n",
    "        resources={\"cpu\": CPUS_PER_TRIAL, \"gpu\": GPUS_PER_TRIAL}),\n",
    "    tune_config=tune_config,\n",
    "    param_space=search_space,\n",
    "    run_config=RunConfig(\n",
    "        local_dir=\"~/POC-Project/ray_results\",\n",
    "        checkpoint_config=CheckpointConfig(\n",
    "            num_to_keep=1,\n",
    "            checkpoint_score_attribute=\"CrackIoU\",\n",
    "            checkpoint_score_order=\"max\",\n",
    "            checkpoint_at_end=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0913de",
   "metadata": {},
   "source": [
    "## Running the Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfb3720",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-27T02:40:59.041Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-27 11:42:08,207\tINFO worker.py:1544 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/search/optuna/optuna_search.py:662: FutureWarning: LogUniformDistribution has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :class:`~optuna.distributions.FloatDistribution` instead.\n",
      "  return ot.distributions.LogUniformDistribution(\n",
      "/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/search/optuna/optuna_search.py:671: FutureWarning: UniformDistribution has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :class:`~optuna.distributions.FloatDistribution` instead.\n",
      "  return ot.distributions.UniformDistribution(\n",
      "\u001b[32m[I 2023-04-27 11:42:21,522]\u001b[0m A new study created in memory with name: optuna\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-04-27 11:51:57</td></tr>\n",
       "<tr><td>Running for: </td><td>00:09:35.84        </td></tr>\n",
       "<tr><td>Memory:      </td><td>41.4/125.4 GiB     </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None<br>Resources requested: 40.0/40 CPUs, 2.0/2 GPUs, 0.0/67.82 GiB heap, 0.0/33.06 GiB objects (0.0/1.0 accelerator_type:RTX)\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  \n",
       "  \n",
       "  Number of errored trials: 4<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name    </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                                                                   </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_08b85916</td><td style=\"text-align: right;\">           1</td><td>/home/pirl/POC-Project/ray_results/train_2023-04-27_11-41-57/train_08b85916_1_Batch_Size=4,Learning_Rate=0.0001,Loss_Combiner=class_loss_combination_loss_BorderedLoss,Loss_Combiner_ratio=0.54_2023-04-27_11-42-21/error.txt</td></tr>\n",
       "<tr><td>train_eca6c353</td><td style=\"text-align: right;\">           1</td><td>/home/pirl/POC-Project/ray_results/train_2023-04-27_11-41-57/train_eca6c353_2_Batch_Size=4,Learning_Rate=0.0006,Loss_Combiner=class_loss_combination_loss_BorderedLoss,Loss_Combiner_ratio=0.84_2023-04-27_11-42-25/error.txt</td></tr>\n",
       "<tr><td>train_dfda29b0</td><td style=\"text-align: right;\">           1</td><td>/home/pirl/POC-Project/ray_results/train_2023-04-27_11-41-57/train_dfda29b0_3_Batch_Size=4,Learning_Rate=0.0000,Loss_Combiner=class_loss_combination_loss_BorderedLoss,Loss_Combiner_ratio=0.36_2023-04-27_11-46-17/error.txt</td></tr>\n",
       "<tr><td>train_2ce3e7d3</td><td style=\"text-align: right;\">           1</td><td>/home/pirl/POC-Project/ray_results/train_2023-04-27_11-41-57/train_2ce3e7d3_4_Batch_Size=4,Learning_Rate=0.0000,Loss_Combiner=class_loss_combination_loss_BorderedLoss,Loss_Combiner_ratio=0.61_2023-04-27_11-46-21/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name    </th><th>status  </th><th>loc                  </th><th style=\"text-align: right;\">  Learning Rate</th><th style=\"text-align: right;\">  Loss Combiner_ratio</th><th style=\"text-align: right;\">  Loss Pixel_gamma</th><th style=\"text-align: right;\">  Loss Pixel_weight</th><th style=\"text-align: right;\">  Pipe Layer_threshold</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_92b4549e</td><td>RUNNING </td><td>141.223.108.122:36942</td><td style=\"text-align: right;\">    0.000326549</td><td style=\"text-align: right;\">             0.617568</td><td style=\"text-align: right;\">         3.77372  </td><td style=\"text-align: right;\">          0.0795479</td><td style=\"text-align: right;\">              1.05296 </td></tr>\n",
       "<tr><td>train_dd276671</td><td>RUNNING </td><td>141.223.108.122:37019</td><td style=\"text-align: right;\">    7.26246e-06</td><td style=\"text-align: right;\">             0.625032</td><td style=\"text-align: right;\">         1.15126  </td><td style=\"text-align: right;\">          0.764014 </td><td style=\"text-align: right;\">              3.06962 </td></tr>\n",
       "<tr><td>train_7532e275</td><td>PENDING </td><td>                     </td><td style=\"text-align: right;\">    0.000458685</td><td style=\"text-align: right;\">             0.794631</td><td style=\"text-align: right;\">         0.74034  </td><td style=\"text-align: right;\">          0.731942 </td><td style=\"text-align: right;\">              1.26741 </td></tr>\n",
       "<tr><td>train_08b85916</td><td>ERROR   </td><td>141.223.108.122:36499</td><td style=\"text-align: right;\">    5.07095e-05</td><td style=\"text-align: right;\">             0.542386</td><td style=\"text-align: right;\">         3.97579  </td><td style=\"text-align: right;\">          0.247624 </td><td style=\"text-align: right;\">              1.22112 </td></tr>\n",
       "<tr><td>train_eca6c353</td><td>ERROR   </td><td>141.223.108.122:36584</td><td style=\"text-align: right;\">    0.000603518</td><td style=\"text-align: right;\">             0.845697</td><td style=\"text-align: right;\">         3.6948   </td><td style=\"text-align: right;\">          0.326855 </td><td style=\"text-align: right;\">              3.95367 </td></tr>\n",
       "<tr><td>train_dfda29b0</td><td>ERROR   </td><td>141.223.108.122:36729</td><td style=\"text-align: right;\">    2.00492e-06</td><td style=\"text-align: right;\">             0.361901</td><td style=\"text-align: right;\">         0.0504258</td><td style=\"text-align: right;\">          0.965534 </td><td style=\"text-align: right;\">              0.569752</td></tr>\n",
       "<tr><td>train_2ce3e7d3</td><td>ERROR   </td><td>141.223.108.122:36806</td><td style=\"text-align: right;\">    2.54547e-06</td><td style=\"text-align: right;\">             0.619572</td><td style=\"text-align: right;\">         2.39281  </td><td style=\"text-align: right;\">          0.534353 </td><td style=\"text-align: right;\">              0.597239</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/optuna/distributions.py:799: FutureWarning: LogUniformDistribution(high=0.001, low=1e-06) is deprecated and internally converted to FloatDistribution(high=0.001, log=True, low=1e-06, step=None). See https://github.com/optuna/optuna/issues/2941.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/optuna/distributions.py:799: FutureWarning: UniformDistribution(high=1.0, low=0.0) is deprecated and internally converted to FloatDistribution(high=1.0, log=False, low=0.0, step=None). See https://github.com/optuna/optuna/issues/2941.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/optuna/distributions.py:799: FutureWarning: UniformDistribution(high=5.0, low=0.0) is deprecated and internally converted to FloatDistribution(high=5.0, log=False, low=0.0, step=None). See https://github.com/optuna/optuna/issues/2941.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/optuna/distributions.py:799: FutureWarning: LogUniformDistribution(high=5.0, low=0.5) is deprecated and internally converted to FloatDistribution(high=5.0, log=True, low=0.5, step=None). See https://github.com/optuna/optuna/issues/2941.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "2023-04-27 11:46:16,643\tERROR trial_runner.py:1062 -- Trial train_08b85916: Error processing event.\n",
      "ray.exceptions.RayTaskError(KeyError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=36499, ip=141.223.108.122, repr=train)\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_33025/2188687277.py\", line 104, in train\n",
      "  File \"/home/pirl/POC-Project/src/train.py\", line 32, in training_loop\n",
      "    metric.write_epoch_tensorboard(epoch, lr_scheduler.get_last_lr()[0])\n",
      "  File \"/home/pirl/POC-Project/src/metrics/metrics.py\", line 87, in write_epoch_tensorboard\n",
      "    if self.hyperparameters['Combine Loss'] == \"PixelLoss\":\n",
      "KeyError: 'Combine Loss'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name    </th><th>date               </th><th>experiment_id                   </th><th>hostname           </th><th>node_ip        </th><th style=\"text-align: right;\">  pid</th><th style=\"text-align: right;\">  timestamp</th><th>trial_id  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_08b85916</td><td>2023-04-27_11-42-25</td><td>1b8a5914f5e840d388f461ebaf61e94f</td><td>pirl-PowerEdge-T640</td><td>141.223.108.122</td><td style=\"text-align: right;\">36499</td><td style=\"text-align: right;\"> 1682563345</td><td>08b85916  </td></tr>\n",
       "<tr><td>train_2ce3e7d3</td><td>2023-04-27_11-46-24</td><td>a1dba36a845643d6bc320c6d23ae6c66</td><td>pirl-PowerEdge-T640</td><td>141.223.108.122</td><td style=\"text-align: right;\">36806</td><td style=\"text-align: right;\"> 1682563584</td><td>2ce3e7d3  </td></tr>\n",
       "<tr><td>train_dfda29b0</td><td>2023-04-27_11-46-20</td><td>1b90afffccbe4859a73ab30fa82e055c</td><td>pirl-PowerEdge-T640</td><td>141.223.108.122</td><td style=\"text-align: right;\">36729</td><td style=\"text-align: right;\"> 1682563580</td><td>dfda29b0  </td></tr>\n",
       "<tr><td>train_eca6c353</td><td>2023-04-27_11-42-28</td><td>09fac4c6f281406088583dd30abe0e33</td><td>pirl-PowerEdge-T640</td><td>141.223.108.122</td><td style=\"text-align: right;\">36584</td><td style=\"text-align: right;\"> 1682563348</td><td>eca6c353  </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-27 11:46:20,599\tERROR trial_runner.py:1062 -- Trial train_eca6c353: Error processing event.\n",
      "ray.exceptions.RayTaskError(KeyError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=36584, ip=141.223.108.122, repr=train)\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_33025/2188687277.py\", line 104, in train\n",
      "  File \"/home/pirl/POC-Project/src/train.py\", line 32, in training_loop\n",
      "    metric.write_epoch_tensorboard(epoch, lr_scheduler.get_last_lr()[0])\n",
      "  File \"/home/pirl/POC-Project/src/metrics/metrics.py\", line 87, in write_epoch_tensorboard\n",
      "    if self.hyperparameters['Combine Loss'] == \"PixelLoss\":\n",
      "KeyError: 'Combine Loss'\n",
      "2023-04-27 11:50:10,404\tERROR trial_runner.py:1062 -- Trial train_dfda29b0: Error processing event.\n",
      "ray.exceptions.RayTaskError(KeyError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=36729, ip=141.223.108.122, repr=train)\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_33025/2188687277.py\", line 104, in train\n",
      "  File \"/home/pirl/POC-Project/src/train.py\", line 32, in training_loop\n",
      "    metric.write_epoch_tensorboard(epoch, lr_scheduler.get_last_lr()[0])\n",
      "  File \"/home/pirl/POC-Project/src/metrics/metrics.py\", line 87, in write_epoch_tensorboard\n",
      "    if self.hyperparameters['Combine Loss'] == \"PixelLoss\":\n",
      "KeyError: 'Combine Loss'\n",
      "2023-04-27 11:50:16,868\tERROR trial_runner.py:1062 -- Trial train_2ce3e7d3: Error processing event.\n",
      "ray.exceptions.RayTaskError(KeyError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=36806, ip=141.223.108.122, repr=train)\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_33025/2188687277.py\", line 104, in train\n",
      "  File \"/home/pirl/POC-Project/src/train.py\", line 32, in training_loop\n",
      "    metric.write_epoch_tensorboard(epoch, lr_scheduler.get_last_lr()[0])\n",
      "  File \"/home/pirl/POC-Project/src/metrics/metrics.py\", line 87, in write_epoch_tensorboard\n",
      "    if self.hyperparameters['Combine Loss'] == \"PixelLoss\":\n",
      "KeyError: 'Combine Loss'\n"
     ]
    }
   ],
   "source": [
    "results = tuner.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08aabe4",
   "metadata": {},
   "source": [
    "# Evaluating the best Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa2da49",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-27T02:40:59.093Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_result = results.get_best_result(metric=\"CrackIoU\", mode=\"max\", scope=\"all\")  # Get best result object\n",
    "print(\"Best trial config: {}\".format(best_result.config))\n",
    "print(\"Best trial final validation loss: {}\".format(best_result.metrics[\"Loss\"]))\n",
    "print(\"Best trial final validation CrackIoU: {}\".format(best_result.metrics[\"CrackIoU\"]))\n",
    "\n",
    "for result in results:\n",
    "    evaluate(test_data=test_data, result=result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8633d3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d599c84a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "POC-env",
   "language": "python",
   "name": "poc-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122.844,
   "position": {
    "height": "144.844px",
    "left": "1576px",
    "right": "20px",
    "top": "120px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
