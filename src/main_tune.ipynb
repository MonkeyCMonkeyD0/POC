{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "035da606",
   "metadata": {},
   "source": [
    "# Setting up imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af16e0d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T07:39:49.032608Z",
     "start_time": "2023-03-09T07:39:46.858609Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn.functional import normalize\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import GaussianBlur\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.air import session\n",
    "from ray.air.checkpoint import Checkpoint\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.search.hyperopt import HyperOptSearch\n",
    "\n",
    "\n",
    "from Dataset import POCDataReader, data_augment_, POCDataset\n",
    "from metrics import Metrics, EvaluationMetrics\n",
    "from models import UNet\n",
    "from loss import *\n",
    "from train import training_loop, validation_loop\n",
    "from train_tqdm import evaluation_loop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9951dd",
   "metadata": {},
   "source": [
    "# Setting up Constant Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "beb97ae7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T07:39:49.038398Z",
     "start_time": "2023-03-09T07:39:49.035235Z"
    }
   },
   "outputs": [],
   "source": [
    "EPOCHS = 3 #20\n",
    "NUM_SAMPLES = 3 #30\n",
    "\n",
    "NB_AUGMENT = 0\n",
    "\n",
    "LOAD_DATA_ON_GPU = False\n",
    "GPUS_PER_TRIAL = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc521e6",
   "metadata": {},
   "source": [
    "## Creating the training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "626acb32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T07:39:49.052407Z",
     "start_time": "2023-03-09T07:39:49.040863Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def train(config, train_data, val_data):\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    train_dataset = POCDataset(\n",
    "        train_data,\n",
    "        transform=normalize,\n",
    "        target_transform= GaussianBlur(kernel_size=3, sigma=0.7) if config[\"SL\"] else None,\n",
    "        negative_mining=config[\"NM\"])\n",
    "    training_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=int(config[\"batch_size\"]),\n",
    "        sampler=train_dataset.sampler,\n",
    "        num_workers=8,\n",
    "        pin_memory=True,\n",
    "        pin_memory_device=device)\n",
    "\n",
    "    val_dataset = POCDataset(val_data, transform=normalize, target_transform=None, negative_mining=False)\n",
    "    validation_dataloader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=int(config[\"batch_size\"]),\n",
    "        shuffle=True,\n",
    "        num_workers=8,\n",
    "        pin_memory=True,\n",
    "        pin_memory_device=device)\n",
    "\n",
    "    model = UNet(n_channels=1, n_classes=2, bilinear=True, crop=False)\n",
    "    if torch.cuda.is_available() and torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "\n",
    "    loss_fn = config[\"loss_fn\"].to(device)\n",
    "    optimizer = Adam(model.parameters(), lr=config[\"lr\"], betas=(0.9, 0.99))\n",
    "    lr_scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS//2)\n",
    "\n",
    "    # To restore a checkpoint, use `session.get_checkpoint()`.\n",
    "    loaded_checkpoint = session.get_checkpoint()\n",
    "    if loaded_checkpoint:\n",
    "        with loaded_checkpoint.as_directory() as loaded_checkpoint_dir:\n",
    "            model_state, optimizer_state, scheduler_state = torch.load(os.path.join(loaded_checkpoint_dir, \"checkpoint.pt\"))\n",
    "        model.load_state_dict(model_state)\n",
    "        optimizer.load_state_dict(optimizer_state)\n",
    "        lr_scheduler.load_state_dict(scheduler_state)\n",
    "\n",
    "    train_metrics = Metrics(\n",
    "        buffer_size=len(training_dataloader),\n",
    "        mode=\"Training\",\n",
    "        model_name=model.__class__.__name__,\n",
    "        loss_name=loss_fn.__class__.__name__,\n",
    "        opt_name=optimizer.__class__.__name__,\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        learning_rate=config[\"lr\"],\n",
    "        negative_mining=config[\"NM\"],\n",
    "        soft_labels=config[\"SL\"],\n",
    "        device=device)\n",
    "\n",
    "    val_metrics = Metrics(\n",
    "        buffer_size=len(validation_dataloader),\n",
    "        mode=\"Validation\",\n",
    "        model_name=model.__class__.__name__,\n",
    "        loss_name=loss_fn.__class__.__name__,\n",
    "        opt_name=optimizer.__class__.__name__,\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        learning_rate=config[\"lr\"],\n",
    "        negative_mining=config[\"NM\"],\n",
    "        soft_labels=config[\"SL\"],\n",
    "        device=device)\n",
    "\n",
    "\n",
    "    for epoch in range(1, EPOCHS+1):  # loop over the dataset multiple times\n",
    "        training_loop(epoch, training_dataloader, model, loss_fn, optimizer, lr_scheduler, train_metrics, device)\n",
    "        validation_loop(epoch, validation_dataloader, model, loss_fn, val_metrics, device)\n",
    "\n",
    "        # Here we save a checkpoint. It is automatically registered with\n",
    "        # Ray Tune and can be accessed through `session.get_checkpoint()`\n",
    "        # API in future iterations.\n",
    "        os.makedirs(\"model\", exist_ok=True)\n",
    "        torch.save((model.state_dict(), optimizer.state_dict(), lr_scheduler.state_dict()), \"model/checkpoint.pt\")\n",
    "        checkpoint = Checkpoint.from_directory(\"model\")\n",
    "        session.report(metrics=val_metrics.get_metrics(epoch), checkpoint=checkpoint)\n",
    "\n",
    "    train_metrics.close_tensorboard()\n",
    "    val_metrics.close_tensorboard()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8a58ec",
   "metadata": {},
   "source": [
    "## Creating the evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da4d17c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T07:39:49.068936Z",
     "start_time": "2023-03-09T07:39:49.055573Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def evaluate(test_data, best_result):\n",
    "\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    test_dataset = POCDataset(test_data, transform=normalize, target_transform=None, negative_mining=False)\n",
    "    evaluation_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=True, num_workers=4, pin_memory=True, pin_memory_device=device)\n",
    "\n",
    "    best_trained_model = UNet(n_channels=1, n_classes=2, bilinear=True, crop=False).to(device)\n",
    "\n",
    "    checkpoint_path = os.path.join(best_result.checkpoint.to_directory(), \"checkpoint.pt\")\n",
    "    model_state, _, _ = torch.load(checkpoint_path)\n",
    "    best_trained_model.load_state_dict(model_state)\n",
    "\n",
    "    test_metrics = EvaluationMetrics(\n",
    "        buffer_size=len(evaluation_dataloader),\n",
    "        model_name=best_trained_model.__class__.__name__,\n",
    "        loss_name=best_result.config[\"loss_fn\"].__class__.__name__,\n",
    "        opt_name=\"Adam\",\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=best_result.config[\"batch_size\"],\n",
    "        learning_rate=best_result.config[\"lr\"],\n",
    "        negative_mining=best_result.config[\"NM\"],\n",
    "        soft_labels=best_result.config[\"SL\"],\n",
    "        device=device)\n",
    "\n",
    "    evaluation_loop(dataloader=evaluation_dataloader, model=best_trained_model, metric=test_metrics, device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580710fe",
   "metadata": {},
   "source": [
    "#### Setting up the loss function sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05b7f919",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T07:39:49.077716Z",
     "start_time": "2023-03-09T07:39:49.070273Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def loss_fn_sampler():\n",
    "    pixel_losses_list = [\n",
    "        CrossEntropyLoss(weight=torch.tensor([.3, .7])), \n",
    "        FocalLoss(weight=torch.tensor([.3, .7]), gamma=2)\n",
    "    ]\n",
    "    volume_losses_list = [\n",
    "        JaccardLoss(),\n",
    "        TverskyLoss(alpha=0.3, beta=0.7),\n",
    "        FocalTverskyLoss(alpha=0.3, beta=0.7, gamma=2)\n",
    "    ]\n",
    "    loss_combinators_list = [ CombinedLoss, BorderedLoss ]\n",
    "\n",
    "    complete_list = pixel_losses_list + volume_losses_list\n",
    "\n",
    "    for combinator in loss_combinators_list:\n",
    "        complete_list += [combinator(loss1, loss2) for loss1 in pixel_losses_list for loss2 in volume_losses_list]\n",
    "\n",
    "    return complete_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918e1c03",
   "metadata": {},
   "source": [
    "# Running the training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215c221d",
   "metadata": {},
   "source": [
    "#### Hyperparameters Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1e136d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T07:39:49.089553Z",
     "start_time": "2023-03-09T07:39:49.079259Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    \"lr\": tune.qloguniform(1e-5, 1e-2, 5e-6),\n",
    "    \"batch_size\": tune.qrandint(2, 4, 2),\n",
    "    \"NM\": tune.choice([True, False]),\n",
    "    \"SL\": tune.choice([True, False]),\n",
    "    \"loss_fn\": tune.choice(loss_fn_sampler()),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d48f809",
   "metadata": {},
   "source": [
    "#### Selecting Cuda device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd6be70b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T07:39:49.150860Z",
     "start_time": "2023-03-09T07:39:49.091733Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f955b19",
   "metadata": {},
   "source": [
    "#### Loading data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e15a7a2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T07:40:13.557114Z",
     "start_time": "2023-03-09T07:39:49.152216Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c1eeb0a9c23438882cba1afd7c627a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset into RAM:   0%|          | 0/2744 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t- Loading done, RAM used: 5.60GiB / free: 32.20GiB / total: 62.73GiB\n",
      "\t- Got a total of 2744 images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tim/Documents/POC_project/src/Dataset.py:36: UserWarning: Need a strictly positive integer for n for data augmentation. Will skip augmentation.\n",
      "  warnings.warn(\"Need a strictly positive integer for n for data augmentation. Will skip augmentation.\")\n"
     ]
    }
   ],
   "source": [
    "data_reader = POCDataReader(root_dir=\"../data\", load_on_gpu=LOAD_DATA_ON_GPU)\n",
    "train_data, val_data, test_data = data_reader.split([0.1, 0.1, 0.2])\n",
    "data_augment_(train_data, n=NB_AUGMENT, load_on_gpu=LOAD_DATA_ON_GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025b0faa",
   "metadata": {},
   "source": [
    "#### Configuring the Tuner with a Scheduler and a Search Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a69701ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T07:40:14.019501Z",
     "start_time": "2023-03-09T07:40:13.558908Z"
    }
   },
   "outputs": [],
   "source": [
    "scheduler = ASHAScheduler(max_t=EPOCHS, grace_period=1, reduction_factor=2)\n",
    "search_algo = HyperOptSearch()\n",
    "\n",
    "tune_config = tune.TuneConfig(\n",
    "    metric=\"CrackIoU\",\n",
    "    mode=\"max\",\n",
    "    num_samples=NUM_SAMPLES,\n",
    "    scheduler=scheduler,\n",
    "    search_alg=search_algo)\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    tune.with_resources(\n",
    "        tune.with_parameters(train, train_data=train_data, val_data=val_data),\n",
    "        resources={\"cpu\": 8, \"gpu\": GPUS_PER_TRIAL}),\n",
    "    tune_config=tune_config,\n",
    "    param_space=search_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0913de",
   "metadata": {},
   "source": [
    "#### Running the Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdfb3720",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T07:45:14.568778Z",
     "start_time": "2023-03-09T07:40:14.022310Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-09 16:40:16,165\tINFO worker.py:1553 -- Started a local Ray instance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-03-09 16:45:14</td></tr>\n",
       "<tr><td>Running for: </td><td>00:04:57.03        </td></tr>\n",
       "<tr><td>Memory:      </td><td>10.7/62.7 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=3<br>Bracket: Iter 2.000: 0.06313158757984638 | Iter 1.000: 0.05989443510770798<br>Resources requested: 0/8 CPUs, 0/1 GPUs, 0.0/34.17 GiB heap, 0.0/17.09 GiB objects (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name    </th><th>status    </th><th>loc                </th><th>NM   </th><th>SL   </th><th style=\"text-align: right;\">  batch_size</th><th>loss_fn             </th><th style=\"text-align: right;\">     lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  Epoch</th><th style=\"text-align: right;\">     Loss</th><th style=\"text-align: right;\">  CrackIoU</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_78fd32f8</td><td>TERMINATED</td><td>192.168.0.96:222685</td><td>False</td><td>True </td><td style=\"text-align: right;\">           2</td><td>(FocalLoss+Foca_e6e0</td><td style=\"text-align: right;\">8.5e-05</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">        148.623 </td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">0.325871 </td><td style=\"text-align: right;\"> 0.0891225</td></tr>\n",
       "<tr><td>train_b399cc00</td><td>TERMINATED</td><td>192.168.0.96:222685</td><td>True </td><td>False</td><td style=\"text-align: right;\">           2</td><td>JaccardLoss         </td><td style=\"text-align: right;\">9.5e-05</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         97.1742</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">0.554521 </td><td style=\"text-align: right;\"> 0.0611611</td></tr>\n",
       "<tr><td>train_ca4c9611</td><td>TERMINATED</td><td>192.168.0.96:222685</td><td>True </td><td>False</td><td style=\"text-align: right;\">           2</td><td>CrossEntropyLoss()  </td><td style=\"text-align: right;\">0.00011</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         48.6109</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">0.0799409</td><td style=\"text-align: right;\"> 0.0486043</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name    </th><th style=\"text-align: right;\">  CrackIoU</th><th style=\"text-align: right;\">  Epoch</th><th style=\"text-align: right;\">     Loss</th><th style=\"text-align: right;\">  MeanIoU</th><th style=\"text-align: right;\">  Tversky</th><th>date               </th><th>done  </th><th>episodes_total  </th><th>experiment_id                   </th><th>hostname  </th><th style=\"text-align: right;\">  iterations_since_restore</th><th>node_ip     </th><th style=\"text-align: right;\">   pid</th><th>should_checkpoint  </th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th>timesteps_total  </th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id  </th><th style=\"text-align: right;\">  warmup_time</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_78fd32f8</td><td style=\"text-align: right;\"> 0.0891225</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">0.325871 </td><td style=\"text-align: right;\"> 0.481059</td><td style=\"text-align: right;\"> 0.235037</td><td>2023-03-09_16-42-48</td><td>True  </td><td>                </td><td>cec2255f05a545e0a747b6817a55c600</td><td>tim-PC    </td><td style=\"text-align: right;\">                         3</td><td>192.168.0.96</td><td style=\"text-align: right;\">222685</td><td>True               </td><td style=\"text-align: right;\">            148.623 </td><td style=\"text-align: right;\">           48.8399</td><td style=\"text-align: right;\">      148.623 </td><td style=\"text-align: right;\"> 1678347768</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   3</td><td>78fd32f8  </td><td style=\"text-align: right;\">   0.00555539</td></tr>\n",
       "<tr><td>train_b399cc00</td><td style=\"text-align: right;\"> 0.0611611</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">0.554521 </td><td style=\"text-align: right;\"> 0.445479</td><td style=\"text-align: right;\"> 0.170824</td><td>2023-03-09_16-44-25</td><td>True  </td><td>                </td><td>cec2255f05a545e0a747b6817a55c600</td><td>tim-PC    </td><td style=\"text-align: right;\">                         2</td><td>192.168.0.96</td><td style=\"text-align: right;\">222685</td><td>True               </td><td style=\"text-align: right;\">             97.1742</td><td style=\"text-align: right;\">           48.453 </td><td style=\"text-align: right;\">       97.1742</td><td style=\"text-align: right;\"> 1678347865</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   2</td><td>b399cc00  </td><td style=\"text-align: right;\">   0.00555539</td></tr>\n",
       "<tr><td>train_ca4c9611</td><td style=\"text-align: right;\"> 0.0486043</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">0.0799409</td><td style=\"text-align: right;\"> 0.447059</td><td style=\"text-align: right;\"> 0.138603</td><td>2023-03-09_16-45-14</td><td>True  </td><td>                </td><td>cec2255f05a545e0a747b6817a55c600</td><td>tim-PC    </td><td style=\"text-align: right;\">                         1</td><td>192.168.0.96</td><td style=\"text-align: right;\">222685</td><td>True               </td><td style=\"text-align: right;\">             48.6109</td><td style=\"text-align: right;\">           48.6109</td><td style=\"text-align: right;\">       48.6109</td><td style=\"text-align: right;\"> 1678347914</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>ca4c9611  </td><td style=\"text-align: right;\">   0.00555539</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-09 16:42:48,695\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'loss_fn': (FocalLoss+FocalTverskyLoss)}\n",
      "2023-03-09 16:44:25,903\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'loss_fn': JaccardLoss}\n",
      "2023-03-09 16:45:14,541\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'loss_fn': CrossEntropyLoss()}\n",
      "2023-03-09 16:45:14,559\tINFO tune.py:798 -- Total run time: 297.06 seconds (297.02 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "results = tuner.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08aabe4",
   "metadata": {},
   "source": [
    "#### Displaying and Evaluating the best Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68f9ba97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-09T07:47:04.877903Z",
     "start_time": "2023-03-09T07:45:14.570358Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial config: {'lr': 8.5e-05, 'batch_size': 2, 'NM': False, 'SL': True, 'loss_fn': (FocalLoss+FocalTverskyLoss)}\n",
      "Best trial final validation loss: 0.32587066292762756\n",
      "Best trial final validation CrackIoU: 0.08912249654531479\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4041b0d1581945b48c411f1fa4690dfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Evaluating]:   0%|          | 0/2196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_result = results.get_best_result(metric=\"CrackIoU\", mode=\"max\", scope=\"all\")  # Get best result object\n",
    "print(\"Best trial config: {}\".format(best_result.config))\n",
    "print(\"Best trial final validation loss: {}\".format(best_result.metrics[\"Loss\"]))\n",
    "print(\"Best trial final validation CrackIoU: {}\".format(best_result.metrics[\"CrackIoU\"]))\n",
    "\n",
    "evaluate(test_data=test_data, best_result=best_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d599c84a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "POC-env",
   "language": "python",
   "name": "poc-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
