{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25a1ac32",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Setting-up-imports\" data-toc-modified-id=\"Setting-up-imports-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Setting up imports</a></span></li><li><span><a href=\"#Setting-up-Constant-Hyperparameters\" data-toc-modified-id=\"Setting-up-Constant-Hyperparameters-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Setting up Constant Hyperparameters</a></span></li><li><span><a href=\"#Setting-up-Parameters-and-Functions-for-Training\" data-toc-modified-id=\"Setting-up-Parameters-and-Functions-for-Training-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Setting up Parameters and Functions for Training</a></span><ul class=\"toc-item\"><li><span><a href=\"#Hyperparameters-Search-Space\" data-toc-modified-id=\"Hyperparameters-Search-Space-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Hyperparameters Search Space</a></span></li><li><span><a href=\"#Creating-the-training-function\" data-toc-modified-id=\"Creating-the-training-function-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Creating the training function</a></span></li><li><span><a href=\"#Creating-the-evaluation-function\" data-toc-modified-id=\"Creating-the-evaluation-function-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Creating the evaluation function</a></span></li></ul></li><li><span><a href=\"#Running-the-training\" data-toc-modified-id=\"Running-the-training-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Running the training</a></span><ul class=\"toc-item\"><li><span><a href=\"#Loading-data-for-training\" data-toc-modified-id=\"Loading-data-for-training-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Loading data for training</a></span></li><li><span><a href=\"#Configuring-the-Tuner-with-a-Scheduler-and-a-Search-Algorithm\" data-toc-modified-id=\"Configuring-the-Tuner-with-a-Scheduler-and-a-Search-Algorithm-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Configuring the Tuner with a Scheduler and a Search Algorithm</a></span></li><li><span><a href=\"#Running-the-Tuner\" data-toc-modified-id=\"Running-the-Tuner-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Running the Tuner</a></span></li></ul></li><li><span><a href=\"#Evaluating-the-best-Results\" data-toc-modified-id=\"Evaluating-the-best-Results-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Evaluating the best Results</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035da606",
   "metadata": {},
   "source": [
    "# Setting up imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af16e0d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T02:37:49.748935Z",
     "start_time": "2023-03-17T02:37:49.748923Z"
    },
    "cell_style": "center",
    "init_cell": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn.functional import normalize\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import GaussianBlur\n",
    "from torchvision.transforms.functional import invert\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.air import session\n",
    "from ray.air.checkpoint import Checkpoint\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.search.hyperopt import HyperOptSearch\n",
    "\n",
    "\n",
    "from Dataset import POCDataReader, data_augment_, POCDataset\n",
    "from metrics import Metrics, EvaluationMetrics\n",
    "from models import UNet\n",
    "from loss import *\n",
    "from pipelines import *\n",
    "from train import training_loop, validation_loop\n",
    "from train_tqdm import evaluation_loop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9951dd",
   "metadata": {},
   "source": [
    "# Setting up Constant Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb97ae7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T02:37:49.750370Z",
     "start_time": "2023-03-17T02:37:49.750358Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 12\n",
    "NUM_SAMPLES = 30\n",
    "NUM_MODEL_TEST = 5\n",
    "\n",
    "NUM_AUGMENT = 1\n",
    "\n",
    "LOAD_DATA_ON_GPU = True\n",
    "GPUS_PER_TRIAL = 1\n",
    "CPUS_PER_TRIAL = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d48f809",
   "metadata": {},
   "source": [
    "##### Selecting Cuda device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6be70b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T02:37:49.751398Z",
     "start_time": "2023-03-17T02:37:49.751386Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9687c3e3",
   "metadata": {},
   "source": [
    "# Setting up Parameters and Functions for Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580710fe",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### Setting up the loss function sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b7f919",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T02:37:49.752435Z",
     "start_time": "2023-03-17T02:37:49.752423Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def loss_fn_sampler():\n",
    "    pixel_losses_list = [\n",
    "        CrossEntropyLoss(weight=torch.tensor([.3, .7])), \n",
    "        FocalLoss(weight=torch.tensor([.3, .7]), gamma=2)\n",
    "    ]\n",
    "    volume_losses_list = [\n",
    "        JaccardLoss(),\n",
    "        TverskyLoss(alpha=0.3, beta=0.7),\n",
    "        FocalTverskyLoss(alpha=0.3, beta=0.7, gamma=2)\n",
    "    ]\n",
    "    loss_combinators_list = [ CombinedLoss, BorderedLoss ]\n",
    "\n",
    "    complete_list = pixel_losses_list + volume_losses_list\n",
    "\n",
    "    for combinator in loss_combinators_list:\n",
    "        complete_list += [combinator(loss1, loss2) for loss1 in pixel_losses_list for loss2 in volume_losses_list]\n",
    "\n",
    "    return complete_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749dfb8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T02:07:15.655414Z",
     "start_time": "2023-03-17T02:07:15.650854Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "##### Setting up the input Pipeline sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4efbeca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T02:37:49.753732Z",
     "start_time": "2023-03-17T02:37:49.753720Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def input_pip_sampler():\n",
    "    transformers_list = [\n",
    "        [invert, normalize],\n",
    "        [normalize],\n",
    "    ]\n",
    "    layer_transformers_list = [\n",
    "        None,\n",
    "        LaplacianFilter(),\n",
    "        SobelFilter(),\n",
    "    ]\n",
    "\n",
    "    return [InputPipeline(transformer, layer_transformer) for transformer in transformers_list for layer_transformer in layer_transformers_list]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215c221d",
   "metadata": {},
   "source": [
    "## Hyperparameters Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e136d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T02:37:49.754992Z",
     "start_time": "2023-03-17T02:37:49.754980Z"
    },
    "code_folding": [],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    \"lr\": 1e-4, #tune.qloguniform(1e-5, 1e-2, 5e-6),\n",
    "    \"batch_size\": 4, #tune.qrandint(2, 8, 2),\n",
    "    \"NM\": tune.choice([True, False]),\n",
    "    \"SL\": tune.choice([True, False]),\n",
    "    \"loss_fn\": tune.choice(loss_fn_sampler()),\n",
    "    \"input_pipeline\": tune.choice(input_pip_sampler())\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc521e6",
   "metadata": {},
   "source": [
    "## Creating the training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626acb32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T02:37:49.756070Z",
     "start_time": "2023-03-17T02:37:49.756058Z"
    },
    "code_folding": [
     0
    ],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def train(config, train_data, val_data):\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    train_dataset = POCDataset(\n",
    "        train_data,\n",
    "        transform=config[\"input_pipeline\"],\n",
    "        target_transform= GaussianBlur(kernel_size=3, sigma=0.7) if config[\"SL\"] else None,\n",
    "        negative_mining=config[\"NM\"])\n",
    "\n",
    "    if LOAD_DATA_ON_GPU:\n",
    "        training_dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=int(config[\"batch_size\"]),\n",
    "            sampler=train_dataset.sampler)\n",
    "    else:\n",
    "        training_dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=int(config[\"batch_size\"]),\n",
    "            sampler=train_dataset.sampler,\n",
    "            num_workers=CPUS_PER_TRIAL//2,\n",
    "            pin_memory=True,\n",
    "            pin_memory_device=device)\n",
    "\n",
    "    val_dataset = POCDataset(val_data, transform=config[\"input_pipeline\"], target_transform=None, negative_mining=False)\n",
    "    \n",
    "    if LOAD_DATA_ON_GPU:\n",
    "        validation_dataloader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=int(config[\"batch_size\"]),\n",
    "            shuffle=True)\n",
    "    else:\n",
    "        validation_dataloader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=int(config[\"batch_size\"]),\n",
    "            shuffle=True,\n",
    "            num_workers=CPUS_PER_TRIAL//2,\n",
    "            pin_memory=True,\n",
    "            pin_memory_device=device)\n",
    "\n",
    "    model = UNet(n_channels=config[\"input_pipeline\"].nb_channel(), n_classes=2, bilinear=True, crop=False)\n",
    "    if torch.cuda.is_available() and torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "\n",
    "    loss_fn = config[\"loss_fn\"].to(device)\n",
    "    optimizer = Adam(model.parameters(), lr=config[\"lr\"], betas=(0.9, 0.99))\n",
    "    lr_scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS//2)\n",
    "\n",
    "    # To restore a checkpoint, use `session.get_checkpoint()`.\n",
    "    loaded_checkpoint = session.get_checkpoint()\n",
    "    if loaded_checkpoint:\n",
    "        with loaded_checkpoint.as_directory() as loaded_checkpoint_dir:\n",
    "            model_state, optimizer_state, scheduler_state = torch.load(os.path.join(loaded_checkpoint_dir, \"checkpoint.pt\"))\n",
    "        model.load_state_dict(model_state)\n",
    "        optimizer.load_state_dict(optimizer_state)\n",
    "        lr_scheduler.load_state_dict(scheduler_state)\n",
    "\n",
    "    train_metrics = Metrics(\n",
    "        buffer_size=len(training_dataloader),\n",
    "        mode=\"Training\",\n",
    "        model_name=model.__class__.__name__,\n",
    "        loss_name=loss_fn.__class__.__name__,\n",
    "        opt_name=optimizer.__class__.__name__,\n",
    "        pip_name=str(config[\"input_pipeline\"]),\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        learning_rate=config[\"lr\"],\n",
    "        negative_mining=config[\"NM\"],\n",
    "        soft_labels=config[\"SL\"],\n",
    "        device=device)\n",
    "\n",
    "    val_metrics = Metrics(\n",
    "        buffer_size=len(validation_dataloader),\n",
    "        mode=\"Validation\",\n",
    "        model_name=model.__class__.__name__,\n",
    "        loss_name=loss_fn.__class__.__name__,\n",
    "        opt_name=optimizer.__class__.__name__,\n",
    "        pip_name=str(config[\"input_pipeline\"]),\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        learning_rate=config[\"lr\"],\n",
    "        negative_mining=config[\"NM\"],\n",
    "        soft_labels=config[\"SL\"],\n",
    "        device=device)\n",
    "\n",
    "\n",
    "    for epoch in range(1, EPOCHS+1):  # loop over the dataset multiple times\n",
    "        training_loop(epoch, training_dataloader, model, loss_fn, optimizer, lr_scheduler, train_metrics, device)\n",
    "        validation_loop(epoch, validation_dataloader, model, loss_fn, val_metrics, device)\n",
    "\n",
    "        # Here we save a checkpoint. It is automatically registered with\n",
    "        # Ray Tune and can be accessed through `session.get_checkpoint()`\n",
    "        # API in future iterations.\n",
    "        os.makedirs(\"model\", exist_ok=True)\n",
    "        torch.save((model.state_dict(), optimizer.state_dict(), lr_scheduler.state_dict()), \"model/checkpoint.pt\")\n",
    "        checkpoint = Checkpoint.from_directory(\"model\")\n",
    "        session.report(metrics=val_metrics.get_metrics(epoch), checkpoint=checkpoint)\n",
    "\n",
    "    train_metrics.close_tensorboard()\n",
    "    val_metrics.close_tensorboard()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8a58ec",
   "metadata": {},
   "source": [
    "## Creating the evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4d17c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T02:37:49.757053Z",
     "start_time": "2023-03-17T02:37:49.757041Z"
    },
    "code_folding": [
     0,
     32
    ],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def evaluate(test_data, best_result):\n",
    "\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    test_dataset = POCDataset(test_data, transform=normalize, target_transform=None, negative_mining=False)\n",
    "    \n",
    "    if LOAD_DATA_ON_GPU:\n",
    "        evaluation_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "    else:\n",
    "        evaluation_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=True, num_workers=20, pin_memory=True, pin_memory_device=device)\n",
    "\n",
    "    best_trained_model = UNet(n_channels=config[\"input_pipeline\"].nb_channel(), n_classes=2, bilinear=True, crop=False).to(device)\n",
    "\n",
    "    checkpoint_path = os.path.join(best_result.checkpoint.to_directory(), \"checkpoint.pt\")\n",
    "    model_state, _, _ = torch.load(checkpoint_path)\n",
    "    best_trained_model.load_state_dict(model_state)\n",
    "\n",
    "    test_metrics = EvaluationMetrics(\n",
    "        buffer_size=len(evaluation_dataloader),\n",
    "        model_name=best_trained_model.__class__.__name__,\n",
    "        loss_name=best_result.config[\"loss_fn\"].__class__.__name__,\n",
    "        opt_name=\"Adam\",\n",
    "        pip_name=str(best_result.config[\"input_pipeline\"]),\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=best_result.config[\"batch_size\"],\n",
    "        learning_rate=best_result.config[\"lr\"],\n",
    "        negative_mining=best_result.config[\"NM\"],\n",
    "        soft_labels=best_result.config[\"SL\"],\n",
    "        device=device)\n",
    "\n",
    "    evaluation_loop(dataloader=evaluation_dataloader, model=best_trained_model, metric=test_metrics, device=device)\n",
    "\n",
    "def evaluate_df(test_data, results_df):\n",
    "\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    test_dataset = POCDataset(test_data, transform=normalize, target_transform=None, negative_mining=False)\n",
    "\n",
    "    if LOAD_DATA_ON_GPU:\n",
    "        evaluation_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "    else:\n",
    "        evaluation_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=True, num_workers=20, pin_memory=True, pin_memory_device=device)\n",
    "\n",
    "    results_df.sort_values(\"CrackIoU\", ascending=False, inplace=True)\n",
    "    for index, res in results_df.head(NUM_MODEL_TEST).iterrows():\n",
    "\n",
    "        trained_model = UNet(n_channels=config[\"input_pipeline\"].nb_channel(), n_classes=2, bilinear=True, crop=False).to(device)\n",
    "\n",
    "        checkpoint_path = os.path.join(res[\"logdir\"], \"model/checkpoint.pt\")\n",
    "        model_state, _, _ = torch.load(checkpoint_path)\n",
    "        trained_model.load_state_dict(model_state)\n",
    "\n",
    "        test_metrics = EvaluationMetrics(\n",
    "            buffer_size=len(evaluation_dataloader),\n",
    "            model_name=trained_model.__class__.__name__,\n",
    "            loss_name=res[\"config/loss_fn\"],\n",
    "            opt_name=\"Adam\",\n",
    "            pip_name=str(best_result.config[\"input_pipeline\"]),\n",
    "            epochs=res[\"Epoch\"],\n",
    "            batch_size=res[\"config/batch_size\"],\n",
    "            learning_rate=res[\"config/lr\"],\n",
    "            negative_mining=res[\"config/NM\"],\n",
    "            soft_labels=res[\"config/SL\"],\n",
    "            device=device)\n",
    "\n",
    "        evaluation_loop(dataloader=evaluation_dataloader, model=trained_model, metric=test_metrics, device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918e1c03",
   "metadata": {},
   "source": [
    "# Running the training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f955b19",
   "metadata": {},
   "source": [
    "## Loading data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e15a7a2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T02:38:40.213822Z",
     "start_time": "2023-03-17T02:38:03.892921Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fb791fb2fe04489b7fd14ec2f65d7f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset into GPU:   0%|          | 0/2744 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t- Loading done, GPU memory used: 3.14GiB / free: 17.97GiB / total: 22.17GiB\n",
      "\t- Got a total of 2744 images.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d801ab5a3c2148fab2c9f83c457abc11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Expending the dataset 1 more times:   0%|          | 0/1920 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t- Augmentation done, GPU memory used: 5.34GiB / free: 15.24GiB / total: 22.17GiB\n",
      "\t- Got 1920 new images and a total of 3840 images.\n"
     ]
    }
   ],
   "source": [
    "data_reader = POCDataReader(root_dir=\"../data\", load_on_gpu=LOAD_DATA_ON_GPU)\n",
    "train_data, val_data, test_data = data_reader.split([0.7, 0.1, 0.2])\n",
    "data_augment_(train_data, n=NUM_AUGMENT, load_on_gpu=LOAD_DATA_ON_GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025b0faa",
   "metadata": {},
   "source": [
    "## Configuring the Tuner with a Scheduler and a Search Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a69701ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T02:38:53.069372Z",
     "start_time": "2023-03-17T02:38:44.494288Z"
    }
   },
   "outputs": [],
   "source": [
    "scheduler = ASHAScheduler(max_t=EPOCHS, grace_period=2, reduction_factor=2)\n",
    "search_algo = HyperOptSearch()\n",
    "\n",
    "tune_config = tune.TuneConfig(\n",
    "    metric=\"CrackIoU\",\n",
    "    mode=\"max\",\n",
    "    num_samples=NUM_SAMPLES,\n",
    "    scheduler=scheduler,\n",
    "    search_alg=search_algo)\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    tune.with_resources(\n",
    "        tune.with_parameters(train, train_data=train_data, val_data=val_data),\n",
    "        resources={\"cpu\": CPUS_PER_TRIAL, \"gpu\": GPUS_PER_TRIAL}),\n",
    "    tune_config=tune_config,\n",
    "    param_space=search_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0913de",
   "metadata": {},
   "source": [
    "## Running the Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdfb3720",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T02:39:36.535192Z",
     "start_time": "2023-03-17T02:38:53.710919Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 11:38:56,604\tINFO worker.py:1544 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-03-17 11:39:31</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:20.71        </td></tr>\n",
       "<tr><td>Memory:      </td><td>24.8/125.4 GiB     </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None<br>Resources requested: 40.0/40 CPUs, 2.0/2 GPUs, 0.0/69.01 GiB heap, 0.0/33.57 GiB objects (0.0/1.0 accelerator_type:RTX)\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  \n",
       "  \n",
       "  Number of errored trials: 2<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name    </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                                                       </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_9de30aff</td><td style=\"text-align: right;\">           1</td><td>/home/pirl/ray_results/train_2023-03-17_11-38-44/train_9de30aff_1_NM=True,SL=False,batch_size=4,input_pipeline=InputPipeline_invert_normalize,loss_fn=CrossEntropyLoss,lr=0.0001_2023-03-17_11-39-10/error.txt   </td></tr>\n",
       "<tr><td>train_13042d22</td><td style=\"text-align: right;\">           1</td><td>/home/pirl/ray_results/train_2023-03-17_11-38-44/train_13042d22_2_NM=False,SL=True,batch_size=4,input_pipeline=InputPipeline_invert_normalize_SobelFilter,loss_fn=FocalLoss,lr=0.00_2023-03-17_11-39-13/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name    </th><th>status  </th><th>loc                  </th><th>NM   </th><th>SL   </th><th style=\"text-align: right;\">  batch_size</th><th>input_pipeline      </th><th>loss_fn             </th><th style=\"text-align: right;\">    lr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_a01bfd90</td><td>RUNNING </td><td>141.223.108.122:39044</td><td>False</td><td>False</td><td style=\"text-align: right;\">           4</td><td>InputPipeline(n_2230</td><td>(B:FocalLoss+V:_be20</td><td style=\"text-align: right;\">0.0001</td></tr>\n",
       "<tr><td>train_6ca31522</td><td>RUNNING </td><td>141.223.108.122:39123</td><td>False</td><td>False</td><td style=\"text-align: right;\">           4</td><td>InputPipeline(n_2410</td><td>FocalLoss           </td><td style=\"text-align: right;\">0.0001</td></tr>\n",
       "<tr><td>train_813fefa1</td><td>PENDING </td><td>                     </td><td>False</td><td>True </td><td style=\"text-align: right;\">           4</td><td>InputPipeline(i_3370</td><td>FocalLoss           </td><td style=\"text-align: right;\">0.0001</td></tr>\n",
       "<tr><td>train_9de30aff</td><td>ERROR   </td><td>141.223.108.122:38866</td><td>True </td><td>False</td><td style=\"text-align: right;\">           4</td><td>InputPipeline(i_c3a0</td><td>CrossEntropyLoss()  </td><td style=\"text-align: right;\">0.0001</td></tr>\n",
       "<tr><td>train_13042d22</td><td>ERROR   </td><td>141.223.108.122:38953</td><td>False</td><td>True </td><td style=\"text-align: right;\">           4</td><td>InputPipeline(i_9960</td><td>FocalLoss           </td><td style=\"text-align: right;\">0.0001</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 11:39:21,363\tERROR trial_runner.py:1062 -- Trial train_9de30aff: Error processing event.\n",
      "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=38866, ip=141.223.108.122, repr=train)\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_35348/406286832.py\", line 41, in train\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1269, in __getattr__\n",
      "    raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n",
      "AttributeError: 'InputPipeline' object has no attribute 'nb_channel'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name    </th><th>date               </th><th>experiment_id                   </th><th>hostname           </th><th>node_ip        </th><th style=\"text-align: right;\">  pid</th><th style=\"text-align: right;\">  timestamp</th><th>trial_id  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_13042d22</td><td>2023-03-17_11-39-16</td><td>1d4cd90168a24273b084ebe8e57cd312</td><td>pirl-PowerEdge-T640</td><td>141.223.108.122</td><td style=\"text-align: right;\">38953</td><td style=\"text-align: right;\"> 1679020756</td><td>13042d22  </td></tr>\n",
       "<tr><td>train_9de30aff</td><td>2023-03-17_11-39-13</td><td>227a0c660edd4c0e868552ea874089e4</td><td>pirl-PowerEdge-T640</td><td>141.223.108.122</td><td style=\"text-align: right;\">38866</td><td style=\"text-align: right;\"> 1679020753</td><td>9de30aff  </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 11:39:24,133\tERROR trial_runner.py:1062 -- Trial train_13042d22: Error processing event.\n",
      "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=38953, ip=141.223.108.122, repr=train)\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_35348/406286832.py\", line 41, in train\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1269, in __getattr__\n",
      "    raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n",
      "AttributeError: 'InputPipeline' object has no attribute 'nb_channel'\n",
      "2023-03-17 11:39:29,018\tWARNING tune.py:146 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "2023-03-17 11:39:36,521\tERROR tune.py:794 -- Trials did not complete: [train_9de30aff, train_13042d22, train_a01bfd90, train_6ca31522, train_813fefa1]\n",
      "2023-03-17 11:39:36,523\tINFO tune.py:798 -- Total run time: 26.21 seconds (20.67 seconds for the tuning loop).\n",
      "2023-03-17 11:39:36,524\tWARNING tune.py:804 -- Experiment has been interrupted, but the most recent state was saved. You can continue running this experiment by passing `resume=True` to `tune.run()`\n"
     ]
    }
   ],
   "source": [
    "results = tuner.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08aabe4",
   "metadata": {},
   "source": [
    "# Evaluating the best Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f9ba97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T05:40:18.913144Z",
     "start_time": "2023-03-10T05:40:18.890272Z"
    }
   },
   "outputs": [],
   "source": [
    "best_result = results.get_best_result(metric=\"CrackIoU\", mode=\"max\", scope=\"all\")  # Get best result object\n",
    "print(\"Best trial config: {}\".format(best_result.config))\n",
    "print(\"Best trial final validation loss: {}\".format(best_result.metrics[\"Loss\"]))\n",
    "print(\"Best trial final validation CrackIoU: {}\".format(best_result.metrics[\"CrackIoU\"]))\n",
    "\n",
    "# evaluate(test_data=test_data, best_result=best_result)\n",
    "\n",
    "results_df = results.get_dataframe(filter_metric=\"CrackIoU\", filter_mode=\"max\")  # Get all trials by CrackIoU\n",
    "results_df.sort_values(\"CrackIoU\", ascending=False, inplace=True)\n",
    "\n",
    "evaluate_df(test_data=test_data, results_df=results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d599c84a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "POC-env",
   "language": "python",
   "name": "poc-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
