{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25a1ac32",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Setting-up-imports\" data-toc-modified-id=\"Setting-up-imports-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Setting up imports</a></span></li><li><span><a href=\"#Setting-up-Constant-Hyperparameters\" data-toc-modified-id=\"Setting-up-Constant-Hyperparameters-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Setting up Constant Hyperparameters</a></span></li><li><span><a href=\"#Setting-up-Parameters-and-Functions-for-Training\" data-toc-modified-id=\"Setting-up-Parameters-and-Functions-for-Training-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Setting up Parameters and Functions for Training</a></span><ul class=\"toc-item\"><li><span><a href=\"#Hyperparameters-Search-Space\" data-toc-modified-id=\"Hyperparameters-Search-Space-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Hyperparameters Search Space</a></span></li><li><span><a href=\"#Creating-the-training-function\" data-toc-modified-id=\"Creating-the-training-function-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Creating the training function</a></span></li><li><span><a href=\"#Creating-the-evaluation-function\" data-toc-modified-id=\"Creating-the-evaluation-function-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Creating the evaluation function</a></span></li></ul></li><li><span><a href=\"#Running-the-training\" data-toc-modified-id=\"Running-the-training-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Running the training</a></span><ul class=\"toc-item\"><li><span><a href=\"#Loading-data-for-training\" data-toc-modified-id=\"Loading-data-for-training-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Loading data for training</a></span></li><li><span><a href=\"#Configuring-the-Tuner-with-a-Scheduler-and-a-Search-Algorithm\" data-toc-modified-id=\"Configuring-the-Tuner-with-a-Scheduler-and-a-Search-Algorithm-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Configuring the Tuner with a Scheduler and a Search Algorithm</a></span></li><li><span><a href=\"#Running-the-Tuner\" data-toc-modified-id=\"Running-the-Tuner-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Running the Tuner</a></span></li></ul></li><li><span><a href=\"#Evaluating-the-best-Results\" data-toc-modified-id=\"Evaluating-the-best-Results-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Evaluating the best Results</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035da606",
   "metadata": {},
   "source": [
    "# Setting up imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af16e0d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:17:56.294649Z",
     "start_time": "2023-03-30T08:17:53.838841Z"
    },
    "cell_style": "center",
    "init_cell": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn.functional import normalize\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import GaussianBlur\n",
    "# from torchvision.transforms.functional import invert\n",
    "from torchvision.models import vision_transformer\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.air import session, RunConfig\n",
    "from ray.air.checkpoint import Checkpoint\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.search.hyperopt import HyperOptSearch\n",
    "\n",
    "\n",
    "from dataset import POCDataReader, data_augment_, POCDataset\n",
    "from metrics import Metrics, EvaluationMetrics\n",
    "from models import UNet\n",
    "from loss import *\n",
    "from pipelines import InputPipeline, SumFilters\n",
    "from pipelines.filters import *\n",
    "from train import training_loop, validation_loop\n",
    "from train_tqdm import evaluation_loop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9951dd",
   "metadata": {},
   "source": [
    "# Setting up Constant Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "beb97ae7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:17:56.301193Z",
     "start_time": "2023-03-30T08:17:56.297758Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 15\n",
    "NUM_SAMPLES = 150\n",
    "NUM_MODEL_TEST = 10\n",
    "\n",
    "NUM_AUGMENT = 1\n",
    "\n",
    "LOAD_DATA_ON_GPU = True\n",
    "GPUS_PER_TRIAL = 1\n",
    "CPUS_PER_TRIAL = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d48f809",
   "metadata": {},
   "source": [
    "##### Selecting Cuda device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd6be70b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:17:56.343962Z",
     "start_time": "2023-03-30T08:17:56.303122Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9687c3e3",
   "metadata": {},
   "source": [
    "# Setting up Parameters and Functions for Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215c221d",
   "metadata": {},
   "source": [
    "## Hyperparameters Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1e136d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:17:56.355742Z",
     "start_time": "2023-03-30T08:17:56.347844Z"
    },
    "code_folding": [],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    \"Network\": UNet,\n",
    "    \"Optimizer\": Adam,\n",
    "    \n",
    "    \"Learning Rate\": 1e-4,     #tune.qloguniform(1e-5, 1e-2, 5e-6),\n",
    "    \"Batch Size\": 4,           #tune.qrandint(2, 8, 2),\n",
    "\n",
    "    \"Pixel Loss\": tune.choice([CrossEntropyLoss(weight=torch.tensor([.3, .7])), FocalLoss(weight=torch.tensor([.3, .7]), gamma=2)]),\n",
    "    \"Volume Loss\": tune.choice([JaccardLoss(), TverskyLoss(alpha=0.3, beta=0.7), FocalTverskyLoss(alpha=0.3, beta=0.7, gamma=2)]),\n",
    "    \"Combine Loss\": tune.choice([CombinedLoss, BorderedLoss, PixelLoss, VolumeLoss]),\n",
    "    \n",
    "    \"Negative Mining\": tune.choice([True, False]),\n",
    "    \"Smooth Labeling\": tune.choice([True, False]),\n",
    "\n",
    "    \"Input Filter\": normalize,  #tune.choice([None, invert]),\n",
    "    \"Input Layer\": FrangiFilter(), #tune.choice([FrangiFilter(), SatoFilter(), SumFilters(FrangiFilter(), SatoFilter())]), #DINOFilter()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc521e6",
   "metadata": {},
   "source": [
    "## Creating the training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "626acb32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:17:56.368931Z",
     "start_time": "2023-03-30T08:17:56.357836Z"
    },
    "code_folding": [
     0
    ],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def train(config, train_data, val_data):\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    inpip = InputPipeline(\n",
    "        transformer=config[\"Input Filter\"],\n",
    "        layer_transformer=config[\"Input Layer\"])\n",
    "    if LOAD_DATA_ON_GPU:\n",
    "        inpip = inpip.to(device)\n",
    "\n",
    "    train_dataset = POCDataset(\n",
    "        train_data,\n",
    "        transform=inpip,\n",
    "        target_transform= GaussianBlur(kernel_size=3, sigma=0.7) if config[\"Smooth Labeling\"] else None,\n",
    "        negative_mining=config[\"Negative Mining\"],\n",
    "        load_on_gpu=LOAD_DATA_ON_GPU)\n",
    "    train_dataset.precompute_transform()\n",
    "\n",
    "    if LOAD_DATA_ON_GPU:\n",
    "        training_dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=int(config[\"Batch Size\"]),\n",
    "            sampler=train_dataset.sampler,\n",
    "            shuffle= True if train_dataset.sampler is None else None,\n",
    "        )\n",
    "    else:\n",
    "        training_dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=int(config[\"Batch Size\"]),\n",
    "            sampler=train_dataset.sampler,\n",
    "            shuffle= True if train_dataset.sampler is None else None,\n",
    "            num_workers=CPUS_PER_TRIAL//2,\n",
    "            pin_memory=True,\n",
    "            pin_memory_device=device)\n",
    "\n",
    "    val_dataset = POCDataset(\n",
    "        val_data, \n",
    "        transform=inpip, \n",
    "        target_transform=None, \n",
    "        negative_mining=False,\n",
    "        load_on_gpu=LOAD_DATA_ON_GPU)\n",
    "    val_dataset.precompute_transform()\n",
    "    \n",
    "    if LOAD_DATA_ON_GPU:\n",
    "        validation_dataloader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=int(config[\"Batch Size\"]),\n",
    "            shuffle=True)\n",
    "    else:\n",
    "        validation_dataloader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=int(config[\"Batch Size\"]),\n",
    "            shuffle=True,\n",
    "            num_workers=CPUS_PER_TRIAL//2,\n",
    "            pin_memory=True,\n",
    "            pin_memory_device=device)\n",
    "\n",
    "    model = config[\"Network\"](n_channels=inpip.nb_channel, n_classes=2, bilinear=True, crop=False)\n",
    "    if torch.cuda.is_available() and torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "\n",
    "    loss_fn = config[\"Combine Loss\"](config[\"Pixel Loss\"], config[\"Volume Loss\"]).to(device)\n",
    "    optimizer = config[\"Optimizer\"](model.parameters(), lr=config[\"Learning Rate\"], betas=(0.9, 0.99))\n",
    "    lr_scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "\n",
    "    loaded_checkpoint = session.get_checkpoint()\n",
    "    if loaded_checkpoint:\n",
    "        with loaded_checkpoint.as_directory() as loaded_checkpoint_dir:\n",
    "            model_state, optimizer_state, scheduler_state = torch.load(os.path.join(loaded_checkpoint_dir, \"checkpoint.pt\"))\n",
    "        model.load_state_dict(model_state)\n",
    "        optimizer.load_state_dict(optimizer_state)\n",
    "        lr_scheduler.load_state_dict(scheduler_state)\n",
    "\n",
    "    train_metrics = Metrics(\n",
    "        buffer_size=len(training_dataloader),\n",
    "        mode=\"Training\",\n",
    "        hyperparam=config,\n",
    "        device=device)\n",
    "\n",
    "    val_metrics = Metrics(\n",
    "        buffer_size=len(validation_dataloader),\n",
    "        mode=\"Validation\",\n",
    "        hyperparam=config,\n",
    "        device=device)\n",
    "\n",
    "\n",
    "    for epoch in range(1, EPOCHS+1):  # loop over the dataset multiple times\n",
    "        training_loop(epoch, training_dataloader, model, loss_fn, optimizer, lr_scheduler, train_metrics, device)\n",
    "        validation_loop(epoch, validation_dataloader, model, loss_fn, val_metrics, device)\n",
    "\n",
    "        # Here we save a checkpoint. It is automatically registered with\n",
    "        # Ray Tune and can be accessed through `session.get_checkpoint()`\n",
    "        # API in future iterations.\n",
    "        os.makedirs(\"model\", exist_ok=True)\n",
    "        torch.save((model.state_dict(), optimizer.state_dict(), lr_scheduler.state_dict()), \"model/checkpoint.pt\")\n",
    "        checkpoint = Checkpoint.from_directory(\"model\")\n",
    "        session.report(metrics=val_metrics.get_metrics(epoch), checkpoint=checkpoint)\n",
    "\n",
    "    train_metrics.close_tensorboard()\n",
    "    val_metrics.close_tensorboard()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8a58ec",
   "metadata": {},
   "source": [
    "## Creating the evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da4d17c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:17:56.376314Z",
     "start_time": "2023-03-30T08:17:56.370743Z"
    },
    "code_folding": [
     0
    ],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def evaluate(test_data, result):\n",
    "\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    inpip = InputPipeline(\n",
    "        transformer=result.config[\"Input Filter\"], \n",
    "        layer_transformer=result.config[\"Input Layer\"])\n",
    "    if LOAD_DATA_ON_GPU:\n",
    "        inpip = inpip.to(device)\n",
    "\n",
    "    test_dataset = POCDataset(test_data, transform=inpip, target_transform=None, negative_mining=False, load_on_gpu=LOAD_DATA_ON_GPU)\n",
    "    \n",
    "    if LOAD_DATA_ON_GPU:\n",
    "        evaluation_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "    else:\n",
    "        evaluation_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=True, num_workers=20, pin_memory=True, pin_memory_device=device)\n",
    "\n",
    "    best_trained_model = result.config[\"Network\"](n_channels=inpip.nb_channel, n_classes=2, bilinear=True, crop=False).to(device)\n",
    "\n",
    "    checkpoint_path = os.path.join(result.checkpoint.to_directory(), \"checkpoint.pt\")\n",
    "    model_state, _, _ = torch.load(checkpoint_path)\n",
    "    best_trained_model.load_state_dict(model_state)\n",
    "\n",
    "    test_metrics = EvaluationMetrics(\n",
    "        buffer_size=len(evaluation_dataloader),\n",
    "        hyperparam=result.config,\n",
    "        epochs=result.metrics[\"Epoch\"],\n",
    "        device=device)\n",
    "\n",
    "    evaluation_loop(dataloader=evaluation_dataloader, model=best_trained_model, metric=test_metrics, device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918e1c03",
   "metadata": {},
   "source": [
    "# Running the training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f955b19",
   "metadata": {},
   "source": [
    "## Loading data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e15a7a2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:18:53.344901Z",
     "start_time": "2023-03-30T08:17:56.378496Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc8a142dace54a62b3d2cddb2bc53a5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset into RAM:   0%|          | 0/2744 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t- Loading done, RAM used: 7.20GiB / free: 28.72GiB / total: 125.40GiB\n",
      "\t- Got a total of 2744 images.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44bf1aab938449999a0c0e003b7de515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Expending the dataset 1 more times:   0%|          | 0/1920 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t- Augmentation done, RAM used: 9.94GiB / free: 25.98GiB / total: 125.40GiB\n",
      "\t- Got 1920 new images and a total of 3840 images.\n"
     ]
    }
   ],
   "source": [
    "data_reader = POCDataReader(root_dir=\"../data/POC\", load_on_gpu=False, verbose=True)\n",
    "train_data, val_data, test_data = data_reader.split([0.7, 0.1, 0.2])\n",
    "data_augment_(train_data, n=NUM_AUGMENT, load_on_gpu=False, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025b0faa",
   "metadata": {},
   "source": [
    "## Configuring the Tuner with a Scheduler and a Search Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a69701ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T08:19:02.128609Z",
     "start_time": "2023-03-30T08:18:53.347383Z"
    }
   },
   "outputs": [],
   "source": [
    "scheduler = ASHAScheduler(max_t=EPOCHS, grace_period=2, reduction_factor=2)\n",
    "search_algo = HyperOptSearch()\n",
    "\n",
    "tune_config = tune.TuneConfig(\n",
    "    metric=\"CrackIoU\",\n",
    "    mode=\"max\",\n",
    "    num_samples=NUM_SAMPLES,\n",
    "    scheduler=scheduler,\n",
    "    search_alg=search_algo)\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    tune.with_resources(\n",
    "        tune.with_parameters(train, train_data=train_data, val_data=val_data),\n",
    "        resources={\"cpu\": CPUS_PER_TRIAL, \"gpu\": GPUS_PER_TRIAL}),\n",
    "    tune_config=tune_config,\n",
    "    param_space=search_space,\n",
    "    run_config=RunConfig(local_dir=\"~/POC-Project/ray_results\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0913de",
   "metadata": {},
   "source": [
    "## Running the Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfb3720",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-30T08:17:54.566Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-30 17:19:05,676\tINFO worker.py:1544 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-03-31 11:42:15</td></tr>\n",
       "<tr><td>Running for: </td><td>18:22:55.95        </td></tr>\n",
       "<tr><td>Memory:      </td><td>48.5/125.4 GiB     </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=45<br>Bracket: Iter 8.000: 0.8181117177009583 | Iter 4.000: 0.787495493888855 | Iter 2.000: 0.7256017923355103<br>Resources requested: 40.0/40 CPUs, 2.0/2 GPUs, 0.0/60.78 GiB heap, 0.0/30.04 GiB objects (0.0/1.0 accelerator_type:RTX)\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  \n",
       "  ... 30 more trials not shown (30 TERMINATED)\n",
       "  Number of errored trials: 2<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name    </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                                                                   </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_14b842ff</td><td style=\"text-align: right;\">           1</td><td>/home/pirl/POC-Project/ray_results/train_2023-03-30_17-18-53/train_14b842ff_4_Batch_Size=4,Combine_Loss=class_loss_loss_PixelLoss,Input_Filter=function_normalize_at_0x7fe27486caf0,Input_Layer_2023-03-30_19-08-08/error.txt</td></tr>\n",
       "<tr><td>train_07e61d56</td><td style=\"text-align: right;\">           1</td><td>/home/pirl/POC-Project/ray_results/train_2023-03-30_17-18-53/train_07e61d56_8_Batch_Size=4,Combine_Loss=class_loss_loss_VolumeLoss,Input_Filter=function_normalize_at_0x7fe27486caf0,Input_Laye_2023-03-30_20-03-10/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name    </th><th>status    </th><th>loc                  </th><th style=\"text-align: right;\">  Batch Size</th><th>Combine Loss        </th><th>Input Filter        </th><th>Input Layer  </th><th style=\"text-align: right;\">  Learning Rate</th><th>Negative Mining  </th><th>Network             </th><th>Optimizer           </th><th>Pixel Loss        </th><th>Smooth Labeling  </th><th>Volume Loss     </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  Epoch</th><th style=\"text-align: right;\">      Loss</th><th style=\"text-align: right;\">  CrackIoU</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_31d2e73f</td><td>RUNNING   </td><td>141.223.108.122:10285</td><td style=\"text-align: right;\">           4</td><td>&lt;class &#x27;loss.lo_a1c0</td><td>&lt;function norma_caf0</td><td>FrangiFilter </td><td style=\"text-align: right;\">         0.0001</td><td>True             </td><td>&lt;class &#x27;models._65a0</td><td>&lt;class &#x27;torch.o_8dc0</td><td>CrossEntropyLoss()</td><td>False            </td><td>JaccardLoss     </td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         2413.91</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">0.0578106 </td><td style=\"text-align: right;\">  0.787604</td></tr>\n",
       "<tr><td>train_949b34b2</td><td>RUNNING   </td><td>141.223.108.122:7282 </td><td style=\"text-align: right;\">           4</td><td>&lt;class &#x27;loss.lo_ad00</td><td>&lt;function norma_caf0</td><td>FrangiFilter </td><td style=\"text-align: right;\">         0.0001</td><td>True             </td><td>&lt;class &#x27;models._65a0</td><td>&lt;class &#x27;torch.o_8dc0</td><td>CrossEntropyLoss()</td><td>False            </td><td>JaccardLoss     </td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         3549.08</td><td style=\"text-align: right;\">      7</td><td style=\"text-align: right;\">0.0936306 </td><td style=\"text-align: right;\">  0.815413</td></tr>\n",
       "<tr><td>train_ecb82977</td><td>PENDING   </td><td>                     </td><td style=\"text-align: right;\">           4</td><td>&lt;class &#x27;loss.lo_a1c0</td><td>&lt;function norma_caf0</td><td>FrangiFilter </td><td style=\"text-align: right;\">         0.0001</td><td>True             </td><td>&lt;class &#x27;models._65a0</td><td>&lt;class &#x27;torch.o_8dc0</td><td>CrossEntropyLoss()</td><td>False            </td><td>FocalTverskyLoss</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_004b8015</td><td>TERMINATED</td><td>141.223.108.122:7282 </td><td style=\"text-align: right;\">           4</td><td>&lt;class &#x27;loss.lo_a580</td><td>&lt;function norma_caf0</td><td>FrangiFilter </td><td style=\"text-align: right;\">         0.0001</td><td>False            </td><td>&lt;class &#x27;models._65a0</td><td>&lt;class &#x27;torch.o_8dc0</td><td>FocalLoss         </td><td>False            </td><td>JaccardLoss     </td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         3940.26</td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">0.0484727 </td><td style=\"text-align: right;\">  0.814925</td></tr>\n",
       "<tr><td>train_0118226b</td><td>TERMINATED</td><td>141.223.108.122:7282 </td><td style=\"text-align: right;\">           4</td><td>&lt;class &#x27;loss.lo_ad00</td><td>&lt;function norma_caf0</td><td>FrangiFilter </td><td style=\"text-align: right;\">         0.0001</td><td>True             </td><td>&lt;class &#x27;models._65a0</td><td>&lt;class &#x27;torch.o_8dc0</td><td>CrossEntropyLoss()</td><td>False            </td><td>JaccardLoss     </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         6563.1 </td><td style=\"text-align: right;\">     15</td><td style=\"text-align: right;\">0.0856395 </td><td style=\"text-align: right;\">  0.830985</td></tr>\n",
       "<tr><td>train_054146f9</td><td>TERMINATED</td><td>141.223.108.122:7282 </td><td style=\"text-align: right;\">           4</td><td>&lt;class &#x27;loss.lo_a940</td><td>&lt;function norma_caf0</td><td>FrangiFilter </td><td style=\"text-align: right;\">         0.0001</td><td>False            </td><td>&lt;class &#x27;models._65a0</td><td>&lt;class &#x27;torch.o_8dc0</td><td>FocalLoss         </td><td>True             </td><td>JaccardLoss     </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         1664.18</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">0.00136666</td><td style=\"text-align: right;\">  0.149483</td></tr>\n",
       "<tr><td>train_0e80ab08</td><td>TERMINATED</td><td>141.223.108.122:10285</td><td style=\"text-align: right;\">           4</td><td>&lt;class &#x27;loss.lo_a580</td><td>&lt;function norma_caf0</td><td>FrangiFilter </td><td style=\"text-align: right;\">         0.0001</td><td>False            </td><td>&lt;class &#x27;models._65a0</td><td>&lt;class &#x27;torch.o_8dc0</td><td>FocalLoss         </td><td>True             </td><td>FocalTverskyLoss</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         1669.55</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">0.0149577 </td><td style=\"text-align: right;\">  0.688651</td></tr>\n",
       "<tr><td>train_0fd7a8b9</td><td>TERMINATED</td><td>141.223.108.122:7282 </td><td style=\"text-align: right;\">           4</td><td>&lt;class &#x27;loss.lo_a580</td><td>&lt;function norma_caf0</td><td>FrangiFilter </td><td style=\"text-align: right;\">         0.0001</td><td>False            </td><td>&lt;class &#x27;models._65a0</td><td>&lt;class &#x27;torch.o_8dc0</td><td>FocalLoss         </td><td>False            </td><td>JaccardLoss     </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         6598.51</td><td style=\"text-align: right;\">     15</td><td style=\"text-align: right;\">0.0430094 </td><td style=\"text-align: right;\">  0.835704</td></tr>\n",
       "<tr><td>train_16db9183</td><td>TERMINATED</td><td>141.223.108.122:10285</td><td style=\"text-align: right;\">           4</td><td>&lt;class &#x27;loss.lo_ad00</td><td>&lt;function norma_caf0</td><td>FrangiFilter </td><td style=\"text-align: right;\">         0.0001</td><td>True             </td><td>&lt;class &#x27;models._65a0</td><td>&lt;class &#x27;torch.o_8dc0</td><td>FocalLoss         </td><td>True             </td><td>JaccardLoss     </td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         2407   </td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">0.113038  </td><td style=\"text-align: right;\">  0.777277</td></tr>\n",
       "<tr><td>train_187244da</td><td>TERMINATED</td><td>141.223.108.122:7282 </td><td style=\"text-align: right;\">           4</td><td>&lt;class &#x27;loss.lo_ad00</td><td>&lt;function norma_caf0</td><td>FrangiFilter </td><td style=\"text-align: right;\">         0.0001</td><td>False            </td><td>&lt;class &#x27;models._65a0</td><td>&lt;class &#x27;torch.o_8dc0</td><td>CrossEntropyLoss()</td><td>False            </td><td>JaccardLoss     </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         1660.46</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">0.145072  </td><td style=\"text-align: right;\">  0.714285</td></tr>\n",
       "<tr><td>train_2a8294b2</td><td>TERMINATED</td><td>141.223.108.122:7282 </td><td style=\"text-align: right;\">           4</td><td>&lt;class &#x27;loss.lo_a580</td><td>&lt;function norma_caf0</td><td>FrangiFilter </td><td style=\"text-align: right;\">         0.0001</td><td>False            </td><td>&lt;class &#x27;models._65a0</td><td>&lt;class &#x27;torch.o_8dc0</td><td>CrossEntropyLoss()</td><td>False            </td><td>FocalTverskyLoss</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         3963.63</td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">0.00598035</td><td style=\"text-align: right;\">  0.783736</td></tr>\n",
       "<tr><td>train_2bfea63b</td><td>TERMINATED</td><td>141.223.108.122:10285</td><td style=\"text-align: right;\">           4</td><td>&lt;class &#x27;loss.lo_a580</td><td>&lt;function norma_caf0</td><td>FrangiFilter </td><td style=\"text-align: right;\">         0.0001</td><td>False            </td><td>&lt;class &#x27;models._65a0</td><td>&lt;class &#x27;torch.o_8dc0</td><td>FocalLoss         </td><td>False            </td><td>JaccardLoss     </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         1662.87</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">0.0862087 </td><td style=\"text-align: right;\">  0.671459</td></tr>\n",
       "<tr><td>train_343807b2</td><td>TERMINATED</td><td>141.223.108.122:7195 </td><td style=\"text-align: right;\">           4</td><td>&lt;class &#x27;loss.lo_a1c0</td><td>&lt;function norma_caf0</td><td>FrangiFilter </td><td style=\"text-align: right;\">         0.0001</td><td>True             </td><td>&lt;class &#x27;models._65a0</td><td>&lt;class &#x27;torch.o_8dc0</td><td>FocalLoss         </td><td>False            </td><td>TverskyLoss     </td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         6525.63</td><td style=\"text-align: right;\">     15</td><td style=\"text-align: right;\">0.0430765 </td><td style=\"text-align: right;\">  0.822199</td></tr>\n",
       "<tr><td>train_4c977d26</td><td>TERMINATED</td><td>141.223.108.122:7282 </td><td style=\"text-align: right;\">           4</td><td>&lt;class &#x27;loss.lo_a580</td><td>&lt;function norma_caf0</td><td>FrangiFilter </td><td style=\"text-align: right;\">         0.0001</td><td>False            </td><td>&lt;class &#x27;models._65a0</td><td>&lt;class &#x27;torch.o_8dc0</td><td>CrossEntropyLoss()</td><td>False            </td><td>JaccardLoss     </td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         3929.35</td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">0.0475233 </td><td style=\"text-align: right;\">  0.819864</td></tr>\n",
       "<tr><td>train_4e39821a</td><td>TERMINATED</td><td>141.223.108.122:9421 </td><td style=\"text-align: right;\">           4</td><td>&lt;class &#x27;loss.lo_ad00</td><td>&lt;function norma_caf0</td><td>FrangiFilter </td><td style=\"text-align: right;\">         0.0001</td><td>True             </td><td>&lt;class &#x27;models._65a0</td><td>&lt;class &#x27;torch.o_8dc0</td><td>FocalLoss         </td><td>False            </td><td>FocalTverskyLoss</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         1633.15</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">0.0212413 </td><td style=\"text-align: right;\">  0.714477</td></tr>\n",
       "<tr><td>train_55e2e8e8</td><td>TERMINATED</td><td>141.223.108.122:7282 </td><td style=\"text-align: right;\">           4</td><td>&lt;class &#x27;loss.lo_a940</td><td>&lt;function norma_caf0</td><td>FrangiFilter </td><td style=\"text-align: right;\">         0.0001</td><td>False            </td><td>&lt;class &#x27;models._65a0</td><td>&lt;class &#x27;torch.o_8dc0</td><td>CrossEntropyLoss()</td><td>False            </td><td>JaccardLoss     </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         1665.08</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">0.00505586</td><td style=\"text-align: right;\">  0.632095</td></tr>\n",
       "<tr><td>train_68e2cdb4</td><td>TERMINATED</td><td>141.223.108.122:10285</td><td style=\"text-align: right;\">           4</td><td>&lt;class &#x27;loss.lo_a940</td><td>&lt;function norma_caf0</td><td>FrangiFilter </td><td style=\"text-align: right;\">         0.0001</td><td>False            </td><td>&lt;class &#x27;models._65a0</td><td>&lt;class &#x27;torch.o_8dc0</td><td>CrossEntropyLoss()</td><td>False            </td><td>JaccardLoss     </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         1658.63</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">0.00486476</td><td style=\"text-align: right;\">  0.609236</td></tr>\n",
       "<tr><td>train_68ed69df</td><td>TERMINATED</td><td>141.223.108.122:7282 </td><td style=\"text-align: right;\">           4</td><td>&lt;class &#x27;loss.lo_ad00</td><td>&lt;function norma_caf0</td><td>FrangiFilter </td><td style=\"text-align: right;\">         0.0001</td><td>False            </td><td>&lt;class &#x27;models._65a0</td><td>&lt;class &#x27;torch.o_8dc0</td><td>FocalLoss         </td><td>False            </td><td>FocalTverskyLoss</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         1655.31</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">0.0941496 </td><td style=\"text-align: right;\">  0.575081</td></tr>\n",
       "<tr><td>train_07e61d56</td><td>ERROR     </td><td>141.223.108.122:9421 </td><td style=\"text-align: right;\">           4</td><td>&lt;class &#x27;loss.lo_ad00</td><td>&lt;function norma_caf0</td><td>FrangiFilter </td><td style=\"text-align: right;\">         0.0001</td><td>True             </td><td>&lt;class &#x27;models._65a0</td><td>&lt;class &#x27;torch.o_8dc0</td><td>CrossEntropyLoss()</td><td>True             </td><td>JaccardLoss     </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_14b842ff</td><td>ERROR     </td><td>141.223.108.122:7195 </td><td style=\"text-align: right;\">           4</td><td>&lt;class &#x27;loss.lo_a940</td><td>&lt;function norma_caf0</td><td>FrangiFilter </td><td style=\"text-align: right;\">         0.0001</td><td>False            </td><td>&lt;class &#x27;models._65a0</td><td>&lt;class &#x27;torch.o_8dc0</td><td>CrossEntropyLoss()</td><td>True             </td><td>TverskyLoss     </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name    </th><th>CrackIoU           </th><th>Epoch  </th><th>Loss                 </th><th>MeanIoU           </th><th>Tversky            </th><th>date               </th><th>done  </th><th>episodes_total  </th><th>experiment_id                   </th><th>hostname           </th><th>iterations_since_restore  </th><th>node_ip        </th><th style=\"text-align: right;\">  pid</th><th>should_checkpoint  </th><th>time_since_restore  </th><th>time_this_iter_s  </th><th>time_total_s      </th><th style=\"text-align: right;\">  timestamp</th><th>timesteps_since_restore  </th><th>timesteps_total  </th><th>training_iteration  </th><th>trial_id  </th><th>warmup_time         </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_004b8015</td><td>0.8149253726005554 </td><td>8      </td><td>0.04847266152501106  </td><td>0.9061765074729919</td><td>0.8969734311103821 </td><td>2023-03-31_06-50-41</td><td>True  </td><td>                </td><td>5819102d969d4c45adca592705b26803</td><td>pirl-PowerEdge-T640</td><td>8                         </td><td>141.223.108.122</td><td style=\"text-align: right;\"> 7282</td><td>True               </td><td>3940.255780696869   </td><td>378.9906711578369 </td><td>3940.255780696869 </td><td style=\"text-align: right;\"> 1680213041</td><td>0                        </td><td>                 </td><td>8                   </td><td>004b8015  </td><td>0.029394149780273438</td></tr>\n",
       "<tr><td>train_0118226b</td><td>0.8309852480888367 </td><td>15     </td><td>0.08563954383134842  </td><td>0.914360523223877 </td><td>0.9103679060935974 </td><td>2023-03-30_22-32-44</td><td>True  </td><td>                </td><td>5819102d969d4c45adca592705b26803</td><td>pirl-PowerEdge-T640</td><td>15                        </td><td>141.223.108.122</td><td style=\"text-align: right;\"> 7282</td><td>True               </td><td>6563.101820707321   </td><td>376.9616069793701 </td><td>6563.101820707321 </td><td style=\"text-align: right;\"> 1680183164</td><td>0                        </td><td>                 </td><td>15                  </td><td>0118226b  </td><td>0.029394149780273438</td></tr>\n",
       "<tr><td>train_054146f9</td><td>0.1494825780391693 </td><td>2      </td><td>0.0013666617451235652</td><td>0.5473992824554443</td><td>0.3472917675971985 </td><td>2023-03-31_01-30-42</td><td>True  </td><td>                </td><td>5819102d969d4c45adca592705b26803</td><td>pirl-PowerEdge-T640</td><td>2                         </td><td>141.223.108.122</td><td style=\"text-align: right;\"> 7282</td><td>True               </td><td>1664.1846039295197  </td><td>376.4370427131653 </td><td>1664.1846039295197</td><td style=\"text-align: right;\"> 1680193842</td><td>0                        </td><td>                 </td><td>2                   </td><td>054146f9  </td><td>0.029394149780273438</td></tr>\n",
       "<tr><td>train_07e61d56</td><td>                   </td><td>       </td><td>                     </td><td>                  </td><td>                   </td><td>2023-03-30_20-03-10</td><td>      </td><td>                </td><td>2ffe0ec47f5f4fde8e8d9c9d2743e6cd</td><td>pirl-PowerEdge-T640</td><td>                          </td><td>141.223.108.122</td><td style=\"text-align: right;\"> 9421</td><td>                   </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1680174190</td><td>                         </td><td>                 </td><td>                    </td><td>07e61d56  </td><td>                    </td></tr>\n",
       "<tr><td>train_0e80ab08</td><td>0.6886513233184814 </td><td>2      </td><td>0.014957666397094727 </td><td>0.8417055606842041</td><td>0.8485428094863892 </td><td>2023-03-31_09-53-24</td><td>True  </td><td>                </td><td>e6779c8fb99c48058a301282b98ff3ad</td><td>pirl-PowerEdge-T640</td><td>2                         </td><td>141.223.108.122</td><td style=\"text-align: right;\">10285</td><td>True               </td><td>1669.5488002300262  </td><td>377.77550315856934</td><td>1669.5488002300262</td><td style=\"text-align: right;\"> 1680224004</td><td>0                        </td><td>                 </td><td>2                   </td><td>0e80ab08  </td><td>0.02836132049560547 </td></tr>\n",
       "<tr><td>train_0fd7a8b9</td><td>0.8357040286064148 </td><td>15     </td><td>0.04300940781831741  </td><td>0.9167305827140808</td><td>0.9111551642417908 </td><td>2023-03-31_01-02-57</td><td>True  </td><td>                </td><td>5819102d969d4c45adca592705b26803</td><td>pirl-PowerEdge-T640</td><td>15                        </td><td>141.223.108.122</td><td style=\"text-align: right;\"> 7282</td><td>True               </td><td>6598.506895065308   </td><td>379.2771954536438 </td><td>6598.506895065308 </td><td style=\"text-align: right;\"> 1680192177</td><td>0                        </td><td>                 </td><td>15                  </td><td>0fd7a8b9  </td><td>0.029394149780273438</td></tr>\n",
       "<tr><td>train_14b842ff</td><td>                   </td><td>       </td><td>                     </td><td>                  </td><td>                   </td><td>2023-03-30_19-08-08</td><td>      </td><td>                </td><td>da0098dce76d44e49c1ac93ef1bb1ab9</td><td>pirl-PowerEdge-T640</td><td>                          </td><td>141.223.108.122</td><td style=\"text-align: right;\"> 7195</td><td>                   </td><td>                    </td><td>                  </td><td>                  </td><td style=\"text-align: right;\"> 1680170888</td><td>                         </td><td>                 </td><td>                    </td><td>14b842ff  </td><td>                    </td></tr>\n",
       "<tr><td>train_16db9183</td><td>0.7772772908210754 </td><td>4      </td><td>0.11303821951150894  </td><td>0.886961817741394 </td><td>0.8845995664596558 </td><td>2023-03-30_23-28-08</td><td>True  </td><td>                </td><td>e6779c8fb99c48058a301282b98ff3ad</td><td>pirl-PowerEdge-T640</td><td>4                         </td><td>141.223.108.122</td><td style=\"text-align: right;\">10285</td><td>True               </td><td>2406.9950964450836  </td><td>374.84212136268616</td><td>2406.9950964450836</td><td style=\"text-align: right;\"> 1680186488</td><td>0                        </td><td>                 </td><td>4                   </td><td>16db9183  </td><td>0.02836132049560547 </td></tr>\n",
       "<tr><td>train_187244da</td><td>0.7142854928970337 </td><td>2      </td><td>0.14507193863391876  </td><td>0.8549280762672424</td><td>0.8289235830307007 </td><td>2023-03-31_01-58-22</td><td>True  </td><td>                </td><td>5819102d969d4c45adca592705b26803</td><td>pirl-PowerEdge-T640</td><td>2                         </td><td>141.223.108.122</td><td style=\"text-align: right;\"> 7282</td><td>True               </td><td>1660.4649925231934  </td><td>376.0921733379364 </td><td>1660.4649925231934</td><td style=\"text-align: right;\"> 1680195502</td><td>0                        </td><td>                 </td><td>2                   </td><td>187244da  </td><td>0.029394149780273438</td></tr>\n",
       "<tr><td>train_2a8294b2</td><td>0.7837362289428711 </td><td>8      </td><td>0.005980351474136114 </td><td>0.8901745676994324</td><td>0.9041333794593811 </td><td>2023-03-30_20-43-20</td><td>True  </td><td>                </td><td>5819102d969d4c45adca592705b26803</td><td>pirl-PowerEdge-T640</td><td>8                         </td><td>141.223.108.122</td><td style=\"text-align: right;\"> 7282</td><td>True               </td><td>3963.6314566135406  </td><td>378.3460123538971 </td><td>3963.6314566135406</td><td style=\"text-align: right;\"> 1680176600</td><td>0                        </td><td>                 </td><td>8                   </td><td>2a8294b2  </td><td>0.029394149780273438</td></tr>\n",
       "<tr><td>train_2bfea63b</td><td>0.6714587211608887 </td><td>2      </td><td>0.08620869368314743  </td><td>0.8332494497299194</td><td>0.7608201503753662 </td><td>2023-03-31_04-13-35</td><td>True  </td><td>                </td><td>e6779c8fb99c48058a301282b98ff3ad</td><td>pirl-PowerEdge-T640</td><td>2                         </td><td>141.223.108.122</td><td style=\"text-align: right;\">10285</td><td>True               </td><td>1662.8712093830109  </td><td>377.7589282989502 </td><td>1662.8712093830109</td><td style=\"text-align: right;\"> 1680203615</td><td>0                        </td><td>                 </td><td>2                   </td><td>2bfea63b  </td><td>0.02836132049560547 </td></tr>\n",
       "<tr><td>train_31d2e73f</td><td>0.787604033946991  </td><td>4      </td><td>0.057810574769973755 </td><td>0.8921676874160767</td><td>0.8828145265579224 </td><td>2023-03-31_11-41-24</td><td>False </td><td>                </td><td>e6779c8fb99c48058a301282b98ff3ad</td><td>pirl-PowerEdge-T640</td><td>4                         </td><td>141.223.108.122</td><td style=\"text-align: right;\">10285</td><td>True               </td><td>2413.907564163208   </td><td>376.00431776046753</td><td>2413.907564163208 </td><td style=\"text-align: right;\"> 1680230484</td><td>0                        </td><td>                 </td><td>4                   </td><td>31d2e73f  </td><td>0.02836132049560547 </td></tr>\n",
       "<tr><td>train_343807b2</td><td>0.8221988677978516 </td><td>15     </td><td>0.04307647794485092  </td><td>0.9098331332206726</td><td>0.9188856482505798 </td><td>2023-03-30_19-08-08</td><td>True  </td><td>                </td><td>da0098dce76d44e49c1ac93ef1bb1ab9</td><td>pirl-PowerEdge-T640</td><td>15                        </td><td>141.223.108.122</td><td style=\"text-align: right;\"> 7195</td><td>True               </td><td>6525.627532958984   </td><td>376.3289420604706 </td><td>6525.627532958984 </td><td style=\"text-align: right;\"> 1680170888</td><td>0                        </td><td>                 </td><td>15                  </td><td>343807b2  </td><td>0.027417659759521484</td></tr>\n",
       "<tr><td>train_4c977d26</td><td>0.8198637962341309 </td><td>8      </td><td>0.04752330854535103  </td><td>0.9087242484092712</td><td>0.8928359746932983 </td><td>2023-03-31_03-03-52</td><td>True  </td><td>                </td><td>5819102d969d4c45adca592705b26803</td><td>pirl-PowerEdge-T640</td><td>8                         </td><td>141.223.108.122</td><td style=\"text-align: right;\"> 7282</td><td>True               </td><td>3929.3530683517456  </td><td>377.75407791137695</td><td>3929.3530683517456</td><td style=\"text-align: right;\"> 1680199432</td><td>0                        </td><td>                 </td><td>8                   </td><td>4c977d26  </td><td>0.029394149780273438</td></tr>\n",
       "<tr><td>train_4e39821a</td><td>0.7144767642021179 </td><td>2      </td><td>0.0212413240224123   </td><td>0.8548089265823364</td><td>0.8669641613960266 </td><td>2023-03-30_19-35-34</td><td>True  </td><td>                </td><td>2ffe0ec47f5f4fde8e8d9c9d2743e6cd</td><td>pirl-PowerEdge-T640</td><td>2                         </td><td>141.223.108.122</td><td style=\"text-align: right;\"> 9421</td><td>True               </td><td>1633.1521487236023  </td><td>374.87849020957947</td><td>1633.1521487236023</td><td style=\"text-align: right;\"> 1680172534</td><td>0                        </td><td>                 </td><td>2                   </td><td>4e39821a  </td><td>0.03082442283630371 </td></tr>\n",
       "<tr><td>train_55e2e8e8</td><td>0.6320953965187073 </td><td>2      </td><td>0.005055857822299004 </td><td>0.8127942681312561</td><td>0.8038426637649536 </td><td>2023-03-31_05-45-01</td><td>True  </td><td>                </td><td>5819102d969d4c45adca592705b26803</td><td>pirl-PowerEdge-T640</td><td>2                         </td><td>141.223.108.122</td><td style=\"text-align: right;\"> 7282</td><td>True               </td><td>1665.0759255886078  </td><td>376.4891412258148 </td><td>1665.0759255886078</td><td style=\"text-align: right;\"> 1680209101</td><td>0                        </td><td>                 </td><td>2                   </td><td>55e2e8e8  </td><td>0.029394149780273438</td></tr>\n",
       "<tr><td>train_68e2cdb4</td><td>0.6092360019683838 </td><td>2      </td><td>0.00486476207152009  </td><td>0.8011082410812378</td><td>0.7935687303543091 </td><td>2023-03-31_07-39-48</td><td>True  </td><td>                </td><td>e6779c8fb99c48058a301282b98ff3ad</td><td>pirl-PowerEdge-T640</td><td>2                         </td><td>141.223.108.122</td><td style=\"text-align: right;\">10285</td><td>True               </td><td>1658.626418352127   </td><td>375.37705969810486</td><td>1658.626418352127 </td><td style=\"text-align: right;\"> 1680215988</td><td>0                        </td><td>                 </td><td>2                   </td><td>68e2cdb4  </td><td>0.02836132049560547 </td></tr>\n",
       "<tr><td>train_68ed69df</td><td>0.575081467628479  </td><td>2      </td><td>0.09414959698915482  </td><td>0.7839265465736389</td><td>0.7208554148674011 </td><td>2023-03-30_17-47-01</td><td>True  </td><td>                </td><td>5819102d969d4c45adca592705b26803</td><td>pirl-PowerEdge-T640</td><td>2                         </td><td>141.223.108.122</td><td style=\"text-align: right;\"> 7282</td><td>True               </td><td>1655.3061563968658  </td><td>377.09298276901245</td><td>1655.3061563968658</td><td style=\"text-align: right;\"> 1680166021</td><td>0                        </td><td>                 </td><td>2                   </td><td>68ed69df  </td><td>0.029394149780273438</td></tr>\n",
       "<tr><td>train_7ce82b04</td><td>0.7223928570747375 </td><td>2      </td><td>0.1356637328863144   </td><td>0.858864963054657 </td><td>0.8643362522125244 </td><td>2023-03-31_08-51-44</td><td>True  </td><td>                </td><td>5819102d969d4c45adca592705b26803</td><td>pirl-PowerEdge-T640</td><td>2                         </td><td>141.223.108.122</td><td style=\"text-align: right;\"> 7282</td><td>True               </td><td>1662.1919813156128  </td><td>377.2135691642761 </td><td>1662.1919813156128</td><td style=\"text-align: right;\"> 1680220304</td><td>0                        </td><td>                 </td><td>2                   </td><td>7ce82b04  </td><td>0.029394149780273438</td></tr>\n",
       "<tr><td>train_7ea21053</td><td>0.6941176056861877 </td><td>2      </td><td>0.07465916126966476  </td><td>0.8446032404899597</td><td>0.8591793179512024 </td><td>2023-03-31_02-00-09</td><td>True  </td><td>                </td><td>e6779c8fb99c48058a301282b98ff3ad</td><td>pirl-PowerEdge-T640</td><td>2                         </td><td>141.223.108.122</td><td style=\"text-align: right;\">10285</td><td>True               </td><td>1668.405591726303   </td><td>376.8328266143799 </td><td>1668.405591726303 </td><td style=\"text-align: right;\"> 1680195609</td><td>0                        </td><td>                 </td><td>2                   </td><td>7ea21053  </td><td>0.02836132049560547 </td></tr>\n",
       "<tr><td>train_8260cfd4</td><td>0.763597846031189  </td><td>4      </td><td>0.011370634660124779 </td><td>0.8799777030944824</td><td>0.8745256662368774 </td><td>2023-03-31_00-36-41</td><td>True  </td><td>                </td><td>e6779c8fb99c48058a301282b98ff3ad</td><td>pirl-PowerEdge-T640</td><td>4                         </td><td>141.223.108.122</td><td style=\"text-align: right;\">10285</td><td>True               </td><td>2425.6247119903564  </td><td>376.92164874076843</td><td>2425.6247119903564</td><td style=\"text-align: right;\"> 1680190601</td><td>0                        </td><td>                 </td><td>4                   </td><td>8260cfd4  </td><td>0.02836132049560547 </td></tr>\n",
       "<tr><td>train_8675ea8b</td><td>0.8185409903526306 </td><td>8      </td><td>0.04727514833211899  </td><td>0.9079962372779846</td><td>0.9075835943222046 </td><td>2023-03-31_03-05-35</td><td>True  </td><td>                </td><td>e6779c8fb99c48058a301282b98ff3ad</td><td>pirl-PowerEdge-T640</td><td>8                         </td><td>141.223.108.122</td><td style=\"text-align: right;\">10285</td><td>True               </td><td>3926.0955471992493  </td><td>377.2528464794159 </td><td>3926.0955471992493</td><td style=\"text-align: right;\"> 1680199535</td><td>0                        </td><td>                 </td><td>8                   </td><td>8675ea8b  </td><td>0.02836132049560547 </td></tr>\n",
       "<tr><td>train_87ab3701</td><td>0.5981666445732117 </td><td>2      </td><td>0.005254207644611597 </td><td>0.7953638434410095</td><td>0.7798758149147034 </td><td>2023-03-30_20-03-10</td><td>True  </td><td>                </td><td>2ffe0ec47f5f4fde8e8d9c9d2743e6cd</td><td>pirl-PowerEdge-T640</td><td>2                         </td><td>141.223.108.122</td><td style=\"text-align: right;\"> 9421</td><td>True               </td><td>1656.2638974189758  </td><td>374.6360557079315 </td><td>1656.2638974189758</td><td style=\"text-align: right;\"> 1680174190</td><td>0                        </td><td>                 </td><td>2                   </td><td>87ab3701  </td><td>0.03082442283630371 </td></tr>\n",
       "<tr><td>train_8959b4af</td><td>0.8318685293197632 </td><td>15     </td><td>0.045237645506858826 </td><td>0.9148000478744507</td><td>0.9106979370117188 </td><td>2023-03-30_22-20-17</td><td>True  </td><td>                </td><td>e6779c8fb99c48058a301282b98ff3ad</td><td>pirl-PowerEdge-T640</td><td>15                        </td><td>141.223.108.122</td><td style=\"text-align: right;\">10285</td><td>True               </td><td>6524.790434122086   </td><td>375.28529596328735</td><td>6524.790434122086 </td><td style=\"text-align: right;\"> 1680182417</td><td>0                        </td><td>                 </td><td>15                  </td><td>8959b4af  </td><td>0.02836132049560547 </td></tr>\n",
       "<tr><td>train_8c874e07</td><td>0.8373875617980957 </td><td>15     </td><td>0.08240749686956406  </td><td>0.9175925254821777</td><td>0.9130924940109253 </td><td>2023-03-30_19-37-17</td><td>True  </td><td>                </td><td>5819102d969d4c45adca592705b26803</td><td>pirl-PowerEdge-T640</td><td>15                        </td><td>141.223.108.122</td><td style=\"text-align: right;\"> 7282</td><td>True               </td><td>6615.27449131012    </td><td>376.43051862716675</td><td>6615.27449131012  </td><td style=\"text-align: right;\"> 1680172637</td><td>0                        </td><td>                 </td><td>15                  </td><td>8c874e07  </td><td>0.029394149780273438</td></tr>\n",
       "<tr><td>train_8ecc108d</td><td>0.8360844254493713 </td><td>15     </td><td>0.04421690106391907  </td><td>0.9169202446937561</td><td>0.912609338760376  </td><td>2023-03-31_10-41-19</td><td>True  </td><td>                </td><td>5819102d969d4c45adca592705b26803</td><td>pirl-PowerEdge-T640</td><td>15                        </td><td>141.223.108.122</td><td style=\"text-align: right;\"> 7282</td><td>True               </td><td>6575.08900976181    </td><td>377.76953506469727</td><td>6575.08900976181  </td><td style=\"text-align: right;\"> 1680226879</td><td>0                        </td><td>                 </td><td>15                  </td><td>8ecc108d  </td><td>0.029394149780273438</td></tr>\n",
       "<tr><td>train_8ed80317</td><td>0.1578768938779831 </td><td>2      </td><td>0.0012162313796579838</td><td>0.5542327761650085</td><td>0.3572293519973755 </td><td>2023-03-31_11-01-10</td><td>True  </td><td>                </td><td>e6779c8fb99c48058a301282b98ff3ad</td><td>pirl-PowerEdge-T640</td><td>2                         </td><td>141.223.108.122</td><td style=\"text-align: right;\">10285</td><td>True               </td><td>1663.479943037033   </td><td>375.6106538772583 </td><td>1663.479943037033 </td><td style=\"text-align: right;\"> 1680228070</td><td>0                        </td><td>                 </td><td>2                   </td><td>8ed80317  </td><td>0.02836132049560547 </td></tr>\n",
       "<tr><td>train_949b34b2</td><td>0.8154132962226868 </td><td>7      </td><td>0.0936305969953537   </td><td>0.9063693881034851</td><td>0.9019612669944763 </td><td>2023-03-31_11-40-29</td><td>False </td><td>                </td><td>5819102d969d4c45adca592705b26803</td><td>pirl-PowerEdge-T640</td><td>7                         </td><td>141.223.108.122</td><td style=\"text-align: right;\"> 7282</td><td>True               </td><td>3549.0816197395325  </td><td>376.99439787864685</td><td>3549.0816197395325</td><td style=\"text-align: right;\"> 1680230429</td><td>0                        </td><td>                 </td><td>7                   </td><td>949b34b2  </td><td>0.029394149780273438</td></tr>\n",
       "<tr><td>train_9a1876c9</td><td>0.6851114630699158 </td><td>2      </td><td>0.015877740457654    </td><td>0.8397456407546997</td><td>0.8519434332847595 </td><td>2023-03-31_06-44-30</td><td>True  </td><td>                </td><td>e6779c8fb99c48058a301282b98ff3ad</td><td>pirl-PowerEdge-T640</td><td>2                         </td><td>141.223.108.122</td><td style=\"text-align: right;\">10285</td><td>True               </td><td>1662.627682685852   </td><td>375.92143082618713</td><td>1662.627682685852 </td><td style=\"text-align: right;\"> 1680212670</td><td>0                        </td><td>                 </td><td>2                   </td><td>9a1876c9  </td><td>0.02836132049560547 </td></tr>\n",
       "<tr><td>train_9d63211f</td><td>0.6978746056556702 </td><td>2      </td><td>0.07133575528860092  </td><td>0.8464475274085999</td><td>0.8593680262565613 </td><td>2023-03-31_07-18-33</td><td>True  </td><td>                </td><td>5819102d969d4c45adca592705b26803</td><td>pirl-PowerEdge-T640</td><td>2                         </td><td>141.223.108.122</td><td style=\"text-align: right;\"> 7282</td><td>True               </td><td>1671.5967042446136  </td><td>378.81687927246094</td><td>1671.5967042446136</td><td style=\"text-align: right;\"> 1680214713</td><td>0                        </td><td>                 </td><td>2                   </td><td>9d63211f  </td><td>0.029394149780273438</td></tr>\n",
       "<tr><td>train_a416c238</td><td>0.6658744215965271 </td><td>2      </td><td>0.016311055049300194 </td><td>0.8299525380134583</td><td>0.83977210521698   </td><td>2023-03-30_22-48-01</td><td>True  </td><td>                </td><td>e6779c8fb99c48058a301282b98ff3ad</td><td>pirl-PowerEdge-T640</td><td>2                         </td><td>141.223.108.122</td><td style=\"text-align: right;\">10285</td><td>True               </td><td>1663.8498923778534  </td><td>377.66155886650085</td><td>1663.8498923778534</td><td style=\"text-align: right;\"> 1680184081</td><td>0                        </td><td>                 </td><td>2                   </td><td>a416c238  </td><td>0.02836132049560547 </td></tr>\n",
       "<tr><td>train_a5786bd1</td><td>0.8070783615112305 </td><td>8      </td><td>0.05108931288123131  </td><td>0.9022093415260315</td><td>0.8880574703216553 </td><td>2023-03-31_09-25-34</td><td>True  </td><td>                </td><td>e6779c8fb99c48058a301282b98ff3ad</td><td>pirl-PowerEdge-T640</td><td>8                         </td><td>141.223.108.122</td><td style=\"text-align: right;\">10285</td><td>True               </td><td>3938.4618911743164  </td><td>378.12200260162354</td><td>3938.4618911743164</td><td style=\"text-align: right;\"> 1680222334</td><td>0                        </td><td>                 </td><td>8                   </td><td>a5786bd1  </td><td>0.02836132049560547 </td></tr>\n",
       "<tr><td>train_a6746817</td><td>0.7720444798469543 </td><td>4      </td><td>0.11570175737142563  </td><td>0.8842982649803162</td><td>0.874661922454834  </td><td>2023-03-30_23-12-59</td><td>True  </td><td>                </td><td>5819102d969d4c45adca592705b26803</td><td>pirl-PowerEdge-T640</td><td>4                         </td><td>141.223.108.122</td><td style=\"text-align: right;\"> 7282</td><td>True               </td><td>2414.942488193512   </td><td>376.9751591682434 </td><td>2414.942488193512 </td><td style=\"text-align: right;\"> 1680185579</td><td>0                        </td><td>                 </td><td>4                   </td><td>a6746817  </td><td>0.029394149780273438</td></tr>\n",
       "<tr><td>train_b13fb3cc</td><td>0.7772560715675354 </td><td>4      </td><td>0.053103115409612656 </td><td>0.8868982195854187</td><td>0.8957003355026245 </td><td>2023-03-31_05-21-31</td><td>True  </td><td>                </td><td>e6779c8fb99c48058a301282b98ff3ad</td><td>pirl-PowerEdge-T640</td><td>4                         </td><td>141.223.108.122</td><td style=\"text-align: right;\">10285</td><td>True               </td><td>2418.38649892807    </td><td>378.4495644569397 </td><td>2418.38649892807  </td><td style=\"text-align: right;\"> 1680207691</td><td>0                        </td><td>                 </td><td>4                   </td><td>b13fb3cc  </td><td>0.02836132049560547 </td></tr>\n",
       "<tr><td>train_b390ab06</td><td>0.7343450784683228 </td><td>4      </td><td>0.012806774117052555 </td><td>0.8650621175765991</td><td>0.8746405839920044 </td><td>2023-03-31_08-19-55</td><td>True  </td><td>                </td><td>e6779c8fb99c48058a301282b98ff3ad</td><td>pirl-PowerEdge-T640</td><td>4                         </td><td>141.223.108.122</td><td style=\"text-align: right;\">10285</td><td>True               </td><td>2407.1189584732056  </td><td>375.57886576652527</td><td>2407.1189584732056</td><td style=\"text-align: right;\"> 1680218395</td><td>0                        </td><td>                 </td><td>4                   </td><td>b390ab06  </td><td>0.02836132049560547 </td></tr>\n",
       "<tr><td>train_b8818218</td><td>0.16407513618469238</td><td>2      </td><td>0.0012173671275377274</td><td>0.5562024712562561</td><td>0.37294110655784607</td><td>2023-03-31_01-32-21</td><td>True  </td><td>                </td><td>e6779c8fb99c48058a301282b98ff3ad</td><td>pirl-PowerEdge-T640</td><td>2                         </td><td>141.223.108.122</td><td style=\"text-align: right;\">10285</td><td>True               </td><td>1664.915067911148   </td><td>375.4865446090698 </td><td>1664.915067911148 </td><td style=\"text-align: right;\"> 1680193941</td><td>0                        </td><td>                 </td><td>2                   </td><td>b8818218  </td><td>0.02836132049560547 </td></tr>\n",
       "<tr><td>train_b8d01c54</td><td>0.8069605231285095 </td><td>8      </td><td>0.09785687178373337  </td><td>0.902143120765686 </td><td>0.8879157900810242 </td><td>2023-03-31_08-24-02</td><td>True  </td><td>                </td><td>5819102d969d4c45adca592705b26803</td><td>pirl-PowerEdge-T640</td><td>8                         </td><td>141.223.108.122</td><td style=\"text-align: right;\"> 7282</td><td>True               </td><td>3928.8631722927094  </td><td>376.2244827747345 </td><td>3928.8631722927094</td><td style=\"text-align: right;\"> 1680218642</td><td>0                        </td><td>                 </td><td>8                   </td><td>b8d01c54  </td><td>0.029394149780273438</td></tr>\n",
       "<tr><td>train_b97a1e1a</td><td>0.7264735698699951 </td><td>2      </td><td>0.014511051587760448 </td><td>0.861104428768158 </td><td>0.8598887324333191 </td><td>2023-03-31_01-04-36</td><td>True  </td><td>                </td><td>e6779c8fb99c48058a301282b98ff3ad</td><td>pirl-PowerEdge-T640</td><td>2                         </td><td>141.223.108.122</td><td style=\"text-align: right;\">10285</td><td>True               </td><td>1674.2260687351227  </td><td>376.4967658519745 </td><td>1674.2260687351227</td><td style=\"text-align: right;\"> 1680192276</td><td>0                        </td><td>                 </td><td>2                   </td><td>b97a1e1a  </td><td>0.02836132049560547 </td></tr>\n",
       "<tr><td>train_d886bc7b</td><td>0.7098749876022339 </td><td>2      </td><td>0.14374308288097382  </td><td>0.8525078892707825</td><td>0.856256902217865  </td><td>2023-03-31_06-16-47</td><td>True  </td><td>                </td><td>e6779c8fb99c48058a301282b98ff3ad</td><td>pirl-PowerEdge-T640</td><td>2                         </td><td>141.223.108.122</td><td style=\"text-align: right;\">10285</td><td>True               </td><td>1657.158507823944   </td><td>374.55138993263245</td><td>1657.158507823944 </td><td style=\"text-align: right;\"> 1680211007</td><td>0                        </td><td>                 </td><td>2                   </td><td>d886bc7b  </td><td>0.02836132049560547 </td></tr>\n",
       "<tr><td>train_da38132a</td><td>0.4467886984348297 </td><td>2      </td><td>0.2806567847728729   </td><td>0.7193432450294495</td><td>0.5359287261962891 </td><td>2023-03-31_05-49-10</td><td>True  </td><td>                </td><td>e6779c8fb99c48058a301282b98ff3ad</td><td>pirl-PowerEdge-T640</td><td>2                         </td><td>141.223.108.122</td><td style=\"text-align: right;\">10285</td><td>True               </td><td>1659.315803527832   </td><td>375.86750411987305</td><td>1659.315803527832 </td><td style=\"text-align: right;\"> 1680209350</td><td>0                        </td><td>                 </td><td>2                   </td><td>da38132a  </td><td>0.02836132049560547 </td></tr>\n",
       "<tr><td>train_e0015b4d</td><td>0.7748361229896545 </td><td>4      </td><td>0.11437243223190308  </td><td>0.8856275677680969</td><td>0.888757050037384  </td><td>2023-03-31_10-33-27</td><td>True  </td><td>                </td><td>e6779c8fb99c48058a301282b98ff3ad</td><td>pirl-PowerEdge-T640</td><td>4                         </td><td>141.223.108.122</td><td style=\"text-align: right;\">10285</td><td>True               </td><td>2403.0993313789368  </td><td>375.45690631866455</td><td>2403.0993313789368</td><td style=\"text-align: right;\"> 1680226407</td><td>0                        </td><td>                 </td><td>4                   </td><td>e0015b4d  </td><td>0.02836132049560547 </td></tr>\n",
       "<tr><td>train_e924c416</td><td>0.7264735102653503 </td><td>2      </td><td>0.13897331058979034  </td><td>0.8610267043113708</td><td>0.8633352518081665 </td><td>2023-03-31_04-41-12</td><td>True  </td><td>                </td><td>e6779c8fb99c48058a301282b98ff3ad</td><td>pirl-PowerEdge-T640</td><td>2                         </td><td>141.223.108.122</td><td style=\"text-align: right;\">10285</td><td>True               </td><td>1657.1941049098969  </td><td>375.18742656707764</td><td>1657.1941049098969</td><td style=\"text-align: right;\"> 1680205272</td><td>0                        </td><td>                 </td><td>2                   </td><td>e924c416  </td><td>0.02836132049560547 </td></tr>\n",
       "<tr><td>train_e9cd4294</td><td>0.5193895697593689 </td><td>2      </td><td>0.0059274532832205296</td><td>0.7540574669837952</td><td>0.7459704279899597 </td><td>2023-03-31_04-12-00</td><td>True  </td><td>                </td><td>5819102d969d4c45adca592705b26803</td><td>pirl-PowerEdge-T640</td><td>2                         </td><td>141.223.108.122</td><td style=\"text-align: right;\"> 7282</td><td>True               </td><td>1665.9892930984497  </td><td>376.6651039123535 </td><td>1665.9892930984497</td><td style=\"text-align: right;\"> 1680203520</td><td>0                        </td><td>                 </td><td>2                   </td><td>e9cd4294  </td><td>0.029394149780273438</td></tr>\n",
       "<tr><td>train_f03ddff5</td><td>0.8113347887992859 </td><td>8      </td><td>0.0956718772649765   </td><td>0.9043281078338623</td><td>0.8915044069290161 </td><td>2023-03-31_05-17-16</td><td>True  </td><td>                </td><td>5819102d969d4c45adca592705b26803</td><td>pirl-PowerEdge-T640</td><td>8                         </td><td>141.223.108.122</td><td style=\"text-align: right;\"> 7282</td><td>True               </td><td>3915.8682341575623  </td><td>375.6423752307892 </td><td>3915.8682341575623</td><td style=\"text-align: right;\"> 1680207436</td><td>0                        </td><td>                 </td><td>8                   </td><td>f03ddff5  </td><td>0.029394149780273438</td></tr>\n",
       "<tr><td>train_f0c498eb</td><td>0.7831945419311523 </td><td>4      </td><td>0.057060353457927704 </td><td>0.8899702429771423</td><td>0.8684922456741333 </td><td>2023-03-31_03-45-52</td><td>True  </td><td>                </td><td>e6779c8fb99c48058a301282b98ff3ad</td><td>pirl-PowerEdge-T640</td><td>4                         </td><td>141.223.108.122</td><td style=\"text-align: right;\">10285</td><td>True               </td><td>2416.3391678333282  </td><td>377.0330231189728 </td><td>2416.3391678333282</td><td style=\"text-align: right;\"> 1680201952</td><td>0                        </td><td>                 </td><td>4                   </td><td>f0c498eb  </td><td>0.02836132049560547 </td></tr>\n",
       "<tr><td>train_f8c58cd6</td><td>0.7772334814071655 </td><td>4      </td><td>0.05872584879398346  </td><td>0.8870123028755188</td><td>0.8654355406761169 </td><td>2023-03-31_03-44-14</td><td>True  </td><td>                </td><td>5819102d969d4c45adca592705b26803</td><td>pirl-PowerEdge-T640</td><td>4                         </td><td>141.223.108.122</td><td style=\"text-align: right;\"> 7282</td><td>True               </td><td>2421.8005921840668  </td><td>378.6011874675751 </td><td>2421.8005921840668</td><td style=\"text-align: right;\"> 1680201854</td><td>0                        </td><td>                 </td><td>4                   </td><td>f8c58cd6  </td><td>0.029394149780273438</td></tr>\n",
       "<tr><td>train_fa36b496</td><td>0.7225600481033325 </td><td>2      </td><td>0.1492619812488556   </td><td>0.8591326475143433</td><td>0.850737988948822  </td><td>2023-03-30_23-56-15</td><td>True  </td><td>                </td><td>e6779c8fb99c48058a301282b98ff3ad</td><td>pirl-PowerEdge-T640</td><td>2                         </td><td>141.223.108.122</td><td style=\"text-align: right;\">10285</td><td>True               </td><td>1687.5992276668549  </td><td>374.76674461364746</td><td>1687.5992276668549</td><td style=\"text-align: right;\"> 1680188175</td><td>0                        </td><td>                 </td><td>2                   </td><td>fa36b496  </td><td>0.02836132049560547 </td></tr>\n",
       "<tr><td>train_fad4c240</td><td>0.6979496479034424 </td><td>2      </td><td>0.07495993375778198  </td><td>0.8464440703392029</td><td>0.8590084910392761 </td><td>2023-03-30_20-31-32</td><td>True  </td><td>                </td><td>e6779c8fb99c48058a301282b98ff3ad</td><td>pirl-PowerEdge-T640</td><td>2                         </td><td>141.223.108.122</td><td style=\"text-align: right;\">10285</td><td>True               </td><td>1689.0711653232574  </td><td>376.2331039905548 </td><td>1689.0711653232574</td><td style=\"text-align: right;\"> 1680175892</td><td>0                        </td><td>                 </td><td>2                   </td><td>fad4c240  </td><td>0.02836132049560547 </td></tr>\n",
       "<tr><td>train_fb773cf3</td><td>0.6744893789291382 </td><td>2      </td><td>0.02678549475967884  </td><td>0.8342719674110413</td><td>0.8507806658744812 </td><td>2023-03-31_07-12-09</td><td>True  </td><td>                </td><td>e6779c8fb99c48058a301282b98ff3ad</td><td>pirl-PowerEdge-T640</td><td>2                         </td><td>141.223.108.122</td><td style=\"text-align: right;\">10285</td><td>True               </td><td>1659.3337688446045  </td><td>375.6478068828583 </td><td>1659.3337688446045</td><td style=\"text-align: right;\"> 1680214329</td><td>0                        </td><td>                 </td><td>2                   </td><td>fb773cf3  </td><td>0.02836132049560547 </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-30 17:47:01,883\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Combine Loss': <class 'loss.loss.VolumeLoss'>, 'Input Filter': <function normalize at 0x7fe27486caf0>, 'Input Layer': FrangiFilter, 'Network': <class 'models.unet.UNet'>, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Pixel Loss': FocalLoss, 'Volume Loss': FocalTverskyLoss}\n",
      "2023-03-30 19:08:08,456\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Combine Loss': <class 'loss.loss.CombinedLoss'>, 'Input Filter': <function normalize at 0x7fe27486caf0>, 'Input Layer': FrangiFilter, 'Network': <class 'models.unet.UNet'>, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Pixel Loss': FocalLoss, 'Volume Loss': TverskyLoss}\n",
      "2023-03-30 19:08:17,036\tERROR trial_runner.py:1062 -- Trial train_14b842ff: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=7195, ip=141.223.108.122, repr=train)\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_3660/2909120779.py\", line 17, in train\n",
      "  File \"/home/pirl/POC-Project/src/dataset/POC_dataset.py\", line 147, in precompute_transform\n",
      "    mask = self.target_transform(mask)\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/torchvision/transforms/transforms.py\", line 1799, in forward\n",
      "    return F.gaussian_blur(img, self.kernel_size, [sigma, sigma])\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/torchvision/transforms/functional.py\", line 1366, in gaussian_blur\n",
      "    output = F_t.gaussian_blur(t_img, kernel_size, sigma)\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/torchvision/transforms/functional_tensor.py\", line 755, in gaussian_blur\n",
      "    kernel = _get_gaussian_kernel2d(kernel_size, sigma, dtype=dtype, device=img.device)\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/torchvision/transforms/functional_tensor.py\", line 744, in _get_gaussian_kernel2d\n",
      "    kernel2d = torch.mm(kernel1d_y[:, None], kernel1d_x[None, :])\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`\n",
      "2023-03-30 19:35:34,369\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Combine Loss': <class 'loss.loss.VolumeLoss'>, 'Input Filter': <function normalize at 0x7fe27486caf0>, 'Input Layer': FrangiFilter, 'Network': <class 'models.unet.UNet'>, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Pixel Loss': FocalLoss, 'Volume Loss': FocalTverskyLoss}\n",
      "2023-03-30 19:37:17,271\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Combine Loss': <class 'loss.loss.VolumeLoss'>, 'Input Filter': <function normalize at 0x7fe27486caf0>, 'Input Layer': FrangiFilter, 'Network': <class 'models.unet.UNet'>, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Pixel Loss': CrossEntropyLoss(), 'Volume Loss': JaccardLoss}\n",
      "2023-03-30 20:03:10,735\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Combine Loss': <class 'loss.loss.PixelLoss'>, 'Input Filter': <function normalize at 0x7fe27486caf0>, 'Input Layer': FrangiFilter, 'Network': <class 'models.unet.UNet'>, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Pixel Loss': CrossEntropyLoss(), 'Volume Loss': TverskyLoss}\n",
      "2023-03-30 20:03:19,040\tERROR trial_runner.py:1062 -- Trial train_07e61d56: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=9421, ip=141.223.108.122, repr=train)\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_3660/2909120779.py\", line 17, in train\n",
      "  File \"/home/pirl/POC-Project/src/dataset/POC_dataset.py\", line 147, in precompute_transform\n",
      "    mask = self.target_transform(mask)\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/torchvision/transforms/transforms.py\", line 1799, in forward\n",
      "    return F.gaussian_blur(img, self.kernel_size, [sigma, sigma])\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/torchvision/transforms/functional.py\", line 1366, in gaussian_blur\n",
      "    output = F_t.gaussian_blur(t_img, kernel_size, sigma)\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/torchvision/transforms/functional_tensor.py\", line 755, in gaussian_blur\n",
      "    kernel = _get_gaussian_kernel2d(kernel_size, sigma, dtype=dtype, device=img.device)\n",
      "  File \"/home/pirl/anaconda3/envs/POC-env/lib/python3.10/site-packages/torchvision/transforms/functional_tensor.py\", line 744, in _get_gaussian_kernel2d\n",
      "    kernel2d = torch.mm(kernel1d_y[:, None], kernel1d_x[None, :])\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`\n",
      "2023-03-30 20:31:32,368\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Combine Loss': <class 'loss.loss.CombinedLoss'>, 'Input Filter': <function normalize at 0x7fe27486caf0>, 'Input Layer': FrangiFilter, 'Network': <class 'models.unet.UNet'>, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Pixel Loss': FocalLoss, 'Volume Loss': TverskyLoss}\n",
      "2023-03-30 20:43:21,014\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Combine Loss': <class 'loss.loss.BorderedLoss'>, 'Input Filter': <function normalize at 0x7fe27486caf0>, 'Input Layer': FrangiFilter, 'Network': <class 'models.unet.UNet'>, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Pixel Loss': CrossEntropyLoss(), 'Volume Loss': FocalTverskyLoss}\n",
      "2023-03-30 22:20:17,256\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Combine Loss': <class 'loss.loss.CombinedLoss'>, 'Input Filter': <function normalize at 0x7fe27486caf0>, 'Input Layer': FrangiFilter, 'Network': <class 'models.unet.UNet'>, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Pixel Loss': CrossEntropyLoss(), 'Volume Loss': JaccardLoss}\n",
      "2023-03-30 22:32:44,223\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Combine Loss': <class 'loss.loss.VolumeLoss'>, 'Input Filter': <function normalize at 0x7fe27486caf0>, 'Input Layer': FrangiFilter, 'Network': <class 'models.unet.UNet'>, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Pixel Loss': CrossEntropyLoss(), 'Volume Loss': JaccardLoss}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-30 22:48:01,218\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Combine Loss': <class 'loss.loss.BorderedLoss'>, 'Input Filter': <function normalize at 0x7fe27486caf0>, 'Input Layer': FrangiFilter, 'Network': <class 'models.unet.UNet'>, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Pixel Loss': CrossEntropyLoss(), 'Volume Loss': FocalTverskyLoss}\n",
      "2023-03-30 23:12:59,273\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Combine Loss': <class 'loss.loss.VolumeLoss'>, 'Input Filter': <function normalize at 0x7fe27486caf0>, 'Input Layer': FrangiFilter, 'Network': <class 'models.unet.UNet'>, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Pixel Loss': FocalLoss, 'Volume Loss': JaccardLoss}\n",
      "2023-03-30 23:28:08,314\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Combine Loss': <class 'loss.loss.VolumeLoss'>, 'Input Filter': <function normalize at 0x7fe27486caf0>, 'Input Layer': FrangiFilter, 'Network': <class 'models.unet.UNet'>, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Pixel Loss': FocalLoss, 'Volume Loss': JaccardLoss}\n",
      "2023-03-30 23:56:16,022\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Combine Loss': <class 'loss.loss.VolumeLoss'>, 'Input Filter': <function normalize at 0x7fe27486caf0>, 'Input Layer': FrangiFilter, 'Network': <class 'models.unet.UNet'>, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Pixel Loss': CrossEntropyLoss(), 'Volume Loss': TverskyLoss}\n",
      "2023-03-31 00:36:41,749\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Combine Loss': <class 'loss.loss.BorderedLoss'>, 'Input Filter': <function normalize at 0x7fe27486caf0>, 'Input Layer': FrangiFilter, 'Network': <class 'models.unet.UNet'>, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Pixel Loss': CrossEntropyLoss(), 'Volume Loss': FocalTverskyLoss}\n",
      "2023-03-31 01:02:57,885\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Combine Loss': <class 'loss.loss.BorderedLoss'>, 'Input Filter': <function normalize at 0x7fe27486caf0>, 'Input Layer': FrangiFilter, 'Network': <class 'models.unet.UNet'>, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Pixel Loss': FocalLoss, 'Volume Loss': JaccardLoss}\n",
      "2023-03-31 01:04:36,083\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Combine Loss': <class 'loss.loss.CombinedLoss'>, 'Input Filter': <function normalize at 0x7fe27486caf0>, 'Input Layer': FrangiFilter, 'Network': <class 'models.unet.UNet'>, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Pixel Loss': FocalLoss, 'Volume Loss': FocalTverskyLoss}\n",
      "2023-03-31 01:30:42,180\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Combine Loss': <class 'loss.loss.PixelLoss'>, 'Input Filter': <function normalize at 0x7fe27486caf0>, 'Input Layer': FrangiFilter, 'Network': <class 'models.unet.UNet'>, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Pixel Loss': FocalLoss, 'Volume Loss': JaccardLoss}\n",
      "2023-03-31 01:32:21,102\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Combine Loss': <class 'loss.loss.PixelLoss'>, 'Input Filter': <function normalize at 0x7fe27486caf0>, 'Input Layer': FrangiFilter, 'Network': <class 'models.unet.UNet'>, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Pixel Loss': FocalLoss, 'Volume Loss': JaccardLoss}\n",
      "2023-03-31 01:58:22,753\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Combine Loss': <class 'loss.loss.VolumeLoss'>, 'Input Filter': <function normalize at 0x7fe27486caf0>, 'Input Layer': FrangiFilter, 'Network': <class 'models.unet.UNet'>, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Pixel Loss': CrossEntropyLoss(), 'Volume Loss': JaccardLoss}\n",
      "2023-03-31 02:00:09,616\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Combine Loss': <class 'loss.loss.CombinedLoss'>, 'Input Filter': <function normalize at 0x7fe27486caf0>, 'Input Layer': FrangiFilter, 'Network': <class 'models.unet.UNet'>, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Pixel Loss': FocalLoss, 'Volume Loss': TverskyLoss}\n",
      "2023-03-31 03:03:52,308\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Combine Loss': <class 'loss.loss.BorderedLoss'>, 'Input Filter': <function normalize at 0x7fe27486caf0>, 'Input Layer': FrangiFilter, 'Network': <class 'models.unet.UNet'>, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Pixel Loss': CrossEntropyLoss(), 'Volume Loss': JaccardLoss}\n",
      "2023-03-31 03:05:35,827\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Combine Loss': <class 'loss.loss.BorderedLoss'>, 'Input Filter': <function normalize at 0x7fe27486caf0>, 'Input Layer': FrangiFilter, 'Network': <class 'models.unet.UNet'>, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Pixel Loss': CrossEntropyLoss(), 'Volume Loss': JaccardLoss}\n",
      "2023-03-31 03:44:14,225\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Combine Loss': <class 'loss.loss.BorderedLoss'>, 'Input Filter': <function normalize at 0x7fe27486caf0>, 'Input Layer': FrangiFilter, 'Network': <class 'models.unet.UNet'>, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Pixel Loss': FocalLoss, 'Volume Loss': JaccardLoss}\n",
      "2023-03-31 03:45:52,273\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Combine Loss': <class 'loss.loss.BorderedLoss'>, 'Input Filter': <function normalize at 0x7fe27486caf0>, 'Input Layer': FrangiFilter, 'Network': <class 'models.unet.UNet'>, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Pixel Loss': CrossEntropyLoss(), 'Volume Loss': JaccardLoss}\n",
      "2023-03-31 04:12:00,320\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Combine Loss': <class 'loss.loss.PixelLoss'>, 'Input Filter': <function normalize at 0x7fe27486caf0>, 'Input Layer': FrangiFilter, 'Network': <class 'models.unet.UNet'>, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Pixel Loss': CrossEntropyLoss(), 'Volume Loss': JaccardLoss}\n",
      "2023-03-31 04:13:35,253\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Combine Loss': <class 'loss.loss.BorderedLoss'>, 'Input Filter': <function normalize at 0x7fe27486caf0>, 'Input Layer': FrangiFilter, 'Network': <class 'models.unet.UNet'>, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Pixel Loss': FocalLoss, 'Volume Loss': JaccardLoss}\n",
      "2023-03-31 04:41:12,549\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Combine Loss': <class 'loss.loss.VolumeLoss'>, 'Input Filter': <function normalize at 0x7fe27486caf0>, 'Input Layer': FrangiFilter, 'Network': <class 'models.unet.UNet'>, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Pixel Loss': FocalLoss, 'Volume Loss': JaccardLoss}\n",
      "2023-03-31 05:17:16,297\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Combine Loss': <class 'loss.loss.VolumeLoss'>, 'Input Filter': <function normalize at 0x7fe27486caf0>, 'Input Layer': FrangiFilter, 'Network': <class 'models.unet.UNet'>, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Pixel Loss': CrossEntropyLoss(), 'Volume Loss': JaccardLoss}\n",
      "2023-03-31 05:21:31,043\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Combine Loss': <class 'loss.loss.BorderedLoss'>, 'Input Filter': <function normalize at 0x7fe27486caf0>, 'Input Layer': FrangiFilter, 'Network': <class 'models.unet.UNet'>, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Pixel Loss': FocalLoss, 'Volume Loss': TverskyLoss}\n",
      "2023-03-31 05:45:01,479\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Combine Loss': <class 'loss.loss.PixelLoss'>, 'Input Filter': <function normalize at 0x7fe27486caf0>, 'Input Layer': FrangiFilter, 'Network': <class 'models.unet.UNet'>, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Pixel Loss': CrossEntropyLoss(), 'Volume Loss': JaccardLoss}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-31 05:49:10,466\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Combine Loss': <class 'loss.loss.VolumeLoss'>, 'Input Filter': <function normalize at 0x7fe27486caf0>, 'Input Layer': FrangiFilter, 'Network': <class 'models.unet.UNet'>, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Pixel Loss': FocalLoss, 'Volume Loss': JaccardLoss}\n",
      "2023-03-31 06:16:47,730\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Combine Loss': <class 'loss.loss.VolumeLoss'>, 'Input Filter': <function normalize at 0x7fe27486caf0>, 'Input Layer': FrangiFilter, 'Network': <class 'models.unet.UNet'>, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Pixel Loss': CrossEntropyLoss(), 'Volume Loss': TverskyLoss}\n",
      "2023-03-31 06:44:30,468\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Combine Loss': <class 'loss.loss.CombinedLoss'>, 'Input Filter': <function normalize at 0x7fe27486caf0>, 'Input Layer': FrangiFilter, 'Network': <class 'models.unet.UNet'>, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Pixel Loss': FocalLoss, 'Volume Loss': FocalTverskyLoss}\n",
      "2023-03-31 06:50:41,840\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Combine Loss': <class 'loss.loss.BorderedLoss'>, 'Input Filter': <function normalize at 0x7fe27486caf0>, 'Input Layer': FrangiFilter, 'Network': <class 'models.unet.UNet'>, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Pixel Loss': FocalLoss, 'Volume Loss': JaccardLoss}\n",
      "2023-03-31 07:12:09,915\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Combine Loss': <class 'loss.loss.VolumeLoss'>, 'Input Filter': <function normalize at 0x7fe27486caf0>, 'Input Layer': FrangiFilter, 'Network': <class 'models.unet.UNet'>, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Pixel Loss': CrossEntropyLoss(), 'Volume Loss': FocalTverskyLoss}\n",
      "2023-03-31 07:18:33,544\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Combine Loss': <class 'loss.loss.BorderedLoss'>, 'Input Filter': <function normalize at 0x7fe27486caf0>, 'Input Layer': FrangiFilter, 'Network': <class 'models.unet.UNet'>, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Pixel Loss': FocalLoss, 'Volume Loss': TverskyLoss}\n",
      "2023-03-31 07:39:48,651\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Combine Loss': <class 'loss.loss.PixelLoss'>, 'Input Filter': <function normalize at 0x7fe27486caf0>, 'Input Layer': FrangiFilter, 'Network': <class 'models.unet.UNet'>, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Pixel Loss': CrossEntropyLoss(), 'Volume Loss': JaccardLoss}\n",
      "2023-03-31 08:19:55,872\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Combine Loss': <class 'loss.loss.CombinedLoss'>, 'Input Filter': <function normalize at 0x7fe27486caf0>, 'Input Layer': FrangiFilter, 'Network': <class 'models.unet.UNet'>, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Pixel Loss': CrossEntropyLoss(), 'Volume Loss': FocalTverskyLoss}\n",
      "2023-03-31 08:24:02,513\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Combine Loss': <class 'loss.loss.VolumeLoss'>, 'Input Filter': <function normalize at 0x7fe27486caf0>, 'Input Layer': FrangiFilter, 'Network': <class 'models.unet.UNet'>, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Pixel Loss': FocalLoss, 'Volume Loss': JaccardLoss}\n",
      "2023-03-31 08:51:44,817\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Combine Loss': <class 'loss.loss.VolumeLoss'>, 'Input Filter': <function normalize at 0x7fe27486caf0>, 'Input Layer': FrangiFilter, 'Network': <class 'models.unet.UNet'>, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Pixel Loss': CrossEntropyLoss(), 'Volume Loss': TverskyLoss}\n",
      "2023-03-31 09:25:34,440\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Combine Loss': <class 'loss.loss.BorderedLoss'>, 'Input Filter': <function normalize at 0x7fe27486caf0>, 'Input Layer': FrangiFilter, 'Network': <class 'models.unet.UNet'>, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Pixel Loss': FocalLoss, 'Volume Loss': JaccardLoss}\n",
      "2023-03-31 09:53:24,099\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Combine Loss': <class 'loss.loss.BorderedLoss'>, 'Input Filter': <function normalize at 0x7fe27486caf0>, 'Input Layer': FrangiFilter, 'Network': <class 'models.unet.UNet'>, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Pixel Loss': FocalLoss, 'Volume Loss': FocalTverskyLoss}\n",
      "2023-03-31 10:33:27,309\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Combine Loss': <class 'loss.loss.VolumeLoss'>, 'Input Filter': <function normalize at 0x7fe27486caf0>, 'Input Layer': FrangiFilter, 'Network': <class 'models.unet.UNet'>, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Pixel Loss': CrossEntropyLoss(), 'Volume Loss': JaccardLoss}\n",
      "2023-03-31 10:41:20,016\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Combine Loss': <class 'loss.loss.CombinedLoss'>, 'Input Filter': <function normalize at 0x7fe27486caf0>, 'Input Layer': FrangiFilter, 'Network': <class 'models.unet.UNet'>, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Pixel Loss': CrossEntropyLoss(), 'Volume Loss': JaccardLoss}\n",
      "2023-03-31 11:01:10,898\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Combine Loss': <class 'loss.loss.PixelLoss'>, 'Input Filter': <function normalize at 0x7fe27486caf0>, 'Input Layer': FrangiFilter, 'Network': <class 'models.unet.UNet'>, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Pixel Loss': FocalLoss, 'Volume Loss': TverskyLoss}\n"
     ]
    }
   ],
   "source": [
    "results = tuner.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08aabe4",
   "metadata": {},
   "source": [
    "# Evaluating the best Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa2da49",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-30T08:17:54.627Z"
    }
   },
   "outputs": [],
   "source": [
    "best_result = results.get_best_result(metric=\"CrackIoU\", mode=\"max\", scope=\"all\")  # Get best result object\n",
    "print(\"Best trial config: {}\".format(best_result.config))\n",
    "print(\"Best trial final validation loss: {}\".format(best_result.metrics[\"Loss\"]))\n",
    "print(\"Best trial final validation CrackIoU: {}\".format(best_result.metrics[\"CrackIoU\"]))\n",
    "\n",
    "for result in results:\n",
    "    evaluate(test_data=test_data, result=result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8633d3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d599c84a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "POC-env",
   "language": "python",
   "name": "poc-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122.844,
   "position": {
    "height": "40px",
    "left": "1576px",
    "right": "20px",
    "top": "120px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
