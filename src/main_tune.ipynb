{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25a1ac32",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Setting-up-imports\" data-toc-modified-id=\"Setting-up-imports-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Setting up imports</a></span></li><li><span><a href=\"#Setting-up-Constant-Hyperparameters\" data-toc-modified-id=\"Setting-up-Constant-Hyperparameters-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Setting up Constant Hyperparameters</a></span></li><li><span><a href=\"#Setting-up-Parameters-and-Functions-for-Training\" data-toc-modified-id=\"Setting-up-Parameters-and-Functions-for-Training-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Setting up Parameters and Functions for Training</a></span><ul class=\"toc-item\"><li><span><a href=\"#Hyperparameters-Search-Space\" data-toc-modified-id=\"Hyperparameters-Search-Space-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Hyperparameters Search Space</a></span></li><li><span><a href=\"#Creating-the-training-function\" data-toc-modified-id=\"Creating-the-training-function-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Creating the training function</a></span></li><li><span><a href=\"#Creating-the-evaluation-function\" data-toc-modified-id=\"Creating-the-evaluation-function-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Creating the evaluation function</a></span></li></ul></li><li><span><a href=\"#Running-the-training\" data-toc-modified-id=\"Running-the-training-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Running the training</a></span><ul class=\"toc-item\"><li><span><a href=\"#Loading-data-for-training\" data-toc-modified-id=\"Loading-data-for-training-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Loading data for training</a></span></li><li><span><a href=\"#Configuring-the-Tuner-with-a-Scheduler-and-a-Search-Algorithm\" data-toc-modified-id=\"Configuring-the-Tuner-with-a-Scheduler-and-a-Search-Algorithm-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Configuring the Tuner with a Scheduler and a Search Algorithm</a></span></li><li><span><a href=\"#Running-the-Tuner\" data-toc-modified-id=\"Running-the-Tuner-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Running the Tuner</a></span></li></ul></li><li><span><a href=\"#Evaluating-the-best-Results\" data-toc-modified-id=\"Evaluating-the-best-Results-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Evaluating the best Results</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035da606",
   "metadata": {},
   "source": [
    "# Setting up imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af16e0d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T03:33:00.835531Z",
     "start_time": "2023-04-07T03:32:58.228195Z"
    },
    "cell_style": "center",
    "init_cell": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from itertools import product\n",
    "\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss, Sequential\n",
    "from torch.nn.functional import normalize\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import CenterCrop, Resize, GaussianBlur\n",
    "# from torchvision.transforms.functional import invert\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.air import session, RunConfig, CheckpointConfig\n",
    "from ray.air.checkpoint import Checkpoint\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "# from ray.tune.search.hyperopt import HyperOptSearch\n",
    "# from ray.tune.search.optuna import OptunaSearch\n",
    "# from ray.tune.search import ConcurrencyLimiter\n",
    "\n",
    "\n",
    "from dataset import POCDataReader, data_augment_, POCDataset\n",
    "from metrics import Metrics, EvaluationMetrics\n",
    "from models import UNet\n",
    "from loss import *\n",
    "from pipelines import InputPipeline, SequenceFilters, SumFilters\n",
    "from pipelines.filters import *\n",
    "from train import training_loop, validation_loop\n",
    "from train_tqdm import evaluation_loop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9951dd",
   "metadata": {},
   "source": [
    "# Setting up Constant Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "beb97ae7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T03:33:00.840936Z",
     "start_time": "2023-04-07T03:33:00.837933Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "NUM_SAMPLES = 1\n",
    "\n",
    "NUM_AUGMENT = 1\n",
    "\n",
    "LOAD_DATA_ON_GPU = False\n",
    "GPUS_PER_TRIAL = 1\n",
    "CPUS_PER_TRIAL = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d48f809",
   "metadata": {},
   "source": [
    "##### Selecting Cuda device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd6be70b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T03:33:00.934571Z",
     "start_time": "2023-04-07T03:33:00.842536Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9687c3e3",
   "metadata": {},
   "source": [
    "# Setting up Parameters and Functions for Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215c221d",
   "metadata": {},
   "source": [
    "## Hyperparameters Search Space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d931716",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### Preload Losses Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28766a0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T03:33:00.982724Z",
     "start_time": "2023-04-07T03:33:00.939079Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pixel_loss_list = [\n",
    "    CrossEntropyLoss(weight=torch.tensor([.3, .7])),\n",
    "    FocalLoss(weight=torch.tensor([.3, .7]), gamma=2),\n",
    "]\n",
    "\n",
    "volume_loss_list = [\n",
    "    JaccardLoss(),\n",
    "    TverskyLoss(alpha=0.3, beta=0.7),\n",
    "    FocalTverskyLoss(alpha=0.3, beta=0.7, gamma=2),\n",
    "]\n",
    "\n",
    "loss_list = []\n",
    "for ploss in pixel_loss_list:\n",
    "    loss_list.append(PixelLoss(pixel_loss=ploss, volume_loss=None))\n",
    "for vloss in volume_loss_list:\n",
    "    loss_list.append(VolumeLoss(pixel_loss=None, volume_loss=vloss))\n",
    "for (ploss, vloss) in product(pixel_loss_list, volume_loss_list):\n",
    "    loss_list.append(CombinedLoss(loss1=ploss, loss2=vloss, ratio=0.3))\n",
    "    loss_list.append(BorderedLoss(border_loss=ploss, volume_loss=vloss, ratio=0.7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9939e19b",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### Preload Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e663e37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T03:33:01.019437Z",
     "start_time": "2023-04-07T03:33:00.985947Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "filter_list = [normalize] #, invert]\n",
    "\n",
    "layer_list = [\n",
    "    SobelFilter(),\n",
    "    LaplacianFilter(),\n",
    "    FrangiFilter(),\n",
    "    SatoFilter(),\n",
    "    SumFilters(FrangiFilter(), SatoFilter()),\n",
    "    SkeletonFilter(SequenceFilters(SumFilters(FrangiFilter(), SatoFilter()), CrackBinaryFilter())),\n",
    "]\n",
    "\n",
    "pipeline_list = []\n",
    "for f, l in product(filter_list, layer_list):\n",
    "    pipeline_list.append(InputPipeline(transformer=f, layer_transformer=l))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d95e76",
   "metadata": {},
   "source": [
    "##### Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1e136d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T03:33:01.047379Z",
     "start_time": "2023-04-07T03:33:01.022288Z"
    },
    "code_folding": [],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    \"Network\": UNet, #tune.grid_search([Unet, DeepCrack, SubUNet]),\n",
    "    \"Optimizer\": Adam,\n",
    "\n",
    "    \"Learning Rate\": 1e-4, #tune.loguniform(1e-6, 1e-4),\n",
    "    \"Batch Size\": 4,           #tune.qrandint(2, 8, 2),\n",
    "\n",
    "    \"Loss Function\": tune.grid_search(loss_list),\n",
    "\n",
    "    \"Negative Mining\": True, #tune.choice([True, False]),\n",
    "    \"Smooth Labeling\": False, #tune.choice([True, False]),\n",
    "\n",
    "    \"Input Pipeline\": tune.grid_search(pipeline_list),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc521e6",
   "metadata": {},
   "source": [
    "## Creating the training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "626acb32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T03:33:01.079911Z",
     "start_time": "2023-04-07T03:33:01.050666Z"
    },
    "code_folding": [
     0
    ],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def train(config, train_data, val_data):\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    inpip = config[\"Input Pipeline\"]\n",
    "    if LOAD_DATA_ON_GPU:\n",
    "        inpip = inpip.to(device)\n",
    "\n",
    "    train_dataset = POCDataset(\n",
    "        train_data,\n",
    "        transform=Sequential(inpip, CenterCrop(size=(480, 480)), Resize(size=(400, 400))),\n",
    "        target_transform= Sequential(\n",
    "            GaussianBlur(kernel_size=3, sigma=0.7),\n",
    "            CenterCrop(size=(480, 480)),\n",
    "            Resize(size=(400, 400)),\n",
    "        ) if config[\"Smooth Labeling\"] else Sequential(\n",
    "            CenterCrop(size=(480, 480)),\n",
    "            Resize(size=(400, 400)),\n",
    "        ),\n",
    "        negative_mining=config[\"Negative Mining\"],\n",
    "        load_on_gpu=LOAD_DATA_ON_GPU)\n",
    "    train_dataset.precompute_transform()\n",
    "\n",
    "    if LOAD_DATA_ON_GPU:\n",
    "        training_dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=int(config[\"Batch Size\"]),\n",
    "            sampler=train_dataset.sampler,\n",
    "            shuffle= True if train_dataset.sampler is None else None,\n",
    "        )\n",
    "    else:\n",
    "        training_dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=int(config[\"Batch Size\"]),\n",
    "            sampler=train_dataset.sampler,\n",
    "            shuffle= True if train_dataset.sampler is None else None,\n",
    "            num_workers=CPUS_PER_TRIAL//2,\n",
    "            pin_memory=True,\n",
    "            pin_memory_device=device)\n",
    "\n",
    "    val_dataset = POCDataset(\n",
    "        val_data, \n",
    "        transform=Sequential(inpip, CenterCrop(size=(480, 480)), Resize(size=(400, 400))),\n",
    "        target_transform=Sequential(CenterCrop(size=(480, 480)), Resize(size=(400, 400))),\n",
    "        negative_mining=False,\n",
    "        load_on_gpu=LOAD_DATA_ON_GPU)\n",
    "    val_dataset.precompute_transform()\n",
    "    \n",
    "    if LOAD_DATA_ON_GPU:\n",
    "        validation_dataloader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=int(config[\"Batch Size\"]),\n",
    "            shuffle=True)\n",
    "    else:\n",
    "        validation_dataloader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=int(config[\"Batch Size\"]),\n",
    "            shuffle=True,\n",
    "            num_workers=CPUS_PER_TRIAL//2,\n",
    "            pin_memory=True,\n",
    "            pin_memory_device=device)\n",
    "\n",
    "    model = config[\"Network\"](n_channels=inpip.nb_channel, n_classes=2)\n",
    "    if torch.cuda.is_available() and torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "\n",
    "    loss_fn = config[\"Loss Function\"].to(device)\n",
    "    optimizer = config[\"Optimizer\"](model.parameters(), lr=config[\"Learning Rate\"], betas=(0.9, 0.99))\n",
    "    lr_scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "\n",
    "    loaded_checkpoint = session.get_checkpoint()\n",
    "    if loaded_checkpoint:\n",
    "        with loaded_checkpoint.as_directory() as loaded_checkpoint_dir:\n",
    "            model_state, optimizer_state, scheduler_state = torch.load(os.path.join(loaded_checkpoint_dir, \"checkpoint.pt\"))\n",
    "        model.load_state_dict(model_state)\n",
    "        optimizer.load_state_dict(optimizer_state)\n",
    "        lr_scheduler.load_state_dict(scheduler_state)\n",
    "\n",
    "    train_metrics = Metrics(\n",
    "        buffer_size=len(training_dataloader),\n",
    "        mode=\"Training\",\n",
    "        hyperparam=config,\n",
    "        device=device)\n",
    "\n",
    "    val_metrics = Metrics(\n",
    "        buffer_size=len(validation_dataloader),\n",
    "        mode=\"Validation\",\n",
    "        hyperparam=config,\n",
    "        device=device)\n",
    "\n",
    "\n",
    "    for epoch in range(1, EPOCHS+1):  # loop over the dataset multiple times\n",
    "        training_loop(epoch, training_dataloader, model, loss_fn, optimizer, lr_scheduler, train_metrics, device)\n",
    "        validation_loop(epoch, validation_dataloader, model, loss_fn, val_metrics, device)\n",
    "\n",
    "        # Here we save a checkpoint. It is automatically registered with\n",
    "        # Ray Tune and can be accessed through `session.get_checkpoint()`\n",
    "        # API in future iterations.\n",
    "        os.makedirs(\"model\", exist_ok=True)\n",
    "        torch.save((model.state_dict(), optimizer.state_dict(), lr_scheduler.state_dict()), \"model/checkpoint.pt\")\n",
    "        checkpoint = Checkpoint.from_directory(\"model\")\n",
    "        session.report(metrics=val_metrics.get_metrics(epoch), checkpoint=checkpoint)\n",
    "\n",
    "    train_metrics.close_tensorboard()\n",
    "    val_metrics.close_tensorboard()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8a58ec",
   "metadata": {},
   "source": [
    "## Creating the evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da4d17c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T03:33:01.130721Z",
     "start_time": "2023-04-07T03:33:01.082412Z"
    },
    "code_folding": [
     0
    ],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def evaluate(test_data, result):\n",
    "\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    inpip = config[\"Input Pipeline\"]\n",
    "    if LOAD_DATA_ON_GPU:\n",
    "        inpip = inpip.to(device)\n",
    "\n",
    "    test_dataset = POCDataset(\n",
    "        test_data,\n",
    "        transform=Sequential(inpip, CenterCrop(size=(480, 480)), Resize(size=(400, 400))),\n",
    "        target_transform=Sequential(CenterCrop(size=(480, 480)), Resize(size=(400, 400))),\n",
    "        negative_mining=False,\n",
    "        load_on_gpu=LOAD_DATA_ON_GPU)\n",
    "    \n",
    "    if LOAD_DATA_ON_GPU:\n",
    "        evaluation_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "    else:\n",
    "        evaluation_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=True, num_workers=2*CPUS_PER_TRIAL, pin_memory=True, pin_memory_device=device)\n",
    "\n",
    "    best_trained_model = result.config[\"Network\"](n_channels=inpip.nb_channel, n_classes=2, bilinear=True, crop=False).to(device)\n",
    "\n",
    "    checkpoint_path = os.path.join(result.checkpoint.to_directory(), \"checkpoint.pt\")\n",
    "    model_state, _, _ = torch.load(checkpoint_path)\n",
    "    best_trained_model.load_state_dict(model_state)\n",
    "\n",
    "    test_metrics = EvaluationMetrics(\n",
    "        buffer_size=len(evaluation_dataloader),\n",
    "        hyperparam=result.config,\n",
    "        epochs=result.metrics[\"Epoch\"],\n",
    "        device=device)\n",
    "\n",
    "    evaluation_loop(dataloader=evaluation_dataloader, model=best_trained_model, metric=test_metrics, device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918e1c03",
   "metadata": {},
   "source": [
    "# Running the training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f955b19",
   "metadata": {},
   "source": [
    "## Loading data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e15a7a2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T03:33:56.534592Z",
     "start_time": "2023-04-07T03:33:01.134226Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "505492a459e947169e590ccd55ec7501",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset into RAM:   0%|          | 0/2744 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t- Loading done, RAM used: 5.40GiB / free: 34.27GiB / total: 62.73GiB\n",
      "\t- Got a total of 2744 images.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b82850778364a14ab33a5e6b9d5215b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Expending the dataset 1 more times:   0%|          | 0/1920 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t- Augmentation done, RAM used: 8.16GiB / free: 31.51GiB / total: 62.73GiB\n",
      "\t- Got 1920 new images and a total of 3840 images.\n"
     ]
    }
   ],
   "source": [
    "data_reader = POCDataReader(root_dir=\"../data/POC\", load_on_gpu=False, verbose=True)\n",
    "train_data, val_data, test_data = data_reader.split([0.7, 0.1, 0.2])\n",
    "data_augment_(train_data, n=NUM_AUGMENT, load_on_gpu=False, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025b0faa",
   "metadata": {},
   "source": [
    "## Configuring the Tuner with a Scheduler and a Search Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a69701ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T03:34:02.391135Z",
     "start_time": "2023-04-07T03:33:56.540156Z"
    }
   },
   "outputs": [],
   "source": [
    "# scheduler = ASHAScheduler(max_t=EPOCHS, grace_period=2, reduction_factor=2)\n",
    "# search_algo = HyperOptSearch()\n",
    "# search_algo = OptunaSearch()\n",
    "\n",
    "tune_config = tune.TuneConfig(\n",
    "    metric=\"CrackIoU\",\n",
    "    mode=\"max\",\n",
    "    num_samples=NUM_SAMPLES,\n",
    "#     scheduler=scheduler,\n",
    "#     search_alg=search_algo,\n",
    ")\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    tune.with_resources(\n",
    "        tune.with_parameters(train, train_data=train_data, val_data=val_data),\n",
    "        resources={\"cpu\": CPUS_PER_TRIAL, \"gpu\": GPUS_PER_TRIAL}),\n",
    "    tune_config=tune_config,\n",
    "    param_space=search_space,\n",
    "    run_config=RunConfig(\n",
    "        local_dir=\"~/Documents/POC-Project/ray_results\",\n",
    "        checkpoint_config=CheckpointConfig(\n",
    "            num_to_keep=1,\n",
    "            checkpoint_score_attribute=\"CrackIoU\",\n",
    "            checkpoint_score_order=\"max\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0913de",
   "metadata": {},
   "source": [
    "## Running the Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdfb3720",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T16:42:59.038833Z",
     "start_time": "2023-04-07T03:34:02.393582Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-07 12:34:05,842\tINFO worker.py:1544 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-04-10 01:42:58</td></tr>\n",
       "<tr><td>Running for: </td><td>2 days, 13:08:43.35</td></tr>\n",
       "<tr><td>Memory:      </td><td>28.9/62.7 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/2 GPUs, 0.0/27.62 GiB heap, 0.0/13.81 GiB objects (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  \n",
       "  \n",
       "  Number of errored trials: 45<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                                                                             </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_12206_00057</td><td style=\"text-align: right;\">           1</td><td>/home/piai/Documents/POC-Project/ray_results/train_2023-04-07_12-33-56/train_12206_00057_57_Input_Pipeline=InputPipeline_normalize_SatoFilter,Loss_Function=CombinedLoss_CrossEntropyLoss_FocalTverskyLos_2023-04-09_19-05-22/error.txt</td></tr>\n",
       "<tr><td>train_12206_00058</td><td style=\"text-align: right;\">           1</td><td>/home/piai/Documents/POC-Project/ray_results/train_2023-04-07_12-33-56/train_12206_00058_58_Input_Pipeline=InputPipeline_normalize_SumFilters_FrangiFilter_SatoFilter,Loss_Function=CombinedLoss_CrossEnt_2023-04-09_19-59-08/error.txt</td></tr>\n",
       "<tr><td>train_12206_00059</td><td style=\"text-align: right;\">           1</td><td>/home/piai/Documents/POC-Project/ray_results/train_2023-04-07_12-33-56/train_12206_00059_59_Input_Pipeline=InputPipeline_normalize_SkeletonFilter,Loss_Function=CombinedLoss_CrossEntropyLoss_FocalTversk_2023-04-09_19-59-30/error.txt</td></tr>\n",
       "<tr><td>train_12206_00060</td><td style=\"text-align: right;\">           1</td><td>/home/piai/Documents/POC-Project/ray_results/train_2023-04-07_12-33-56/train_12206_00060_60_Input_Pipeline=InputPipeline_normalize_SobelFilter,Loss_Function=BorderedLoss_CrossEntropyLoss_FocalTverskyLo_2023-04-09_19-59-30/error.txt</td></tr>\n",
       "<tr><td>train_12206_00061</td><td style=\"text-align: right;\">           1</td><td>/home/piai/Documents/POC-Project/ray_results/train_2023-04-07_12-33-56/train_12206_00061_61_Input_Pipeline=InputPipeline_normalize_LaplacianFilter,Loss_Function=BorderedLoss_CrossEntropyLoss_FocalTvers_2023-04-09_20-01-34/error.txt</td></tr>\n",
       "<tr><td>train_12206_00062</td><td style=\"text-align: right;\">           1</td><td>/home/piai/Documents/POC-Project/ray_results/train_2023-04-07_12-33-56/train_12206_00062_62_Input_Pipeline=InputPipeline_normalize_FrangiFilter,Loss_Function=BorderedLoss_CrossEntropyLoss_FocalTverskyL_2023-04-09_20-05-59/error.txt</td></tr>\n",
       "<tr><td>train_12206_00063</td><td style=\"text-align: right;\">           1</td><td>/home/piai/Documents/POC-Project/ray_results/train_2023-04-07_12-33-56/train_12206_00063_63_Input_Pipeline=InputPipeline_normalize_SatoFilter,Loss_Function=BorderedLoss_CrossEntropyLoss_FocalTverskyLos_2023-04-09_20-21-39/error.txt</td></tr>\n",
       "<tr><td>train_12206_00064</td><td style=\"text-align: right;\">           1</td><td>/home/piai/Documents/POC-Project/ray_results/train_2023-04-07_12-33-56/train_12206_00064_64_Input_Pipeline=InputPipeline_normalize_SumFilters_FrangiFilter_SatoFilter,Loss_Function=BorderedLoss_CrossEnt_2023-04-09_20-30-15/error.txt</td></tr>\n",
       "<tr><td>train_12206_00065</td><td style=\"text-align: right;\">           1</td><td>/home/piai/Documents/POC-Project/ray_results/train_2023-04-07_12-33-56/train_12206_00065_65_Input_Pipeline=InputPipeline_normalize_SkeletonFilter,Loss_Function=BorderedLoss_CrossEntropyLoss_FocalTversk_2023-04-09_20-34-16/error.txt</td></tr>\n",
       "<tr><td>train_12206_00066</td><td style=\"text-align: right;\">           1</td><td>/home/piai/Documents/POC-Project/ray_results/train_2023-04-07_12-33-56/train_12206_00066_66_Input_Pipeline=InputPipeline_normalize_SobelFilter,Loss_Function=CombinedLoss_FocalLoss_JaccardLoss_2023-04-09_20-57-11/error.txt          </td></tr>\n",
       "<tr><td>train_12206_00067</td><td style=\"text-align: right;\">           1</td><td>/home/piai/Documents/POC-Project/ray_results/train_2023-04-07_12-33-56/train_12206_00067_67_Input_Pipeline=InputPipeline_normalize_LaplacianFilter,Loss_Function=CombinedLoss_FocalLoss_JaccardLoss_2023-04-09_20-59-40/error.txt      </td></tr>\n",
       "<tr><td>train_12206_00068</td><td style=\"text-align: right;\">           1</td><td>/home/piai/Documents/POC-Project/ray_results/train_2023-04-07_12-33-56/train_12206_00068_68_Input_Pipeline=InputPipeline_normalize_FrangiFilter,Loss_Function=CombinedLoss_FocalLoss_JaccardLoss_2023-04-09_21-04-16/error.txt         </td></tr>\n",
       "<tr><td>train_12206_00069</td><td style=\"text-align: right;\">           1</td><td>/home/piai/Documents/POC-Project/ray_results/train_2023-04-07_12-33-56/train_12206_00069_69_Input_Pipeline=InputPipeline_normalize_SatoFilter,Loss_Function=CombinedLoss_FocalLoss_JaccardLoss_2023-04-09_21-05-06/error.txt           </td></tr>\n",
       "<tr><td>train_12206_00070</td><td style=\"text-align: right;\">           1</td><td>/home/piai/Documents/POC-Project/ray_results/train_2023-04-07_12-33-56/train_12206_00070_70_Input_Pipeline=InputPipeline_normalize_SumFilters_FrangiFilter_SatoFilter,Loss_Function=CombinedLoss_FocalLos_2023-04-09_21-17-26/error.txt</td></tr>\n",
       "<tr><td>train_12206_00071</td><td style=\"text-align: right;\">           1</td><td>/home/piai/Documents/POC-Project/ray_results/train_2023-04-07_12-33-56/train_12206_00071_71_Input_Pipeline=InputPipeline_normalize_SkeletonFilter,Loss_Function=CombinedLoss_FocalLoss_JaccardLoss_2023-04-09_21-20-07/error.txt       </td></tr>\n",
       "<tr><td>train_12206_00072</td><td style=\"text-align: right;\">           1</td><td>/home/piai/Documents/POC-Project/ray_results/train_2023-04-07_12-33-56/train_12206_00072_72_Input_Pipeline=InputPipeline_normalize_SobelFilter,Loss_Function=BorderedLoss_FocalLoss_JaccardLoss_2023-04-09_21-44-48/error.txt          </td></tr>\n",
       "<tr><td>train_12206_00073</td><td style=\"text-align: right;\">           1</td><td>/home/piai/Documents/POC-Project/ray_results/train_2023-04-07_12-33-56/train_12206_00073_73_Input_Pipeline=InputPipeline_normalize_LaplacianFilter,Loss_Function=BorderedLoss_FocalLoss_JaccardLoss_2023-04-09_21-47-06/error.txt      </td></tr>\n",
       "<tr><td>train_12206_00074</td><td style=\"text-align: right;\">           1</td><td>/home/piai/Documents/POC-Project/ray_results/train_2023-04-07_12-33-56/train_12206_00074_74_Input_Pipeline=InputPipeline_normalize_FrangiFilter,Loss_Function=BorderedLoss_FocalLoss_JaccardLoss_2023-04-09_21-50-50/error.txt         </td></tr>\n",
       "<tr><td>train_12206_00075</td><td style=\"text-align: right;\">           1</td><td>/home/piai/Documents/POC-Project/ray_results/train_2023-04-07_12-33-56/train_12206_00075_75_Input_Pipeline=InputPipeline_normalize_SatoFilter,Loss_Function=BorderedLoss_FocalLoss_JaccardLoss_2023-04-09_21-51-44/error.txt           </td></tr>\n",
       "<tr><td>train_12206_00076</td><td style=\"text-align: right;\">           1</td><td>/home/piai/Documents/POC-Project/ray_results/train_2023-04-07_12-33-56/train_12206_00076_76_Input_Pipeline=InputPipeline_normalize_SumFilters_FrangiFilter_SatoFilter,Loss_Function=BorderedLoss_FocalLos_2023-04-09_22-03-57/error.txt</td></tr>\n",
       "<tr><td>train_12206_00077</td><td style=\"text-align: right;\">           1</td><td>/home/piai/Documents/POC-Project/ray_results/train_2023-04-07_12-33-56/train_12206_00077_77_Input_Pipeline=InputPipeline_normalize_SkeletonFilter,Loss_Function=BorderedLoss_FocalLoss_JaccardLoss_2023-04-09_22-06-30/error.txt       </td></tr>\n",
       "<tr><td>train_12206_00078</td><td style=\"text-align: right;\">           1</td><td>/home/piai/Documents/POC-Project/ray_results/train_2023-04-07_12-33-56/train_12206_00078_78_Input_Pipeline=InputPipeline_normalize_SobelFilter,Loss_Function=CombinedLoss_FocalLoss_TverskyLoss_2023-04-09_22-31-34/error.txt          </td></tr>\n",
       "<tr><td>train_12206_00079</td><td style=\"text-align: right;\">           1</td><td>/home/piai/Documents/POC-Project/ray_results/train_2023-04-07_12-33-56/train_12206_00079_79_Input_Pipeline=InputPipeline_normalize_LaplacianFilter,Loss_Function=CombinedLoss_FocalLoss_TverskyLoss_2023-04-09_22-33-34/error.txt      </td></tr>\n",
       "<tr><td>train_12206_00080</td><td style=\"text-align: right;\">           1</td><td>/home/piai/Documents/POC-Project/ray_results/train_2023-04-07_12-33-56/train_12206_00080_80_Input_Pipeline=InputPipeline_normalize_FrangiFilter,Loss_Function=CombinedLoss_FocalLoss_TverskyLoss_2023-04-09_22-37-14/error.txt         </td></tr>\n",
       "<tr><td>train_12206_00081</td><td style=\"text-align: right;\">           1</td><td>/home/piai/Documents/POC-Project/ray_results/train_2023-04-07_12-33-56/train_12206_00081_81_Input_Pipeline=InputPipeline_normalize_SatoFilter,Loss_Function=CombinedLoss_FocalLoss_TverskyLoss_2023-04-09_22-38-03/error.txt           </td></tr>\n",
       "<tr><td>train_12206_00082</td><td style=\"text-align: right;\">           1</td><td>/home/piai/Documents/POC-Project/ray_results/train_2023-04-07_12-33-56/train_12206_00082_82_Input_Pipeline=InputPipeline_normalize_SumFilters_FrangiFilter_SatoFilter,Loss_Function=CombinedLoss_FocalLos_2023-04-09_22-50-40/error.txt</td></tr>\n",
       "<tr><td>train_12206_00083</td><td style=\"text-align: right;\">           1</td><td>/home/piai/Documents/POC-Project/ray_results/train_2023-04-07_12-33-56/train_12206_00083_83_Input_Pipeline=InputPipeline_normalize_SkeletonFilter,Loss_Function=CombinedLoss_FocalLoss_TverskyLoss_2023-04-09_22-53-00/error.txt       </td></tr>\n",
       "<tr><td>train_12206_00084</td><td style=\"text-align: right;\">           1</td><td>/home/piai/Documents/POC-Project/ray_results/train_2023-04-07_12-33-56/train_12206_00084_84_Input_Pipeline=InputPipeline_normalize_SobelFilter,Loss_Function=BorderedLoss_FocalLoss_TverskyLoss_2023-04-09_23-17-56/error.txt          </td></tr>\n",
       "<tr><td>train_12206_00085</td><td style=\"text-align: right;\">           1</td><td>/home/piai/Documents/POC-Project/ray_results/train_2023-04-07_12-33-56/train_12206_00085_85_Input_Pipeline=InputPipeline_normalize_LaplacianFilter,Loss_Function=BorderedLoss_FocalLoss_TverskyLoss_2023-04-09_23-20-15/error.txt      </td></tr>\n",
       "<tr><td>train_12206_00086</td><td style=\"text-align: right;\">           1</td><td>/home/piai/Documents/POC-Project/ray_results/train_2023-04-07_12-33-56/train_12206_00086_86_Input_Pipeline=InputPipeline_normalize_FrangiFilter,Loss_Function=BorderedLoss_FocalLoss_TverskyLoss_2023-04-09_23-23-41/error.txt         </td></tr>\n",
       "<tr><td>train_12206_00087</td><td style=\"text-align: right;\">           1</td><td>/home/piai/Documents/POC-Project/ray_results/train_2023-04-07_12-33-56/train_12206_00087_87_Input_Pipeline=InputPipeline_normalize_SatoFilter,Loss_Function=BorderedLoss_FocalLoss_TverskyLoss_2023-04-09_23-25-04/error.txt           </td></tr>\n",
       "<tr><td>train_12206_00088</td><td style=\"text-align: right;\">           1</td><td>/home/piai/Documents/POC-Project/ray_results/train_2023-04-07_12-33-56/train_12206_00088_88_Input_Pipeline=InputPipeline_normalize_SumFilters_FrangiFilter_SatoFilter,Loss_Function=BorderedLoss_FocalLos_2023-04-09_23-37-22/error.txt</td></tr>\n",
       "<tr><td>train_12206_00089</td><td style=\"text-align: right;\">           1</td><td>/home/piai/Documents/POC-Project/ray_results/train_2023-04-07_12-33-56/train_12206_00089_89_Input_Pipeline=InputPipeline_normalize_SkeletonFilter,Loss_Function=BorderedLoss_FocalLoss_TverskyLoss_2023-04-09_23-39-18/error.txt       </td></tr>\n",
       "<tr><td>train_12206_00090</td><td style=\"text-align: right;\">           1</td><td>/home/piai/Documents/POC-Project/ray_results/train_2023-04-07_12-33-56/train_12206_00090_90_Input_Pipeline=InputPipeline_normalize_SobelFilter,Loss_Function=CombinedLoss_FocalLoss_FocalTverskyLoss_2023-04-10_00-04-49/error.txt     </td></tr>\n",
       "<tr><td>train_12206_00091</td><td style=\"text-align: right;\">           1</td><td>/home/piai/Documents/POC-Project/ray_results/train_2023-04-07_12-33-56/train_12206_00091_91_Input_Pipeline=InputPipeline_normalize_LaplacianFilter,Loss_Function=CombinedLoss_FocalLoss_FocalTverskyLoss_2023-04-10_00-06-51/error.txt </td></tr>\n",
       "<tr><td>train_12206_00092</td><td style=\"text-align: right;\">           1</td><td>/home/piai/Documents/POC-Project/ray_results/train_2023-04-07_12-33-56/train_12206_00092_92_Input_Pipeline=InputPipeline_normalize_FrangiFilter,Loss_Function=CombinedLoss_FocalLoss_FocalTverskyLoss_2023-04-10_00-10-12/error.txt    </td></tr>\n",
       "<tr><td>train_12206_00093</td><td style=\"text-align: right;\">           1</td><td>/home/piai/Documents/POC-Project/ray_results/train_2023-04-07_12-33-56/train_12206_00093_93_Input_Pipeline=InputPipeline_normalize_SatoFilter,Loss_Function=CombinedLoss_FocalLoss_FocalTverskyLoss_2023-04-10_00-11-32/error.txt      </td></tr>\n",
       "<tr><td>train_12206_00094</td><td style=\"text-align: right;\">           1</td><td>/home/piai/Documents/POC-Project/ray_results/train_2023-04-07_12-33-56/train_12206_00094_94_Input_Pipeline=InputPipeline_normalize_SumFilters_FrangiFilter_SatoFilter,Loss_Function=CombinedLoss_FocalLos_2023-04-10_00-24-12/error.txt</td></tr>\n",
       "<tr><td>train_12206_00095</td><td style=\"text-align: right;\">           1</td><td>/home/piai/Documents/POC-Project/ray_results/train_2023-04-07_12-33-56/train_12206_00095_95_Input_Pipeline=InputPipeline_normalize_SkeletonFilter,Loss_Function=CombinedLoss_FocalLoss_FocalTverskyLoss_2023-04-10_00-25-54/error.txt  </td></tr>\n",
       "<tr><td>train_12206_00096</td><td style=\"text-align: right;\">           1</td><td>/home/piai/Documents/POC-Project/ray_results/train_2023-04-07_12-33-56/train_12206_00096_96_Input_Pipeline=InputPipeline_normalize_SobelFilter,Loss_Function=BorderedLoss_FocalLoss_FocalTverskyLoss_2023-04-10_00-51-45/error.txt     </td></tr>\n",
       "<tr><td>train_12206_00097</td><td style=\"text-align: right;\">           1</td><td>/home/piai/Documents/POC-Project/ray_results/train_2023-04-07_12-33-56/train_12206_00097_97_Input_Pipeline=InputPipeline_normalize_LaplacianFilter,Loss_Function=BorderedLoss_FocalLoss_FocalTverskyLoss_2023-04-10_00-53-46/error.txt </td></tr>\n",
       "<tr><td>train_12206_00098</td><td style=\"text-align: right;\">           1</td><td>/home/piai/Documents/POC-Project/ray_results/train_2023-04-07_12-33-56/train_12206_00098_98_Input_Pipeline=InputPipeline_normalize_FrangiFilter,Loss_Function=BorderedLoss_FocalLoss_FocalTverskyLoss_2023-04-10_00-56-39/error.txt    </td></tr>\n",
       "<tr><td>train_12206_00099</td><td style=\"text-align: right;\">           1</td><td>/home/piai/Documents/POC-Project/ray_results/train_2023-04-07_12-33-56/train_12206_00099_99_Input_Pipeline=InputPipeline_normalize_SatoFilter,Loss_Function=BorderedLoss_FocalLoss_FocalTverskyLoss_2023-04-10_00-58-42/error.txt      </td></tr>\n",
       "<tr><td>train_12206_00100</td><td style=\"text-align: right;\">           1</td><td>/home/piai/Documents/POC-Project/ray_results/train_2023-04-07_12-33-56/train_12206_00100_100_Input_Pipeline=InputPipeline_normalize_SumFilters_FrangiFilter_SatoFilter,Loss_Function=BorderedLoss_FocalLo_2023-04-10_01-11-04/error.txt</td></tr>\n",
       "<tr><td>train_12206_00101</td><td style=\"text-align: right;\">           1</td><td>/home/piai/Documents/POC-Project/ray_results/train_2023-04-07_12-33-56/train_12206_00101_101_Input_Pipeline=InputPipeline_normalize_SkeletonFilter,Loss_Function=BorderedLoss_FocalLoss_FocalTverskyLoss_2023-04-10_01-12-21/error.txt </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status    </th><th>loc                 </th><th>Input Pipeline      </th><th>Loss Function       </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  Epoch</th><th style=\"text-align: right;\">      Loss</th><th style=\"text-align: right;\">  CrackIoU</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_12206_00000</td><td>TERMINATED</td><td>141.223.107.22:16771</td><td>InputPipeline(n_f100</td><td>PixelLoss:Cross_d5d0</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         5857.44</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.0976571 </td><td style=\"text-align: right;\">  0.74874 </td></tr>\n",
       "<tr><td>train_12206_00001</td><td>TERMINATED</td><td>141.223.107.22:16816</td><td>InputPipeline(n_d720</td><td>PixelLoss:Cross_d2a0</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         6606.41</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.0977389 </td><td style=\"text-align: right;\">  0.739624</td></tr>\n",
       "<tr><td>train_12206_00002</td><td>TERMINATED</td><td>141.223.107.22:16771</td><td>InputPipeline(n_e860</td><td>PixelLoss:Cross_cb50</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         6662.15</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.097758  </td><td style=\"text-align: right;\">  0.738588</td></tr>\n",
       "<tr><td>train_12206_00003</td><td>TERMINATED</td><td>141.223.107.22:16816</td><td>InputPipeline(n_e890</td><td>PixelLoss:Cross_ea40</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         7076.28</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.0977079 </td><td style=\"text-align: right;\">  0.743115</td></tr>\n",
       "<tr><td>train_12206_00004</td><td>TERMINATED</td><td>141.223.107.22:16771</td><td>InputPipeline(n_b250</td><td>PixelLoss:Cross_e0e0</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         7366.22</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.0977144 </td><td style=\"text-align: right;\">  0.734599</td></tr>\n",
       "<tr><td>train_12206_00005</td><td>TERMINATED</td><td>141.223.107.22:16816</td><td>InputPipeline(n_b100</td><td>PixelLoss:Cross_b670</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         8263.78</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.0977378 </td><td style=\"text-align: right;\">  0.738433</td></tr>\n",
       "<tr><td>train_12206_00006</td><td>TERMINATED</td><td>141.223.107.22:16771</td><td>InputPipeline(n_bd00</td><td>PixelLoss:FocalLoss </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         5894.06</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.00770159</td><td style=\"text-align: right;\">  0.73222 </td></tr>\n",
       "<tr><td>train_12206_00007</td><td>TERMINATED</td><td>141.223.107.22:16816</td><td>InputPipeline(n_8430</td><td>PixelLoss:FocalLoss </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         6634.1 </td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.00773644</td><td style=\"text-align: right;\">  0.729173</td></tr>\n",
       "<tr><td>train_12206_00008</td><td>TERMINATED</td><td>141.223.107.22:16771</td><td>InputPipeline(n_91b0</td><td>PixelLoss:FocalLoss </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         6689.24</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.00777491</td><td style=\"text-align: right;\">  0.718509</td></tr>\n",
       "<tr><td>train_12206_00009</td><td>TERMINATED</td><td>141.223.107.22:16816</td><td>InputPipeline(n_a2c0</td><td>PixelLoss:FocalLoss </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         7089.16</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.00775036</td><td style=\"text-align: right;\">  0.727848</td></tr>\n",
       "<tr><td>train_12206_00010</td><td>TERMINATED</td><td>141.223.107.22:16771</td><td>InputPipeline(n_a590</td><td>PixelLoss:FocalLoss </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         7405.65</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.00773826</td><td style=\"text-align: right;\">  0.72957 </td></tr>\n",
       "<tr><td>train_12206_00011</td><td>TERMINATED</td><td>141.223.107.22:16816</td><td>InputPipeline(n_b160</td><td>PixelLoss:FocalLoss </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         8301.36</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.00775784</td><td style=\"text-align: right;\">  0.72548 </td></tr>\n",
       "<tr><td>train_12206_00012</td><td>TERMINATED</td><td>141.223.107.22:16771</td><td>InputPipeline(n_9a80</td><td>VolumeLoss:Jacc_8d90</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         5883.3 </td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.119949  </td><td style=\"text-align: right;\">  0.764128</td></tr>\n",
       "<tr><td>train_12206_00013</td><td>TERMINATED</td><td>141.223.107.22:16816</td><td>InputPipeline(n_9960</td><td>VolumeLoss:Jacc_9e70</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         6614.27</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.125026  </td><td style=\"text-align: right;\">  0.754072</td></tr>\n",
       "<tr><td>train_12206_00014</td><td>TERMINATED</td><td>141.223.107.22:16771</td><td>InputPipeline(n_9810</td><td>VolumeLoss:Jacc_8520</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         6690.26</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.124361  </td><td style=\"text-align: right;\">  0.755487</td></tr>\n",
       "<tr><td>train_12206_00015</td><td>TERMINATED</td><td>141.223.107.22:16816</td><td>InputPipeline(n_9f30</td><td>VolumeLoss:Jacc_8e20</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         7065.38</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.120501  </td><td style=\"text-align: right;\">  0.763051</td></tr>\n",
       "<tr><td>train_12206_00016</td><td>TERMINATED</td><td>141.223.107.22:16771</td><td>InputPipeline(n_a9b0</td><td>VolumeLoss:Jacc_b760</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         7387.09</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.119702  </td><td style=\"text-align: right;\">  0.764652</td></tr>\n",
       "<tr><td>train_12206_00017</td><td>TERMINATED</td><td>141.223.107.22:16816</td><td>InputPipeline(n_ac20</td><td>VolumeLoss:Jacc_8220</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         8272.79</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.119966  </td><td style=\"text-align: right;\">  0.764135</td></tr>\n",
       "<tr><td>train_12206_00018</td><td>TERMINATED</td><td>141.223.107.22:16771</td><td>InputPipeline(n_cac0</td><td>VolumeLoss:Tver_ebc0</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         5878.38</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.12035   </td><td style=\"text-align: right;\">  0.746757</td></tr>\n",
       "<tr><td>train_12206_00019</td><td>TERMINATED</td><td>141.223.107.22:16771</td><td>InputPipeline(n_dbd0</td><td>VolumeLoss:Tver_c610</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         6031.57</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.12282   </td><td style=\"text-align: right;\">  0.744912</td></tr>\n",
       "<tr><td>train_12206_00020</td><td>TERMINATED</td><td>141.223.107.22:16816</td><td>InputPipeline(n_8fd0</td><td>VolumeLoss:Tver_8be0</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         7266.83</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.123654  </td><td style=\"text-align: right;\">  0.741707</td></tr>\n",
       "<tr><td>train_12206_00021</td><td>TERMINATED</td><td>141.223.107.22:16771</td><td>InputPipeline(n_b730</td><td>VolumeLoss:Tver_b0a0</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         6500   </td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.120123  </td><td style=\"text-align: right;\">  0.748859</td></tr>\n",
       "<tr><td>train_12206_00022</td><td>TERMINATED</td><td>141.223.107.22:16816</td><td>InputPipeline(n_c790</td><td>VolumeLoss:Tver_d300</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         7925.3 </td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.121786  </td><td style=\"text-align: right;\">  0.743368</td></tr>\n",
       "<tr><td>train_12206_00023</td><td>TERMINATED</td><td>141.223.107.22:16771</td><td>InputPipeline(n_c3a0</td><td>VolumeLoss:Tver_ddb0</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         7639.46</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.124923  </td><td style=\"text-align: right;\">  0.743353</td></tr>\n",
       "<tr><td>train_12206_00024</td><td>TERMINATED</td><td>141.223.107.22:16816</td><td>InputPipeline(n_d450</td><td>VolumeLoss:Foca_c6a0</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         6500.85</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.0177823 </td><td style=\"text-align: right;\">  0.741542</td></tr>\n",
       "<tr><td>train_12206_00025</td><td>TERMINATED</td><td>141.223.107.22:16771</td><td>InputPipeline(n_8640</td><td>VolumeLoss:Foca_ed40</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         6036.67</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.017988  </td><td style=\"text-align: right;\">  0.740411</td></tr>\n",
       "<tr><td>train_12206_00026</td><td>TERMINATED</td><td>141.223.107.22:16816</td><td>InputPipeline(n_8520</td><td>VolumeLoss:Foca_90c0</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         7272.52</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.0194123 </td><td style=\"text-align: right;\">  0.733617</td></tr>\n",
       "<tr><td>train_12206_00027</td><td>TERMINATED</td><td>141.223.107.22:16771</td><td>InputPipeline(n_ba30</td><td>VolumeLoss:Foca_a830</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         6505.34</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.017174  </td><td style=\"text-align: right;\">  0.736791</td></tr>\n",
       "<tr><td>train_12206_00028</td><td>TERMINATED</td><td>141.223.107.22:16816</td><td>InputPipeline(n_2020</td><td>VolumeLoss:Foca_0370</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         7922.02</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.0170084 </td><td style=\"text-align: right;\">  0.743512</td></tr>\n",
       "<tr><td>train_12206_00029</td><td>TERMINATED</td><td>141.223.107.22:16771</td><td>InputPipeline(n_2b00</td><td>VolumeLoss:Foca_3dc0</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         7647.45</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.0176934 </td><td style=\"text-align: right;\">  0.745618</td></tr>\n",
       "<tr><td>train_12206_00030</td><td>TERMINATED</td><td>141.223.107.22:16816</td><td>InputPipeline(n_b940</td><td>CombinedLoss(Cr_3100</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         6509.72</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.112049  </td><td style=\"text-align: right;\">  0.767805</td></tr>\n",
       "<tr><td>train_12206_00031</td><td>TERMINATED</td><td>141.223.107.22:16771</td><td>InputPipeline(n_ba90</td><td>CombinedLoss(Cr_b310</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         6034.89</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.113677  </td><td style=\"text-align: right;\">  0.763176</td></tr>\n",
       "<tr><td>train_12206_00032</td><td>TERMINATED</td><td>141.223.107.22:16816</td><td>InputPipeline(n_9090</td><td>CombinedLoss(Cr_9ff0</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         7252.41</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.113377  </td><td style=\"text-align: right;\">  0.764092</td></tr>\n",
       "<tr><td>train_12206_00033</td><td>TERMINATED</td><td>141.223.107.22:16771</td><td>InputPipeline(n_db10</td><td>CombinedLoss(Cr_d6f0</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         6501.29</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.115429  </td><td style=\"text-align: right;\">  0.7581  </td></tr>\n",
       "<tr><td>train_12206_00034</td><td>TERMINATED</td><td>141.223.107.22:16816</td><td>InputPipeline(n_f130</td><td>CombinedLoss(Cr_ee30</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         7918.83</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.113313  </td><td style=\"text-align: right;\">  0.764151</td></tr>\n",
       "<tr><td>train_12206_00035</td><td>TERMINATED</td><td>141.223.107.22:16771</td><td>InputPipeline(n_dcc0</td><td>CombinedLoss(Cr_c490</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         7625   </td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.114718  </td><td style=\"text-align: right;\">  0.76023 </td></tr>\n",
       "<tr><td>train_12206_00036</td><td>TERMINATED</td><td>141.223.107.22:16816</td><td>InputPipeline(n_f7c0</td><td>BorderedLoss(Cr_d4b0</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         6461.43</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.0836971 </td><td style=\"text-align: right;\">  0.766799</td></tr>\n",
       "<tr><td>train_12206_00037</td><td>TERMINATED</td><td>141.223.107.22:16771</td><td>InputPipeline(n_d0f0</td><td>BorderedLoss(Cr_f5b0</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         6028.89</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.0849837 </td><td style=\"text-align: right;\">  0.763154</td></tr>\n",
       "<tr><td>train_12206_00038</td><td>TERMINATED</td><td>141.223.107.22:16816</td><td>InputPipeline(n_f370</td><td>BorderedLoss(Cr_f100</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         7223.29</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.0872574 </td><td style=\"text-align: right;\">  0.75681 </td></tr>\n",
       "<tr><td>train_12206_00039</td><td>TERMINATED</td><td>141.223.107.22:16771</td><td>InputPipeline(n_0280</td><td>BorderedLoss(Cr_dd20</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         6484.11</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.0854233 </td><td style=\"text-align: right;\">  0.761901</td></tr>\n",
       "<tr><td>train_12206_00040</td><td>TERMINATED</td><td>141.223.107.22:16816</td><td>InputPipeline(n_0d00</td><td>BorderedLoss(Cr_03a0</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         7918.73</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.0837492 </td><td style=\"text-align: right;\">  0.766705</td></tr>\n",
       "<tr><td>train_12206_00041</td><td>TERMINATED</td><td>141.223.107.22:16771</td><td>InputPipeline(n_2440</td><td>BorderedLoss(Cr_3ac0</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         7624.94</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.085474  </td><td style=\"text-align: right;\">  0.761839</td></tr>\n",
       "<tr><td>train_12206_00042</td><td>TERMINATED</td><td>141.223.107.22:16816</td><td>InputPipeline(n_23b0</td><td>CombinedLoss(Cr_0040</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         6416.97</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.111555  </td><td style=\"text-align: right;\">  0.753083</td></tr>\n",
       "<tr><td>train_12206_00043</td><td>TERMINATED</td><td>141.223.107.22:16771</td><td>InputPipeline(n_01c0</td><td>CombinedLoss(Cr_2140</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         6023   </td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.117508  </td><td style=\"text-align: right;\">  0.742087</td></tr>\n",
       "<tr><td>train_12206_00044</td><td>TERMINATED</td><td>141.223.107.22:16771</td><td>InputPipeline(n_3640</td><td>CombinedLoss(Cr_1210</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         6712.74</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.115483  </td><td style=\"text-align: right;\">  0.745278</td></tr>\n",
       "<tr><td>train_12206_00045</td><td>TERMINATED</td><td>141.223.107.22:16816</td><td>InputPipeline(n_1e70</td><td>CombinedLoss(Cr_22c0</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         7041.09</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.114491  </td><td style=\"text-align: right;\">  0.744939</td></tr>\n",
       "<tr><td>train_12206_00046</td><td>TERMINATED</td><td>141.223.107.22:16771</td><td>InputPipeline(n_3b50</td><td>CombinedLoss(Cr_21d0</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         7419.23</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.115853  </td><td style=\"text-align: right;\">  0.741073</td></tr>\n",
       "<tr><td>train_12206_00047</td><td>TERMINATED</td><td>141.223.107.22:16816</td><td>InputPipeline(n_0c10</td><td>CombinedLoss(Cr_3070</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         8247.78</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.116103  </td><td style=\"text-align: right;\">  0.74372 </td></tr>\n",
       "<tr><td>train_12206_00048</td><td>TERMINATED</td><td>141.223.107.22:16771</td><td>InputPipeline(n_1e10</td><td>BorderedLoss(Cr_3280</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         5952.42</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.0845145 </td><td style=\"text-align: right;\">  0.750201</td></tr>\n",
       "<tr><td>train_12206_00049</td><td>TERMINATED</td><td>141.223.107.22:16816</td><td>InputPipeline(n_32e0</td><td>BorderedLoss(Cr_0a00</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         6586.67</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.088925  </td><td style=\"text-align: right;\">  0.742166</td></tr>\n",
       "<tr><td>train_12206_00050</td><td>TERMINATED</td><td>141.223.107.22:16771</td><td>InputPipeline(n_0340</td><td>BorderedLoss(Cr_3d60</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         6820.33</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.0850978 </td><td style=\"text-align: right;\">  0.745191</td></tr>\n",
       "<tr><td>train_12206_00051</td><td>TERMINATED</td><td>141.223.107.22:16816</td><td>InputPipeline(n_0e80</td><td>BorderedLoss(Cr_1960</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         7020.56</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.0857937 </td><td style=\"text-align: right;\">  0.745256</td></tr>\n",
       "<tr><td>train_12206_00052</td><td>TERMINATED</td><td>141.223.107.22:16771</td><td>InputPipeline(n_2fe0</td><td>BorderedLoss(Cr_1a80</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         7500.94</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.086144  </td><td style=\"text-align: right;\">  0.743338</td></tr>\n",
       "<tr><td>train_12206_00053</td><td>TERMINATED</td><td>141.223.107.22:16816</td><td>InputPipeline(n_1000</td><td>BorderedLoss(Cr_2b00</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         8250.76</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.0872007 </td><td style=\"text-align: right;\">  0.743196</td></tr>\n",
       "<tr><td>train_12206_00054</td><td>TERMINATED</td><td>141.223.107.22:16771</td><td>InputPipeline(n_3a30</td><td>CombinedLoss(Cr_2020</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         5922.57</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.0405    </td><td style=\"text-align: right;\">  0.748304</td></tr>\n",
       "<tr><td>train_12206_00055</td><td>TERMINATED</td><td>141.223.107.22:16816</td><td>InputPipeline(n_0430</td><td>CombinedLoss(Cr_0700</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         6590.3 </td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.0418153 </td><td style=\"text-align: right;\">  0.74752 </td></tr>\n",
       "<tr><td>train_12206_00056</td><td>TERMINATED</td><td>141.223.107.22:16771</td><td>InputPipeline(n_2920</td><td>CombinedLoss(Cr_18a0</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         6754.87</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">0.0427908 </td><td style=\"text-align: right;\">  0.739538</td></tr>\n",
       "<tr><td>train_12206_00057</td><td>ERROR     </td><td>141.223.107.22:16816</td><td>InputPipeline(n_2650</td><td>CombinedLoss(Cr_04f0</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         2942.69</td><td style=\"text-align: right;\">      7</td><td style=\"text-align: right;\">0.0443755 </td><td style=\"text-align: right;\">  0.735887</td></tr>\n",
       "<tr><td>train_12206_00058</td><td>ERROR     </td><td>141.223.107.22:16771</td><td>InputPipeline(n_14e0</td><td>CombinedLoss(Cr_2770</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_12206_00059</td><td>ERROR     </td><td>141.223.107.22:31196</td><td>InputPipeline(n_1a20</td><td>CombinedLoss(Cr_19f0</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_12206_00060</td><td>ERROR     </td><td>141.223.107.22:31198</td><td>InputPipeline(n_0790</td><td>BorderedLoss(Cr_04c0</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_12206_00061</td><td>ERROR     </td><td>141.223.107.22:31366</td><td>InputPipeline(n_2a70</td><td>BorderedLoss(Cr_2350</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_12206_00062</td><td>ERROR     </td><td>141.223.107.22:31532</td><td>InputPipeline(n_2e30</td><td>BorderedLoss(Cr_2cb0</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_12206_00063</td><td>ERROR     </td><td>141.223.107.22:31857</td><td>InputPipeline(n_ec20</td><td>BorderedLoss(Cr_93c0</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_12206_00064</td><td>ERROR     </td><td>141.223.107.22:32072</td><td>InputPipeline(n_ab30</td><td>BorderedLoss(Cr_8460</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_12206_00065</td><td>ERROR     </td><td>141.223.107.22:32226</td><td>InputPipeline(n_b400</td><td>BorderedLoss(Cr_bfa0</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_12206_00066</td><td>ERROR     </td><td>141.223.107.22:32653</td><td>InputPipeline(n_be20</td><td>CombinedLoss(Fo_9fc0</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_12206_00067</td><td>ERROR     </td><td>141.223.107.22:329  </td><td>InputPipeline(n_96c0</td><td>CombinedLoss(Fo_9b70</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_12206_00068</td><td>ERROR     </td><td>141.223.107.22:503  </td><td>InputPipeline(n_8b20</td><td>CombinedLoss(Fo_b040</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_12206_00069</td><td>ERROR     </td><td>141.223.107.22:631  </td><td>InputPipeline(n_aaa0</td><td>CombinedLoss(Fo_b2e0</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_12206_00070</td><td>ERROR     </td><td>141.223.107.22:923  </td><td>InputPipeline(n_9660</td><td>CombinedLoss(Fo_b9a0</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_12206_00071</td><td>ERROR     </td><td>141.223.107.22:1078 </td><td>InputPipeline(n_92d0</td><td>CombinedLoss(Fo_8c10</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_12206_00072</td><td>ERROR     </td><td>141.223.107.22:1579 </td><td>InputPipeline(n_9270</td><td>BorderedLoss(Fo_bbe0</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_12206_00073</td><td>ERROR     </td><td>141.223.107.22:1715 </td><td>InputPipeline(n_9510</td><td>BorderedLoss(Fo_95a0</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_12206_00074</td><td>ERROR     </td><td>141.223.107.22:1868 </td><td>InputPipeline(n_82e0</td><td>BorderedLoss(Fo_90c0</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_12206_00075</td><td>ERROR     </td><td>141.223.107.22:1981 </td><td>InputPipeline(n_a050</td><td>BorderedLoss(Fo_a830</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_12206_00076</td><td>ERROR     </td><td>141.223.107.22:2373 </td><td>InputPipeline(n_9ae0</td><td>BorderedLoss(Fo_8f40</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_12206_00077</td><td>ERROR     </td><td>141.223.107.22:2507 </td><td>InputPipeline(n_b3a0</td><td>BorderedLoss(Fo_9e40</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_12206_00078</td><td>ERROR     </td><td>141.223.107.22:3273 </td><td>InputPipeline(n_b4c0</td><td>CombinedLoss(Fo_b970</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_12206_00079</td><td>ERROR     </td><td>141.223.107.22:3402 </td><td>InputPipeline(n_ac50</td><td>CombinedLoss(Fo_8730</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_12206_00080</td><td>ERROR     </td><td>141.223.107.22:3552 </td><td>InputPipeline(n_9840</td><td>CombinedLoss(Fo_9990</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_12206_00081</td><td>ERROR     </td><td>141.223.107.22:3662 </td><td>InputPipeline(n_a1d0</td><td>CombinedLoss(Fo_8ee0</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_12206_00082</td><td>ERROR     </td><td>141.223.107.22:3940 </td><td>InputPipeline(n_8580</td><td>CombinedLoss(Fo_8940</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_12206_00083</td><td>ERROR     </td><td>141.223.107.22:4067 </td><td>InputPipeline(n_9750</td><td>CombinedLoss(Fo_9900</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_12206_00084</td><td>ERROR     </td><td>141.223.107.22:4526 </td><td>InputPipeline(n_94b0</td><td>BorderedLoss(Fo_93f0</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_12206_00085</td><td>ERROR     </td><td>141.223.107.22:4661 </td><td>InputPipeline(n_9120</td><td>BorderedLoss(Fo_add0</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_12206_00086</td><td>ERROR     </td><td>141.223.107.22:4814 </td><td>InputPipeline(n_ac20</td><td>BorderedLoss(Fo_ac80</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_12206_00087</td><td>ERROR     </td><td>141.223.107.22:4934 </td><td>InputPipeline(n_d600</td><td>BorderedLoss(Fo_a110</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_12206_00088</td><td>ERROR     </td><td>141.223.107.22:5208 </td><td>InputPipeline(n_f400</td><td>BorderedLoss(Fo_f4c0</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_12206_00089</td><td>ERROR     </td><td>141.223.107.22:5340 </td><td>InputPipeline(n_dde0</td><td>BorderedLoss(Fo_cc10</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_12206_00090</td><td>ERROR     </td><td>141.223.107.22:5796 </td><td>InputPipeline(n_d300</td><td>CombinedLoss(Fo_c400</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_12206_00091</td><td>ERROR     </td><td>141.223.107.22:6026 </td><td>InputPipeline(n_c4c0</td><td>CombinedLoss(Fo_d840</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_12206_00092</td><td>ERROR     </td><td>141.223.107.22:6177 </td><td>InputPipeline(n_fb50</td><td>CombinedLoss(Fo_e9b0</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_12206_00093</td><td>ERROR     </td><td>141.223.107.22:6292 </td><td>InputPipeline(n_c700</td><td>CombinedLoss(Fo_e9e0</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_12206_00094</td><td>ERROR     </td><td>141.223.107.22:6564 </td><td>InputPipeline(n_c940</td><td>CombinedLoss(Fo_ca90</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_12206_00095</td><td>ERROR     </td><td>141.223.107.22:6692 </td><td>InputPipeline(n_c970</td><td>CombinedLoss(Fo_ce20</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_12206_00096</td><td>ERROR     </td><td>141.223.107.22:7144 </td><td>InputPipeline(n_c0a0</td><td>BorderedLoss(Fo_ce80</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_12206_00097</td><td>ERROR     </td><td>141.223.107.22:7270 </td><td>InputPipeline(n_c4f0</td><td>BorderedLoss(Fo_e3e0</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_12206_00098</td><td>ERROR     </td><td>141.223.107.22:7406 </td><td>InputPipeline(n_c9a0</td><td>BorderedLoss(Fo_eb90</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_12206_00099</td><td>ERROR     </td><td>141.223.107.22:7531 </td><td>InputPipeline(n_cd90</td><td>BorderedLoss(Fo_cf10</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_12206_00100</td><td>ERROR     </td><td>141.223.107.22:7806 </td><td>InputPipeline(n_d150</td><td>BorderedLoss(Fo_c130</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>train_12206_00101</td><td>ERROR     </td><td>141.223.107.22:7920 </td><td>InputPipeline(n_d870</td><td>BorderedLoss(Fo_ca60</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">          </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>date               </th><th>experiment_id                   </th><th>hostname                 </th><th>node_ip       </th><th style=\"text-align: right;\">  pid</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">   trial_id</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_12206_00000</td><td>2023-04-07_14-11-57</td><td>a6b2cb5999574c94930a0ce71be3c4ef</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16771</td><td style=\"text-align: right;\"> 1680844317</td><td style=\"text-align: right;\">12206_00000</td></tr>\n",
       "<tr><td>train_12206_00001</td><td>2023-04-07_14-24-30</td><td>3341b9c1035f4e63a28414608ccda31f</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16816</td><td style=\"text-align: right;\"> 1680845070</td><td style=\"text-align: right;\">12206_00001</td></tr>\n",
       "<tr><td>train_12206_00002</td><td>2023-04-07_16-02-59</td><td>a6b2cb5999574c94930a0ce71be3c4ef</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16771</td><td style=\"text-align: right;\"> 1680850979</td><td style=\"text-align: right;\">12206_00002</td></tr>\n",
       "<tr><td>train_12206_00003</td><td>2023-04-07_16-22-27</td><td>3341b9c1035f4e63a28414608ccda31f</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16816</td><td style=\"text-align: right;\"> 1680852147</td><td style=\"text-align: right;\">12206_00003</td></tr>\n",
       "<tr><td>train_12206_00004</td><td>2023-04-07_18-05-46</td><td>a6b2cb5999574c94930a0ce71be3c4ef</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16771</td><td style=\"text-align: right;\"> 1680858346</td><td style=\"text-align: right;\">12206_00004</td></tr>\n",
       "<tr><td>train_12206_00005</td><td>2023-04-07_18-40-11</td><td>3341b9c1035f4e63a28414608ccda31f</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16816</td><td style=\"text-align: right;\"> 1680860411</td><td style=\"text-align: right;\">12206_00005</td></tr>\n",
       "<tr><td>train_12206_00006</td><td>2023-04-07_19-44-00</td><td>a6b2cb5999574c94930a0ce71be3c4ef</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16771</td><td style=\"text-align: right;\"> 1680864240</td><td style=\"text-align: right;\">12206_00006</td></tr>\n",
       "<tr><td>train_12206_00007</td><td>2023-04-07_20-30-45</td><td>3341b9c1035f4e63a28414608ccda31f</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16816</td><td style=\"text-align: right;\"> 1680867045</td><td style=\"text-align: right;\">12206_00007</td></tr>\n",
       "<tr><td>train_12206_00008</td><td>2023-04-07_21-35-30</td><td>a6b2cb5999574c94930a0ce71be3c4ef</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16771</td><td style=\"text-align: right;\"> 1680870930</td><td style=\"text-align: right;\">12206_00008</td></tr>\n",
       "<tr><td>train_12206_00009</td><td>2023-04-07_22-28-55</td><td>3341b9c1035f4e63a28414608ccda31f</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16816</td><td style=\"text-align: right;\"> 1680874135</td><td style=\"text-align: right;\">12206_00009</td></tr>\n",
       "<tr><td>train_12206_00010</td><td>2023-04-07_23-38-56</td><td>a6b2cb5999574c94930a0ce71be3c4ef</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16771</td><td style=\"text-align: right;\"> 1680878336</td><td style=\"text-align: right;\">12206_00010</td></tr>\n",
       "<tr><td>train_12206_00011</td><td>2023-04-08_00-47-16</td><td>3341b9c1035f4e63a28414608ccda31f</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16816</td><td style=\"text-align: right;\"> 1680882436</td><td style=\"text-align: right;\">12206_00011</td></tr>\n",
       "<tr><td>train_12206_00012</td><td>2023-04-08_01-16-59</td><td>a6b2cb5999574c94930a0ce71be3c4ef</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16771</td><td style=\"text-align: right;\"> 1680884219</td><td style=\"text-align: right;\">12206_00012</td></tr>\n",
       "<tr><td>train_12206_00013</td><td>2023-04-08_02-37-31</td><td>3341b9c1035f4e63a28414608ccda31f</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16816</td><td style=\"text-align: right;\"> 1680889051</td><td style=\"text-align: right;\">12206_00013</td></tr>\n",
       "<tr><td>train_12206_00014</td><td>2023-04-08_03-08-30</td><td>a6b2cb5999574c94930a0ce71be3c4ef</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16771</td><td style=\"text-align: right;\"> 1680890910</td><td style=\"text-align: right;\">12206_00014</td></tr>\n",
       "<tr><td>train_12206_00015</td><td>2023-04-08_04-35-17</td><td>3341b9c1035f4e63a28414608ccda31f</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16816</td><td style=\"text-align: right;\"> 1680896117</td><td style=\"text-align: right;\">12206_00015</td></tr>\n",
       "<tr><td>train_12206_00016</td><td>2023-04-08_05-11-37</td><td>a6b2cb5999574c94930a0ce71be3c4ef</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16771</td><td style=\"text-align: right;\"> 1680898297</td><td style=\"text-align: right;\">12206_00016</td></tr>\n",
       "<tr><td>train_12206_00017</td><td>2023-04-08_06-53-10</td><td>3341b9c1035f4e63a28414608ccda31f</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16816</td><td style=\"text-align: right;\"> 1680904390</td><td style=\"text-align: right;\">12206_00017</td></tr>\n",
       "<tr><td>train_12206_00018</td><td>2023-04-08_06-49-36</td><td>a6b2cb5999574c94930a0ce71be3c4ef</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16771</td><td style=\"text-align: right;\"> 1680904176</td><td style=\"text-align: right;\">12206_00018</td></tr>\n",
       "<tr><td>train_12206_00019</td><td>2023-04-08_08-30-08</td><td>a6b2cb5999574c94930a0ce71be3c4ef</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16771</td><td style=\"text-align: right;\"> 1680910208</td><td style=\"text-align: right;\">12206_00019</td></tr>\n",
       "<tr><td>train_12206_00020</td><td>2023-04-08_08-54-17</td><td>3341b9c1035f4e63a28414608ccda31f</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16816</td><td style=\"text-align: right;\"> 1680911657</td><td style=\"text-align: right;\">12206_00020</td></tr>\n",
       "<tr><td>train_12206_00021</td><td>2023-04-08_10-18-28</td><td>a6b2cb5999574c94930a0ce71be3c4ef</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16771</td><td style=\"text-align: right;\"> 1680916708</td><td style=\"text-align: right;\">12206_00021</td></tr>\n",
       "<tr><td>train_12206_00022</td><td>2023-04-08_11-06-22</td><td>3341b9c1035f4e63a28414608ccda31f</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16816</td><td style=\"text-align: right;\"> 1680919582</td><td style=\"text-align: right;\">12206_00022</td></tr>\n",
       "<tr><td>train_12206_00023</td><td>2023-04-08_12-25-48</td><td>a6b2cb5999574c94930a0ce71be3c4ef</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16771</td><td style=\"text-align: right;\"> 1680924348</td><td style=\"text-align: right;\">12206_00023</td></tr>\n",
       "<tr><td>train_12206_00024</td><td>2023-04-08_12-54-44</td><td>3341b9c1035f4e63a28414608ccda31f</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16816</td><td style=\"text-align: right;\"> 1680926084</td><td style=\"text-align: right;\">12206_00024</td></tr>\n",
       "<tr><td>train_12206_00025</td><td>2023-04-08_14-06-25</td><td>a6b2cb5999574c94930a0ce71be3c4ef</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16771</td><td style=\"text-align: right;\"> 1680930385</td><td style=\"text-align: right;\">12206_00025</td></tr>\n",
       "<tr><td>train_12206_00026</td><td>2023-04-08_14-55-56</td><td>3341b9c1035f4e63a28414608ccda31f</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16816</td><td style=\"text-align: right;\"> 1680933356</td><td style=\"text-align: right;\">12206_00026</td></tr>\n",
       "<tr><td>train_12206_00027</td><td>2023-04-08_15-54-50</td><td>a6b2cb5999574c94930a0ce71be3c4ef</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16771</td><td style=\"text-align: right;\"> 1680936890</td><td style=\"text-align: right;\">12206_00027</td></tr>\n",
       "<tr><td>train_12206_00028</td><td>2023-04-08_17-07-59</td><td>3341b9c1035f4e63a28414608ccda31f</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16816</td><td style=\"text-align: right;\"> 1680941279</td><td style=\"text-align: right;\">12206_00028</td></tr>\n",
       "<tr><td>train_12206_00029</td><td>2023-04-08_18-02-18</td><td>a6b2cb5999574c94930a0ce71be3c4ef</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16771</td><td style=\"text-align: right;\"> 1680944538</td><td style=\"text-align: right;\">12206_00029</td></tr>\n",
       "<tr><td>train_12206_00030</td><td>2023-04-08_18-56-29</td><td>3341b9c1035f4e63a28414608ccda31f</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16816</td><td style=\"text-align: right;\"> 1680947789</td><td style=\"text-align: right;\">12206_00030</td></tr>\n",
       "<tr><td>train_12206_00031</td><td>2023-04-08_19-42-53</td><td>a6b2cb5999574c94930a0ce71be3c4ef</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16771</td><td style=\"text-align: right;\"> 1680950573</td><td style=\"text-align: right;\">12206_00031</td></tr>\n",
       "<tr><td>train_12206_00032</td><td>2023-04-08_20-57-21</td><td>3341b9c1035f4e63a28414608ccda31f</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16816</td><td style=\"text-align: right;\"> 1680955041</td><td style=\"text-align: right;\">12206_00032</td></tr>\n",
       "<tr><td>train_12206_00033</td><td>2023-04-08_21-31-15</td><td>a6b2cb5999574c94930a0ce71be3c4ef</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16771</td><td style=\"text-align: right;\"> 1680957075</td><td style=\"text-align: right;\">12206_00033</td></tr>\n",
       "<tr><td>train_12206_00034</td><td>2023-04-08_23-09-21</td><td>3341b9c1035f4e63a28414608ccda31f</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16816</td><td style=\"text-align: right;\"> 1680962961</td><td style=\"text-align: right;\">12206_00034</td></tr>\n",
       "<tr><td>train_12206_00035</td><td>2023-04-08_23-38-20</td><td>a6b2cb5999574c94930a0ce71be3c4ef</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16771</td><td style=\"text-align: right;\"> 1680964700</td><td style=\"text-align: right;\">12206_00035</td></tr>\n",
       "<tr><td>train_12206_00036</td><td>2023-04-09_00-57-02</td><td>3341b9c1035f4e63a28414608ccda31f</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16816</td><td style=\"text-align: right;\"> 1680969422</td><td style=\"text-align: right;\">12206_00036</td></tr>\n",
       "<tr><td>train_12206_00037</td><td>2023-04-09_01-18-49</td><td>a6b2cb5999574c94930a0ce71be3c4ef</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16771</td><td style=\"text-align: right;\"> 1680970729</td><td style=\"text-align: right;\">12206_00037</td></tr>\n",
       "<tr><td>train_12206_00038</td><td>2023-04-09_02-57-26</td><td>3341b9c1035f4e63a28414608ccda31f</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16816</td><td style=\"text-align: right;\"> 1680976646</td><td style=\"text-align: right;\">12206_00038</td></tr>\n",
       "<tr><td>train_12206_00039</td><td>2023-04-09_03-06-54</td><td>a6b2cb5999574c94930a0ce71be3c4ef</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16771</td><td style=\"text-align: right;\"> 1680977214</td><td style=\"text-align: right;\">12206_00039</td></tr>\n",
       "<tr><td>train_12206_00040</td><td>2023-04-09_05-09-25</td><td>3341b9c1035f4e63a28414608ccda31f</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16816</td><td style=\"text-align: right;\"> 1680984565</td><td style=\"text-align: right;\">12206_00040</td></tr>\n",
       "<tr><td>train_12206_00041</td><td>2023-04-09_05-13-59</td><td>a6b2cb5999574c94930a0ce71be3c4ef</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16771</td><td style=\"text-align: right;\"> 1680984839</td><td style=\"text-align: right;\">12206_00041</td></tr>\n",
       "<tr><td>train_12206_00042</td><td>2023-04-09_06-56-22</td><td>3341b9c1035f4e63a28414608ccda31f</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16816</td><td style=\"text-align: right;\"> 1680990982</td><td style=\"text-align: right;\">12206_00042</td></tr>\n",
       "<tr><td>train_12206_00043</td><td>2023-04-09_06-54-22</td><td>a6b2cb5999574c94930a0ce71be3c4ef</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16771</td><td style=\"text-align: right;\"> 1680990862</td><td style=\"text-align: right;\">12206_00043</td></tr>\n",
       "<tr><td>train_12206_00044</td><td>2023-04-09_08-46-15</td><td>a6b2cb5999574c94930a0ce71be3c4ef</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16771</td><td style=\"text-align: right;\"> 1680997575</td><td style=\"text-align: right;\">12206_00044</td></tr>\n",
       "<tr><td>train_12206_00045</td><td>2023-04-09_08-53-44</td><td>3341b9c1035f4e63a28414608ccda31f</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16816</td><td style=\"text-align: right;\"> 1680998024</td><td style=\"text-align: right;\">12206_00045</td></tr>\n",
       "<tr><td>train_12206_00046</td><td>2023-04-09_10-49-55</td><td>a6b2cb5999574c94930a0ce71be3c4ef</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16771</td><td style=\"text-align: right;\"> 1681004995</td><td style=\"text-align: right;\">12206_00046</td></tr>\n",
       "<tr><td>train_12206_00047</td><td>2023-04-09_11-11-12</td><td>3341b9c1035f4e63a28414608ccda31f</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16816</td><td style=\"text-align: right;\"> 1681006272</td><td style=\"text-align: right;\">12206_00047</td></tr>\n",
       "<tr><td>train_12206_00048</td><td>2023-04-09_12-29-07</td><td>a6b2cb5999574c94930a0ce71be3c4ef</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16771</td><td style=\"text-align: right;\"> 1681010947</td><td style=\"text-align: right;\">12206_00048</td></tr>\n",
       "<tr><td>train_12206_00049</td><td>2023-04-09_13-00-59</td><td>3341b9c1035f4e63a28414608ccda31f</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16816</td><td style=\"text-align: right;\"> 1681012859</td><td style=\"text-align: right;\">12206_00049</td></tr>\n",
       "<tr><td>train_12206_00050</td><td>2023-04-09_14-22-48</td><td>a6b2cb5999574c94930a0ce71be3c4ef</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16771</td><td style=\"text-align: right;\"> 1681017768</td><td style=\"text-align: right;\">12206_00050</td></tr>\n",
       "<tr><td>train_12206_00051</td><td>2023-04-09_14-58-00</td><td>3341b9c1035f4e63a28414608ccda31f</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16816</td><td style=\"text-align: right;\"> 1681019880</td><td style=\"text-align: right;\">12206_00051</td></tr>\n",
       "<tr><td>train_12206_00052</td><td>2023-04-09_16-27-49</td><td>a6b2cb5999574c94930a0ce71be3c4ef</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16771</td><td style=\"text-align: right;\"> 1681025269</td><td style=\"text-align: right;\">12206_00052</td></tr>\n",
       "<tr><td>train_12206_00053</td><td>2023-04-09_17-15-31</td><td>3341b9c1035f4e63a28414608ccda31f</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16816</td><td style=\"text-align: right;\"> 1681028131</td><td style=\"text-align: right;\">12206_00053</td></tr>\n",
       "<tr><td>train_12206_00054</td><td>2023-04-09_18-06-32</td><td>a6b2cb5999574c94930a0ce71be3c4ef</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16771</td><td style=\"text-align: right;\"> 1681031192</td><td style=\"text-align: right;\">12206_00054</td></tr>\n",
       "<tr><td>train_12206_00055</td><td>2023-04-09_19-05-21</td><td>3341b9c1035f4e63a28414608ccda31f</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16816</td><td style=\"text-align: right;\"> 1681034721</td><td style=\"text-align: right;\">12206_00055</td></tr>\n",
       "<tr><td>train_12206_00056</td><td>2023-04-09_19-59-07</td><td>a6b2cb5999574c94930a0ce71be3c4ef</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16771</td><td style=\"text-align: right;\"> 1681037947</td><td style=\"text-align: right;\">12206_00056</td></tr>\n",
       "<tr><td>train_12206_00057</td><td>2023-04-09_19-54-24</td><td>3341b9c1035f4e63a28414608ccda31f</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16816</td><td style=\"text-align: right;\"> 1681037664</td><td style=\"text-align: right;\">12206_00057</td></tr>\n",
       "<tr><td>train_12206_00058</td><td>2023-04-09_19-59-08</td><td>a6b2cb5999574c94930a0ce71be3c4ef</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">16771</td><td style=\"text-align: right;\"> 1681037948</td><td style=\"text-align: right;\">12206_00058</td></tr>\n",
       "<tr><td>train_12206_00059</td><td>2023-04-09_19-59-36</td><td>dfb301a8fda544bab26e369020ef0121</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">31196</td><td style=\"text-align: right;\"> 1681037976</td><td style=\"text-align: right;\">12206_00059</td></tr>\n",
       "<tr><td>train_12206_00060</td><td>2023-04-09_19-59-36</td><td>291761c5038b48c682144da41db7b243</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">31198</td><td style=\"text-align: right;\"> 1681037976</td><td style=\"text-align: right;\">12206_00060</td></tr>\n",
       "<tr><td>train_12206_00061</td><td>2023-04-09_20-01-38</td><td>907c1825cdef4546910823e0c3e8f45a</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">31366</td><td style=\"text-align: right;\"> 1681038098</td><td style=\"text-align: right;\">12206_00061</td></tr>\n",
       "<tr><td>train_12206_00062</td><td>2023-04-09_20-06-03</td><td>272bd557d3604025b421b3566eac4141</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">31532</td><td style=\"text-align: right;\"> 1681038363</td><td style=\"text-align: right;\">12206_00062</td></tr>\n",
       "<tr><td>train_12206_00063</td><td>2023-04-09_20-21-43</td><td>20403f27d6484db39fe49b2c7ea6acdd</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">31857</td><td style=\"text-align: right;\"> 1681039303</td><td style=\"text-align: right;\">12206_00063</td></tr>\n",
       "<tr><td>train_12206_00064</td><td>2023-04-09_20-30-19</td><td>f41f10b71ef44801a8a0fbfb6db6584f</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">32072</td><td style=\"text-align: right;\"> 1681039819</td><td style=\"text-align: right;\">12206_00064</td></tr>\n",
       "<tr><td>train_12206_00065</td><td>2023-04-09_20-34-20</td><td>86e4b611e4d84bb5afa5008ee31ff638</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">32226</td><td style=\"text-align: right;\"> 1681040060</td><td style=\"text-align: right;\">12206_00065</td></tr>\n",
       "<tr><td>train_12206_00066</td><td>2023-04-09_20-57-15</td><td>218504b50b8a45dca0c38d1c19774ca4</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">32653</td><td style=\"text-align: right;\"> 1681041435</td><td style=\"text-align: right;\">12206_00066</td></tr>\n",
       "<tr><td>train_12206_00067</td><td>2023-04-09_20-59-44</td><td>fc705d3012934397b59e292dd877f601</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">  329</td><td style=\"text-align: right;\"> 1681041584</td><td style=\"text-align: right;\">12206_00067</td></tr>\n",
       "<tr><td>train_12206_00068</td><td>2023-04-09_21-04-20</td><td>7c93e6d477f349b9a618bca9ed0c2a0b</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">  503</td><td style=\"text-align: right;\"> 1681041860</td><td style=\"text-align: right;\">12206_00068</td></tr>\n",
       "<tr><td>train_12206_00069</td><td>2023-04-09_21-05-10</td><td>f42b08ab295d4dbb9e404d4448c3572a</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">  631</td><td style=\"text-align: right;\"> 1681041910</td><td style=\"text-align: right;\">12206_00069</td></tr>\n",
       "<tr><td>train_12206_00070</td><td>2023-04-09_21-17-30</td><td>5dd339fff912459fa258022c30f89df7</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\">  923</td><td style=\"text-align: right;\"> 1681042650</td><td style=\"text-align: right;\">12206_00070</td></tr>\n",
       "<tr><td>train_12206_00071</td><td>2023-04-09_21-20-11</td><td>31ae8d20e603475490007b6cd4f9c136</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\"> 1078</td><td style=\"text-align: right;\"> 1681042811</td><td style=\"text-align: right;\">12206_00071</td></tr>\n",
       "<tr><td>train_12206_00072</td><td>2023-04-09_21-44-51</td><td>110fead732a6465eb0aa8774a214ee51</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\"> 1579</td><td style=\"text-align: right;\"> 1681044291</td><td style=\"text-align: right;\">12206_00072</td></tr>\n",
       "<tr><td>train_12206_00073</td><td>2023-04-09_21-47-09</td><td>6f529128ed7543979b788b9a34d409ad</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\"> 1715</td><td style=\"text-align: right;\"> 1681044429</td><td style=\"text-align: right;\">12206_00073</td></tr>\n",
       "<tr><td>train_12206_00074</td><td>2023-04-09_21-50-54</td><td>26e8413ba5514d289e6dc01cc36f10fa</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\"> 1868</td><td style=\"text-align: right;\"> 1681044654</td><td style=\"text-align: right;\">12206_00074</td></tr>\n",
       "<tr><td>train_12206_00075</td><td>2023-04-09_21-51-48</td><td>31698de79bf142e0aafcfad2d3423b1a</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\"> 1981</td><td style=\"text-align: right;\"> 1681044708</td><td style=\"text-align: right;\">12206_00075</td></tr>\n",
       "<tr><td>train_12206_00076</td><td>2023-04-09_22-04-01</td><td>bc706e3d62824116a79de3e9652a33f7</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\"> 2373</td><td style=\"text-align: right;\"> 1681045441</td><td style=\"text-align: right;\">12206_00076</td></tr>\n",
       "<tr><td>train_12206_00077</td><td>2023-04-09_22-06-34</td><td>45280c2499d54383b3a9825566af6b7f</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\"> 2507</td><td style=\"text-align: right;\"> 1681045594</td><td style=\"text-align: right;\">12206_00077</td></tr>\n",
       "<tr><td>train_12206_00078</td><td>2023-04-09_22-31-38</td><td>6300ae1479024c4f8ac6a93e76563de0</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\"> 3273</td><td style=\"text-align: right;\"> 1681047098</td><td style=\"text-align: right;\">12206_00078</td></tr>\n",
       "<tr><td>train_12206_00079</td><td>2023-04-09_22-33-38</td><td>83b49bf892b94a5eb163a785777200c4</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\"> 3402</td><td style=\"text-align: right;\"> 1681047218</td><td style=\"text-align: right;\">12206_00079</td></tr>\n",
       "<tr><td>train_12206_00080</td><td>2023-04-09_22-37-18</td><td>75c7fc8fd45b4321822157bfff670291</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\"> 3552</td><td style=\"text-align: right;\"> 1681047438</td><td style=\"text-align: right;\">12206_00080</td></tr>\n",
       "<tr><td>train_12206_00081</td><td>2023-04-09_22-38-07</td><td>e8068619304d4725bf3e2885835b65e6</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\"> 3662</td><td style=\"text-align: right;\"> 1681047487</td><td style=\"text-align: right;\">12206_00081</td></tr>\n",
       "<tr><td>train_12206_00082</td><td>2023-04-09_22-50-44</td><td>e6ddaec3c90d4a428e029a37ef2e5956</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\"> 3940</td><td style=\"text-align: right;\"> 1681048244</td><td style=\"text-align: right;\">12206_00082</td></tr>\n",
       "<tr><td>train_12206_00083</td><td>2023-04-09_22-53-04</td><td>8bfd1f82a51c4401a6c9f8d7d1d15098</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\"> 4067</td><td style=\"text-align: right;\"> 1681048384</td><td style=\"text-align: right;\">12206_00083</td></tr>\n",
       "<tr><td>train_12206_00084</td><td>2023-04-09_23-18-00</td><td>193903c91d8a4afa9f16a49baba859dc</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\"> 4526</td><td style=\"text-align: right;\"> 1681049880</td><td style=\"text-align: right;\">12206_00084</td></tr>\n",
       "<tr><td>train_12206_00085</td><td>2023-04-09_23-20-19</td><td>6ea6a86137904589ba3f12ba66acffd0</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\"> 4661</td><td style=\"text-align: right;\"> 1681050019</td><td style=\"text-align: right;\">12206_00085</td></tr>\n",
       "<tr><td>train_12206_00086</td><td>2023-04-09_23-23-45</td><td>c7aca78f39804a369cb0a69e781be289</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\"> 4814</td><td style=\"text-align: right;\"> 1681050225</td><td style=\"text-align: right;\">12206_00086</td></tr>\n",
       "<tr><td>train_12206_00087</td><td>2023-04-09_23-25-08</td><td>0d3375dc67f44b0abe722aa6ffc4e6a0</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\"> 4934</td><td style=\"text-align: right;\"> 1681050308</td><td style=\"text-align: right;\">12206_00087</td></tr>\n",
       "<tr><td>train_12206_00088</td><td>2023-04-09_23-37-26</td><td>9d69bdda4dce45eeabe1ef9d37454cd8</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\"> 5208</td><td style=\"text-align: right;\"> 1681051046</td><td style=\"text-align: right;\">12206_00088</td></tr>\n",
       "<tr><td>train_12206_00089</td><td>2023-04-09_23-39-22</td><td>14255d92b8054705a149aa4f796b9d59</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\"> 5340</td><td style=\"text-align: right;\"> 1681051162</td><td style=\"text-align: right;\">12206_00089</td></tr>\n",
       "<tr><td>train_12206_00090</td><td>2023-04-10_00-04-53</td><td>f67dfde88d624b06a8753765a5539024</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\"> 5796</td><td style=\"text-align: right;\"> 1681052693</td><td style=\"text-align: right;\">12206_00090</td></tr>\n",
       "<tr><td>train_12206_00091</td><td>2023-04-10_00-06-56</td><td>fd39369ada544a3dba4b6f70909e8e74</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\"> 6026</td><td style=\"text-align: right;\"> 1681052816</td><td style=\"text-align: right;\">12206_00091</td></tr>\n",
       "<tr><td>train_12206_00092</td><td>2023-04-10_00-10-16</td><td>32963115f72c43c6b22fb5aa95ed6503</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\"> 6177</td><td style=\"text-align: right;\"> 1681053016</td><td style=\"text-align: right;\">12206_00092</td></tr>\n",
       "<tr><td>train_12206_00093</td><td>2023-04-10_00-11-36</td><td>2f91d12ffc51427f8869ff64970359dd</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\"> 6292</td><td style=\"text-align: right;\"> 1681053096</td><td style=\"text-align: right;\">12206_00093</td></tr>\n",
       "<tr><td>train_12206_00094</td><td>2023-04-10_00-24-16</td><td>60aaf718f865484aac33a1a066926c3b</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\"> 6564</td><td style=\"text-align: right;\"> 1681053856</td><td style=\"text-align: right;\">12206_00094</td></tr>\n",
       "<tr><td>train_12206_00095</td><td>2023-04-10_00-25-58</td><td>6a606d8b436442d88ec98ef2c942bf26</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\"> 6692</td><td style=\"text-align: right;\"> 1681053958</td><td style=\"text-align: right;\">12206_00095</td></tr>\n",
       "<tr><td>train_12206_00096</td><td>2023-04-10_00-51-49</td><td>c7757c7a12c242ccb92470402403efed</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\"> 7144</td><td style=\"text-align: right;\"> 1681055509</td><td style=\"text-align: right;\">12206_00096</td></tr>\n",
       "<tr><td>train_12206_00097</td><td>2023-04-10_00-53-50</td><td>63f0e785d93c45bf957bbee3cf22b107</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\"> 7270</td><td style=\"text-align: right;\"> 1681055630</td><td style=\"text-align: right;\">12206_00097</td></tr>\n",
       "<tr><td>train_12206_00098</td><td>2023-04-10_00-56-43</td><td>606d19db3af348b584c0d9a895819a1c</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\"> 7406</td><td style=\"text-align: right;\"> 1681055803</td><td style=\"text-align: right;\">12206_00098</td></tr>\n",
       "<tr><td>train_12206_00099</td><td>2023-04-10_00-58-46</td><td>c8b4c68bb46c4b2cb78afd2600a85d95</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\"> 7531</td><td style=\"text-align: right;\"> 1681055926</td><td style=\"text-align: right;\">12206_00099</td></tr>\n",
       "<tr><td>train_12206_00100</td><td>2023-04-10_01-11-08</td><td>b8873acd446844b7bd8c11f5b655361c</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\"> 7806</td><td style=\"text-align: right;\"> 1681056668</td><td style=\"text-align: right;\">12206_00100</td></tr>\n",
       "<tr><td>train_12206_00101</td><td>2023-04-10_01-12-25</td><td>b6b0d5e432d2452dafb5554db83e1826</td><td>piai-Precision-Tower-7910</td><td>141.223.107.22</td><td style=\"text-align: right;\"> 7920</td><td style=\"text-align: right;\"> 1681056745</td><td style=\"text-align: right;\">12206_00101</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-07 14:11:57,700\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): SobelFilter\n",
      "  )\n",
      "), 'Loss Function': PixelLoss(\n",
      "  (pixel_loss): CrossEntropyLoss()\n",
      ")}\n",
      "2023-04-07 14:24:30,765\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): LaplacianFilter\n",
      "  )\n",
      "), 'Loss Function': PixelLoss(\n",
      "  (pixel_loss): CrossEntropyLoss()\n",
      ")}\n",
      "2023-04-07 16:03:00,167\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): FrangiFilter\n",
      "  )\n",
      "), 'Loss Function': PixelLoss(\n",
      "  (pixel_loss): CrossEntropyLoss()\n",
      ")}\n",
      "2023-04-07 16:22:27,309\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): SatoFilter\n",
      "  )\n",
      "), 'Loss Function': PixelLoss(\n",
      "  (pixel_loss): CrossEntropyLoss()\n",
      ")}\n",
      "2023-04-07 18:05:46,691\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): ('SumFilters', 'FrangiFilter', 'SatoFilter')\n",
      "  )\n",
      "), 'Loss Function': PixelLoss(\n",
      "  (pixel_loss): CrossEntropyLoss()\n",
      ")}\n",
      "2023-04-07 18:40:11,402\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): SkeletonFilter\n",
      "  )\n",
      "), 'Loss Function': PixelLoss(\n",
      "  (pixel_loss): CrossEntropyLoss()\n",
      ")}\n",
      "2023-04-07 19:44:01,041\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): SobelFilter\n",
      "  )\n",
      "), 'Loss Function': PixelLoss(\n",
      "  (pixel_loss): FocalLoss\n",
      ")}\n",
      "2023-04-07 20:30:45,783\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): LaplacianFilter\n",
      "  )\n",
      "), 'Loss Function': PixelLoss(\n",
      "  (pixel_loss): FocalLoss\n",
      ")}\n",
      "2023-04-07 21:35:30,557\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): FrangiFilter\n",
      "  )\n",
      "), 'Loss Function': PixelLoss(\n",
      "  (pixel_loss): FocalLoss\n",
      ")}\n",
      "2023-04-07 22:28:55,241\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): SatoFilter\n",
      "  )\n",
      "), 'Loss Function': PixelLoss(\n",
      "  (pixel_loss): FocalLoss\n",
      ")}\n",
      "2023-04-07 23:38:56,507\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): ('SumFilters', 'FrangiFilter', 'SatoFilter')\n",
      "  )\n",
      "), 'Loss Function': PixelLoss(\n",
      "  (pixel_loss): FocalLoss\n",
      ")}\n",
      "2023-04-08 00:47:16,913\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): SkeletonFilter\n",
      "  )\n",
      "), 'Loss Function': PixelLoss(\n",
      "  (pixel_loss): FocalLoss\n",
      ")}\n",
      "2023-04-08 01:17:00,057\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): SobelFilter\n",
      "  )\n",
      "), 'Loss Function': VolumeLoss(\n",
      "  (volume_loss): JaccardLoss\n",
      ")}\n",
      "2023-04-08 02:37:31,500\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): LaplacianFilter\n",
      "  )\n",
      "), 'Loss Function': VolumeLoss(\n",
      "  (volume_loss): JaccardLoss\n",
      ")}\n",
      "2023-04-08 03:08:30,609\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): FrangiFilter\n",
      "  )\n",
      "), 'Loss Function': VolumeLoss(\n",
      "  (volume_loss): JaccardLoss\n",
      ")}\n",
      "2023-04-08 04:35:17,287\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): SatoFilter\n",
      "  )\n",
      "), 'Loss Function': VolumeLoss(\n",
      "  (volume_loss): JaccardLoss\n",
      ")}\n",
      "2023-04-08 05:11:37,945\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): ('SumFilters', 'FrangiFilter', 'SatoFilter')\n",
      "  )\n",
      "), 'Loss Function': VolumeLoss(\n",
      "  (volume_loss): JaccardLoss\n",
      ")}\n",
      "2023-04-08 06:49:36,623\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): SobelFilter\n",
      "  )\n",
      "), 'Loss Function': VolumeLoss(\n",
      "  (volume_loss): TverskyLoss\n",
      ")}\n",
      "2023-04-08 06:53:10,395\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): SkeletonFilter\n",
      "  )\n",
      "), 'Loss Function': VolumeLoss(\n",
      "  (volume_loss): JaccardLoss\n",
      ")}\n",
      "2023-04-08 08:30:08,447\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): LaplacianFilter\n",
      "  )\n",
      "), 'Loss Function': VolumeLoss(\n",
      "  (volume_loss): TverskyLoss\n",
      ")}\n",
      "2023-04-08 08:54:17,501\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): FrangiFilter\n",
      "  )\n",
      "), 'Loss Function': VolumeLoss(\n",
      "  (volume_loss): TverskyLoss\n",
      ")}\n",
      "2023-04-08 10:18:28,745\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): SatoFilter\n",
      "  )\n",
      "), 'Loss Function': VolumeLoss(\n",
      "  (volume_loss): TverskyLoss\n",
      ")}\n",
      "2023-04-08 11:06:23,105\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): ('SumFilters', 'FrangiFilter', 'SatoFilter')\n",
      "  )\n",
      "), 'Loss Function': VolumeLoss(\n",
      "  (volume_loss): TverskyLoss\n",
      ")}\n",
      "2023-04-08 12:25:48,492\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): SkeletonFilter\n",
      "  )\n",
      "), 'Loss Function': VolumeLoss(\n",
      "  (volume_loss): TverskyLoss\n",
      ")}\n",
      "2023-04-08 12:54:44,252\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): SobelFilter\n",
      "  )\n",
      "), 'Loss Function': VolumeLoss(\n",
      "  (volume_loss): FocalTverskyLoss\n",
      ")}\n",
      "2023-04-08 14:06:25,441\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): LaplacianFilter\n",
      "  )\n",
      "), 'Loss Function': VolumeLoss(\n",
      "  (volume_loss): FocalTverskyLoss\n",
      ")}\n",
      "2023-04-08 14:55:57,071\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): FrangiFilter\n",
      "  )\n",
      "), 'Loss Function': VolumeLoss(\n",
      "  (volume_loss): FocalTverskyLoss\n",
      ")}\n",
      "2023-04-08 15:54:51,059\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): SatoFilter\n",
      "  )\n",
      "), 'Loss Function': VolumeLoss(\n",
      "  (volume_loss): FocalTverskyLoss\n",
      ")}\n",
      "2023-04-08 17:07:59,383\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): ('SumFilters', 'FrangiFilter', 'SatoFilter')\n",
      "  )\n",
      "), 'Loss Function': VolumeLoss(\n",
      "  (volume_loss): FocalTverskyLoss\n",
      ")}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-08 18:02:18,800\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): SkeletonFilter\n",
      "  )\n",
      "), 'Loss Function': VolumeLoss(\n",
      "  (volume_loss): FocalTverskyLoss\n",
      ")}\n",
      "2023-04-08 18:56:29,492\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): SobelFilter\n",
      "  )\n",
      "), 'Loss Function': CombinedLoss(\n",
      "  (loss1): CrossEntropyLoss()\n",
      "  (loss2): JaccardLoss\n",
      ")}\n",
      "2023-04-08 19:42:53,969\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): LaplacianFilter\n",
      "  )\n",
      "), 'Loss Function': CombinedLoss(\n",
      "  (loss1): CrossEntropyLoss()\n",
      "  (loss2): JaccardLoss\n",
      ")}\n",
      "2023-04-08 20:57:22,230\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): FrangiFilter\n",
      "  )\n",
      "), 'Loss Function': CombinedLoss(\n",
      "  (loss1): CrossEntropyLoss()\n",
      "  (loss2): JaccardLoss\n",
      ")}\n",
      "2023-04-08 21:31:15,527\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): SatoFilter\n",
      "  )\n",
      "), 'Loss Function': CombinedLoss(\n",
      "  (loss1): CrossEntropyLoss()\n",
      "  (loss2): JaccardLoss\n",
      ")}\n",
      "2023-04-08 23:09:21,329\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): ('SumFilters', 'FrangiFilter', 'SatoFilter')\n",
      "  )\n",
      "), 'Loss Function': CombinedLoss(\n",
      "  (loss1): CrossEntropyLoss()\n",
      "  (loss2): JaccardLoss\n",
      ")}\n",
      "2023-04-08 23:38:20,825\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): SkeletonFilter\n",
      "  )\n",
      "), 'Loss Function': CombinedLoss(\n",
      "  (loss1): CrossEntropyLoss()\n",
      "  (loss2): JaccardLoss\n",
      ")}\n",
      "2023-04-09 00:57:03,070\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): SobelFilter\n",
      "  )\n",
      "), 'Loss Function': BorderedLoss(\n",
      "  (border_loss): CrossEntropyLoss()\n",
      "  (volume_loss): JaccardLoss\n",
      ")}\n",
      "2023-04-09 01:18:50,031\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): LaplacianFilter\n",
      "  )\n",
      "), 'Loss Function': BorderedLoss(\n",
      "  (border_loss): CrossEntropyLoss()\n",
      "  (volume_loss): JaccardLoss\n",
      ")}\n",
      "2023-04-09 02:57:26,629\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): FrangiFilter\n",
      "  )\n",
      "), 'Loss Function': BorderedLoss(\n",
      "  (border_loss): CrossEntropyLoss()\n",
      "  (volume_loss): JaccardLoss\n",
      ")}\n",
      "2023-04-09 03:06:54,405\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): SatoFilter\n",
      "  )\n",
      "), 'Loss Function': BorderedLoss(\n",
      "  (border_loss): CrossEntropyLoss()\n",
      "  (volume_loss): JaccardLoss\n",
      ")}\n",
      "2023-04-09 05:09:25,722\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): ('SumFilters', 'FrangiFilter', 'SatoFilter')\n",
      "  )\n",
      "), 'Loss Function': BorderedLoss(\n",
      "  (border_loss): CrossEntropyLoss()\n",
      "  (volume_loss): JaccardLoss\n",
      ")}\n",
      "2023-04-09 05:13:59,579\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): SkeletonFilter\n",
      "  )\n",
      "), 'Loss Function': BorderedLoss(\n",
      "  (border_loss): CrossEntropyLoss()\n",
      "  (volume_loss): JaccardLoss\n",
      ")}\n",
      "2023-04-09 06:54:22,888\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): LaplacianFilter\n",
      "  )\n",
      "), 'Loss Function': CombinedLoss(\n",
      "  (loss1): CrossEntropyLoss()\n",
      "  (loss2): TverskyLoss\n",
      ")}\n",
      "2023-04-09 06:56:23,036\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): SobelFilter\n",
      "  )\n",
      "), 'Loss Function': CombinedLoss(\n",
      "  (loss1): CrossEntropyLoss()\n",
      "  (loss2): TverskyLoss\n",
      ")}\n",
      "2023-04-09 08:46:15,917\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): FrangiFilter\n",
      "  )\n",
      "), 'Loss Function': CombinedLoss(\n",
      "  (loss1): CrossEntropyLoss()\n",
      "  (loss2): TverskyLoss\n",
      ")}\n",
      "2023-04-09 08:53:44,436\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): SatoFilter\n",
      "  )\n",
      "), 'Loss Function': CombinedLoss(\n",
      "  (loss1): CrossEntropyLoss()\n",
      "  (loss2): TverskyLoss\n",
      ")}\n",
      "2023-04-09 10:49:55,436\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): ('SumFilters', 'FrangiFilter', 'SatoFilter')\n",
      "  )\n",
      "), 'Loss Function': CombinedLoss(\n",
      "  (loss1): CrossEntropyLoss()\n",
      "  (loss2): TverskyLoss\n",
      ")}\n",
      "2023-04-09 11:11:12,532\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): SkeletonFilter\n",
      "  )\n",
      "), 'Loss Function': CombinedLoss(\n",
      "  (loss1): CrossEntropyLoss()\n",
      "  (loss2): TverskyLoss\n",
      ")}\n",
      "2023-04-09 12:29:08,162\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): SobelFilter\n",
      "  )\n",
      "), 'Loss Function': BorderedLoss(\n",
      "  (border_loss): CrossEntropyLoss()\n",
      "  (volume_loss): TverskyLoss\n",
      ")}\n",
      "2023-04-09 13:00:59,570\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): LaplacianFilter\n",
      "  )\n",
      "), 'Loss Function': BorderedLoss(\n",
      "  (border_loss): CrossEntropyLoss()\n",
      "  (volume_loss): TverskyLoss\n",
      ")}\n",
      "2023-04-09 14:22:48,793\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): FrangiFilter\n",
      "  )\n",
      "), 'Loss Function': BorderedLoss(\n",
      "  (border_loss): CrossEntropyLoss()\n",
      "  (volume_loss): TverskyLoss\n",
      ")}\n",
      "2023-04-09 14:58:00,427\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): SatoFilter\n",
      "  )\n",
      "), 'Loss Function': BorderedLoss(\n",
      "  (border_loss): CrossEntropyLoss()\n",
      "  (volume_loss): TverskyLoss\n",
      ")}\n",
      "2023-04-09 16:27:50,042\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): ('SumFilters', 'FrangiFilter', 'SatoFilter')\n",
      "  )\n",
      "), 'Loss Function': BorderedLoss(\n",
      "  (border_loss): CrossEntropyLoss()\n",
      "  (volume_loss): TverskyLoss\n",
      ")}\n",
      "2023-04-09 17:15:31,504\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): SkeletonFilter\n",
      "  )\n",
      "), 'Loss Function': BorderedLoss(\n",
      "  (border_loss): CrossEntropyLoss()\n",
      "  (volume_loss): TverskyLoss\n",
      ")}\n",
      "2023-04-09 18:06:32,899\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): SobelFilter\n",
      "  )\n",
      "), 'Loss Function': CombinedLoss(\n",
      "  (loss1): CrossEntropyLoss()\n",
      "  (loss2): FocalTverskyLoss\n",
      ")}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-09 19:05:22,110\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): LaplacianFilter\n",
      "  )\n",
      "), 'Loss Function': CombinedLoss(\n",
      "  (loss1): CrossEntropyLoss()\n",
      "  (loss2): FocalTverskyLoss\n",
      ")}\n",
      "2023-04-09 19:59:08,093\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): FrangiFilter\n",
      "  )\n",
      "), 'Loss Function': CombinedLoss(\n",
      "  (loss1): CrossEntropyLoss()\n",
      "  (loss2): FocalTverskyLoss\n",
      ")}\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-04-09 19:59:11,939 E 16313 16313] (raylet) node_manager.cc:3040: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: f23f2b0e98a5dbe3f362b7b0159eafdd21a7c11a8d8772aa42c80af4, IP: 141.223.107.22) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 141.223.107.22`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "2023-04-09 19:59:22,849\tERROR trial_runner.py:1062 -- Trial train_12206_00057: Error processing event.\n",
      "ray.tune.error._TuneNoNextExecutorEventError: Traceback (most recent call last):\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/execution/ray_trial_executor.py\", line 1276, in get_next_executor_event\n",
      "    future_result = ray.get(ready_future)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/_private/worker.py\", line 2382, in get\n",
      "    raise value\n",
      "ray.exceptions.OutOfMemoryError: Task was killed due to the node running low on memory.\n",
      "Memory on the node (IP: 141.223.107.22, ID: f23f2b0e98a5dbe3f362b7b0159eafdd21a7c11a8d8772aa42c80af4) where the task (actor ID: d5952f6239d95a5876c3007901000000, name=ImplicitFunc.__init__, pid=16816, memory used=0.20GB) was running was 62.25GB / 62.73GB (0.992289), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 1334020eb1e86d1422e1ecf00a0e700de3508f042fd892e204a9aa6c) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 141.223.107.22`. To see the logs of the worker, use `ray logs worker-1334020eb1e86d1422e1ecf00a0e700de3508f042fd892e204a9aa6c*out -ip 141.223.107.22. Top 10 memory users:\n",
      "PID\tMEM(GB)\tCOMMAND\n",
      "16771\t29.07\tray::ImplicitFunc.train\n",
      "16139\t11.03\t/home/piai/anaconda3/envs/POC-env/bin/python -m ipykernel_launcher -f /home/piai/.local/share/jupyte...\n",
      "3088\t0.27\t/opt/google/chrome/chrome\n",
      "2663\t0.20\t/usr/bin/gnome-shell\n",
      "16816\t0.20\tray::ImplicitFunc.train\n",
      "3035\t0.17\t/usr/bin/gnome-software --gapplication-service\n",
      "16313\t0.16\t/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayl...\n",
      "16185\t0.13\t/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log...\n",
      "3137\t0.11\t/opt/google/chrome/chrome --type=gpu-process --crashpad-handler-pid=3097 --enable-crash-reporter=fad...\n",
      "26918\t0.10\t/home/piai/anaconda3/bin/python /home/piai/anaconda3/bin/jupyter-notebook\n",
      "Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\n",
      "2023-04-09 19:59:22,939\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): SatoFilter\n",
      "  )\n",
      "), 'Loss Function': CombinedLoss(\n",
      "  (loss1): CrossEntropyLoss()\n",
      "  (loss2): FocalTverskyLoss\n",
      ")}\n",
      "2023-04-09 19:59:27,700\tERROR ray_trial_executor.py:930 -- An exception occurred when trying to stop the Ray actor:Traceback (most recent call last):\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/execution/ray_trial_executor.py\", line 921, in _resolve_stop_event\n",
      "    ray.get(future, timeout=timeout)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/_private/worker.py\", line 2382, in get\n",
      "    raise value\n",
      "ray.exceptions.OutOfMemoryError: Task was killed due to the node running low on memory.\n",
      "Memory on the node (IP: 141.223.107.22, ID: f23f2b0e98a5dbe3f362b7b0159eafdd21a7c11a8d8772aa42c80af4) where the task (actor ID: d5952f6239d95a5876c3007901000000, name=ImplicitFunc.__init__, pid=16816, memory used=0.20GB) was running was 62.25GB / 62.73GB (0.992289), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 1334020eb1e86d1422e1ecf00a0e700de3508f042fd892e204a9aa6c) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 141.223.107.22`. To see the logs of the worker, use `ray logs worker-1334020eb1e86d1422e1ecf00a0e700de3508f042fd892e204a9aa6c*out -ip 141.223.107.22. Top 10 memory users:\n",
      "PID\tMEM(GB)\tCOMMAND\n",
      "16771\t29.07\tray::ImplicitFunc.train\n",
      "16139\t11.03\t/home/piai/anaconda3/envs/POC-env/bin/python -m ipykernel_launcher -f /home/piai/.local/share/jupyte...\n",
      "3088\t0.27\t/opt/google/chrome/chrome\n",
      "2663\t0.20\t/usr/bin/gnome-shell\n",
      "16816\t0.20\tray::ImplicitFunc.train\n",
      "3035\t0.17\t/usr/bin/gnome-software --gapplication-service\n",
      "16313\t0.16\t/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayl...\n",
      "16185\t0.13\t/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log...\n",
      "3137\t0.11\t/opt/google/chrome/chrome --type=gpu-process --crashpad-handler-pid=3097 --enable-crash-reporter=fad...\n",
      "26918\t0.10\t/home/piai/anaconda3/bin/python /home/piai/anaconda3/bin/jupyter-notebook\n",
      "Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\n",
      "2023-04-09 19:59:29,529\tERROR trial_runner.py:1062 -- Trial train_12206_00058: Error processing event.\n",
      "ray.tune.error._TuneNoNextExecutorEventError: Traceback (most recent call last):\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/execution/ray_trial_executor.py\", line 1276, in get_next_executor_event\n",
      "    future_result = ray.get(ready_future)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/_private/worker.py\", line 2382, in get\n",
      "    raise value\n",
      "ray.exceptions.OutOfMemoryError: Task was killed due to the node running low on memory.\n",
      "Memory on the node (IP: 141.223.107.22, ID: f23f2b0e98a5dbe3f362b7b0159eafdd21a7c11a8d8772aa42c80af4) where the task (actor ID: a9ecbb3dd7afd6eb179a420e01000000, name=ImplicitFunc.__init__, pid=16771, memory used=29.75GB) was running was 62.70GB / 62.73GB (0.999528), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: a6c1d636f78314551e794a44d14f10d1a86c4670dbfaeaec556b9d52) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 141.223.107.22`. To see the logs of the worker, use `ray logs worker-a6c1d636f78314551e794a44d14f10d1a86c4670dbfaeaec556b9d52*out -ip 141.223.107.22. Top 10 memory users:\n",
      "PID\tMEM(GB)\tCOMMAND\n",
      "16771\t29.75\tray::ImplicitFunc.train\n",
      "31023\t13.74\tray::ImplicitFunc.train\n",
      "16139\t11.04\t/home/piai/anaconda3/envs/POC-env/bin/python -m ipykernel_launcher -f /home/piai/.local/share/jupyte...\n",
      "3088\t0.26\t/opt/google/chrome/chrome\n",
      "2663\t0.19\t/usr/bin/gnome-shell\n",
      "3035\t0.17\t/usr/bin/gnome-software --gapplication-service\n",
      "16313\t0.16\t/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayl...\n",
      "16185\t0.14\t/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log...\n",
      "3137\t0.11\t/opt/google/chrome/chrome --type=gpu-process --crashpad-handler-pid=3097 --enable-crash-reporter=fad...\n",
      "26918\t0.10\t/home/piai/anaconda3/bin/python /home/piai/anaconda3/bin/jupyter-notebook\n",
      "Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=31198)\u001b[0m /home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "\u001b[2m\u001b[36m(train pid=31198)\u001b[0m   return torch._C._cuda_getDeviceCount() > 0\n",
      "\u001b[2m\u001b[36m(train pid=31196)\u001b[0m /home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "\u001b[2m\u001b[36m(train pid=31196)\u001b[0m   return torch._C._cuda_getDeviceCount() > 0\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-04-09 20:00:11,941 E 16313 16313] (raylet) node_manager.cc:3040: 3 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: f23f2b0e98a5dbe3f362b7b0159eafdd21a7c11a8d8772aa42c80af4, IP: 141.223.107.22) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 141.223.107.22`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "2023-04-09 20:01:34,428\tERROR trial_runner.py:1062 -- Trial train_12206_00060: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=31198, ip=141.223.107.22, repr=train)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_16139/26714430.py\", line 94, in train\n",
      "  File \"/home/piai/Documents/POC-Project/src/train.py\", line 10, in training_loop\n",
      "    for batch_idx, (X, Y, _, items_index) in enumerate(dataloader):\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 435, in __iter__\n",
      "    return self._get_iterator()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 381, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1046, in __init__\n",
      "    torch.cuda.current_device(),\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 552, in current_device\n",
      "    _lazy_init()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 229, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW\n",
      "\u001b[2m\u001b[36m(train pid=31366)\u001b[0m /home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "\u001b[2m\u001b[36m(train pid=31366)\u001b[0m   return torch._C._cuda_getDeviceCount() > 0\n",
      "2023-04-09 20:05:58,879\tERROR trial_runner.py:1062 -- Trial train_12206_00061: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=31366, ip=141.223.107.22, repr=train)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_16139/26714430.py\", line 94, in train\n",
      "  File \"/home/piai/Documents/POC-Project/src/train.py\", line 10, in training_loop\n",
      "    for batch_idx, (X, Y, _, items_index) in enumerate(dataloader):\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 435, in __iter__\n",
      "    return self._get_iterator()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 381, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1046, in __init__\n",
      "    torch.cuda.current_device(),\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 552, in current_device\n",
      "    _lazy_init()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 229, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW\n",
      "\u001b[2m\u001b[36m(train pid=31532)\u001b[0m /home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "\u001b[2m\u001b[36m(train pid=31532)\u001b[0m   return torch._C._cuda_getDeviceCount() > 0\n",
      "2023-04-09 20:21:39,356\tERROR trial_runner.py:1062 -- Trial train_12206_00062: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=31532, ip=141.223.107.22, repr=train)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_16139/26714430.py\", line 94, in train\n",
      "  File \"/home/piai/Documents/POC-Project/src/train.py\", line 10, in training_loop\n",
      "    for batch_idx, (X, Y, _, items_index) in enumerate(dataloader):\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 435, in __iter__\n",
      "    return self._get_iterator()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 381, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1046, in __init__\n",
      "    torch.cuda.current_device(),\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 552, in current_device\n",
      "    _lazy_init()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 229, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=31857)\u001b[0m /home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "\u001b[2m\u001b[36m(train pid=31857)\u001b[0m   return torch._C._cuda_getDeviceCount() > 0\n",
      "2023-04-09 20:30:14,261\tERROR trial_runner.py:1062 -- Trial train_12206_00059: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=31196, ip=141.223.107.22, repr=train)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_16139/26714430.py\", line 94, in train\n",
      "  File \"/home/piai/Documents/POC-Project/src/train.py\", line 10, in training_loop\n",
      "    for batch_idx, (X, Y, _, items_index) in enumerate(dataloader):\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 435, in __iter__\n",
      "    return self._get_iterator()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 381, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1046, in __init__\n",
      "    torch.cuda.current_device(),\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 552, in current_device\n",
      "    _lazy_init()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 229, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW\n",
      "\u001b[2m\u001b[36m(train pid=32072)\u001b[0m /home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "\u001b[2m\u001b[36m(train pid=32072)\u001b[0m   return torch._C._cuda_getDeviceCount() > 0\n",
      "2023-04-09 20:34:15,656\tERROR trial_runner.py:1062 -- Trial train_12206_00063: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=31857, ip=141.223.107.22, repr=train)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_16139/26714430.py\", line 94, in train\n",
      "  File \"/home/piai/Documents/POC-Project/src/train.py\", line 10, in training_loop\n",
      "    for batch_idx, (X, Y, _, items_index) in enumerate(dataloader):\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 435, in __iter__\n",
      "    return self._get_iterator()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 381, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1046, in __init__\n",
      "    torch.cuda.current_device(),\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 552, in current_device\n",
      "    _lazy_init()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 229, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW\n",
      "\u001b[2m\u001b[36m(train pid=32226)\u001b[0m /home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "\u001b[2m\u001b[36m(train pid=32226)\u001b[0m   return torch._C._cuda_getDeviceCount() > 0\n",
      "2023-04-09 20:57:11,309\tERROR trial_runner.py:1062 -- Trial train_12206_00064: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=32072, ip=141.223.107.22, repr=train)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_16139/26714430.py\", line 94, in train\n",
      "  File \"/home/piai/Documents/POC-Project/src/train.py\", line 10, in training_loop\n",
      "    for batch_idx, (X, Y, _, items_index) in enumerate(dataloader):\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 435, in __iter__\n",
      "    return self._get_iterator()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 381, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1046, in __init__\n",
      "    torch.cuda.current_device(),\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 552, in current_device\n",
      "    _lazy_init()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 229, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=32653)\u001b[0m /home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "\u001b[2m\u001b[36m(train pid=32653)\u001b[0m   return torch._C._cuda_getDeviceCount() > 0\n",
      "2023-04-09 20:59:39,476\tERROR trial_runner.py:1062 -- Trial train_12206_00066: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=32653, ip=141.223.107.22, repr=train)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_16139/26714430.py\", line 94, in train\n",
      "  File \"/home/piai/Documents/POC-Project/src/train.py\", line 10, in training_loop\n",
      "    for batch_idx, (X, Y, _, items_index) in enumerate(dataloader):\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 435, in __iter__\n",
      "    return self._get_iterator()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 381, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1046, in __init__\n",
      "    torch.cuda.current_device(),\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 552, in current_device\n",
      "    _lazy_init()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 229, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW\n",
      "\u001b[2m\u001b[36m(train pid=329)\u001b[0m /home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "\u001b[2m\u001b[36m(train pid=329)\u001b[0m   return torch._C._cuda_getDeviceCount() > 0\n",
      "2023-04-09 21:04:16,268\tERROR trial_runner.py:1062 -- Trial train_12206_00067: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=329, ip=141.223.107.22, repr=train)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_16139/26714430.py\", line 94, in train\n",
      "  File \"/home/piai/Documents/POC-Project/src/train.py\", line 10, in training_loop\n",
      "    for batch_idx, (X, Y, _, items_index) in enumerate(dataloader):\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 435, in __iter__\n",
      "    return self._get_iterator()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 381, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1046, in __init__\n",
      "    torch.cuda.current_device(),\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 552, in current_device\n",
      "    _lazy_init()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 229, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW\n",
      "\u001b[2m\u001b[36m(train pid=503)\u001b[0m /home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "\u001b[2m\u001b[36m(train pid=503)\u001b[0m   return torch._C._cuda_getDeviceCount() > 0\n",
      "2023-04-09 21:05:06,266\tERROR trial_runner.py:1062 -- Trial train_12206_00065: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=32226, ip=141.223.107.22, repr=train)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_16139/26714430.py\", line 94, in train\n",
      "  File \"/home/piai/Documents/POC-Project/src/train.py\", line 10, in training_loop\n",
      "    for batch_idx, (X, Y, _, items_index) in enumerate(dataloader):\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 435, in __iter__\n",
      "    return self._get_iterator()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 381, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1046, in __init__\n",
      "    torch.cuda.current_device(),\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 552, in current_device\n",
      "    _lazy_init()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 229, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=631)\u001b[0m /home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "\u001b[2m\u001b[36m(train pid=631)\u001b[0m   return torch._C._cuda_getDeviceCount() > 0\n",
      "2023-04-09 21:17:25,638\tERROR trial_runner.py:1062 -- Trial train_12206_00069: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=631, ip=141.223.107.22, repr=train)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_16139/26714430.py\", line 94, in train\n",
      "  File \"/home/piai/Documents/POC-Project/src/train.py\", line 10, in training_loop\n",
      "    for batch_idx, (X, Y, _, items_index) in enumerate(dataloader):\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 435, in __iter__\n",
      "    return self._get_iterator()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 381, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1046, in __init__\n",
      "    torch.cuda.current_device(),\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 552, in current_device\n",
      "    _lazy_init()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 229, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW\n",
      "\u001b[2m\u001b[36m(train pid=923)\u001b[0m /home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "\u001b[2m\u001b[36m(train pid=923)\u001b[0m   return torch._C._cuda_getDeviceCount() > 0\n",
      "2023-04-09 21:20:07,055\tERROR trial_runner.py:1062 -- Trial train_12206_00068: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=503, ip=141.223.107.22, repr=train)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_16139/26714430.py\", line 94, in train\n",
      "  File \"/home/piai/Documents/POC-Project/src/train.py\", line 10, in training_loop\n",
      "    for batch_idx, (X, Y, _, items_index) in enumerate(dataloader):\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 435, in __iter__\n",
      "    return self._get_iterator()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 381, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1046, in __init__\n",
      "    torch.cuda.current_device(),\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 552, in current_device\n",
      "    _lazy_init()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 229, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW\n",
      "\u001b[2m\u001b[36m(train pid=1078)\u001b[0m /home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "\u001b[2m\u001b[36m(train pid=1078)\u001b[0m   return torch._C._cuda_getDeviceCount() > 0\n",
      "2023-04-09 21:44:47,167\tERROR trial_runner.py:1062 -- Trial train_12206_00070: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=923, ip=141.223.107.22, repr=train)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_16139/26714430.py\", line 94, in train\n",
      "  File \"/home/piai/Documents/POC-Project/src/train.py\", line 10, in training_loop\n",
      "    for batch_idx, (X, Y, _, items_index) in enumerate(dataloader):\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 435, in __iter__\n",
      "    return self._get_iterator()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 381, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1046, in __init__\n",
      "    torch.cuda.current_device(),\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 552, in current_device\n",
      "    _lazy_init()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 229, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=1579)\u001b[0m /home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "\u001b[2m\u001b[36m(train pid=1579)\u001b[0m   return torch._C._cuda_getDeviceCount() > 0\n",
      "2023-04-09 21:47:05,672\tERROR trial_runner.py:1062 -- Trial train_12206_00072: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=1579, ip=141.223.107.22, repr=train)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_16139/26714430.py\", line 94, in train\n",
      "  File \"/home/piai/Documents/POC-Project/src/train.py\", line 10, in training_loop\n",
      "    for batch_idx, (X, Y, _, items_index) in enumerate(dataloader):\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 435, in __iter__\n",
      "    return self._get_iterator()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 381, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1046, in __init__\n",
      "    torch.cuda.current_device(),\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 552, in current_device\n",
      "    _lazy_init()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 229, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW\n",
      "\u001b[2m\u001b[36m(train pid=1715)\u001b[0m /home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "\u001b[2m\u001b[36m(train pid=1715)\u001b[0m   return torch._C._cuda_getDeviceCount() > 0\n",
      "2023-04-09 21:50:49,442\tERROR trial_runner.py:1062 -- Trial train_12206_00071: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=1078, ip=141.223.107.22, repr=train)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_16139/26714430.py\", line 94, in train\n",
      "  File \"/home/piai/Documents/POC-Project/src/train.py\", line 10, in training_loop\n",
      "    for batch_idx, (X, Y, _, items_index) in enumerate(dataloader):\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 435, in __iter__\n",
      "    return self._get_iterator()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 381, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1046, in __init__\n",
      "    torch.cuda.current_device(),\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 552, in current_device\n",
      "    _lazy_init()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 229, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW\n",
      "\u001b[2m\u001b[36m(train pid=1868)\u001b[0m /home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "\u001b[2m\u001b[36m(train pid=1868)\u001b[0m   return torch._C._cuda_getDeviceCount() > 0\n",
      "2023-04-09 21:51:43,894\tERROR trial_runner.py:1062 -- Trial train_12206_00073: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=1715, ip=141.223.107.22, repr=train)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_16139/26714430.py\", line 94, in train\n",
      "  File \"/home/piai/Documents/POC-Project/src/train.py\", line 10, in training_loop\n",
      "    for batch_idx, (X, Y, _, items_index) in enumerate(dataloader):\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 435, in __iter__\n",
      "    return self._get_iterator()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 381, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1046, in __init__\n",
      "    torch.cuda.current_device(),\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 552, in current_device\n",
      "    _lazy_init()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 229, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=1981)\u001b[0m /home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "\u001b[2m\u001b[36m(train pid=1981)\u001b[0m   return torch._C._cuda_getDeviceCount() > 0\n",
      "2023-04-09 22:03:56,622\tERROR trial_runner.py:1062 -- Trial train_12206_00075: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=1981, ip=141.223.107.22, repr=train)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_16139/26714430.py\", line 94, in train\n",
      "  File \"/home/piai/Documents/POC-Project/src/train.py\", line 10, in training_loop\n",
      "    for batch_idx, (X, Y, _, items_index) in enumerate(dataloader):\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 435, in __iter__\n",
      "    return self._get_iterator()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 381, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1046, in __init__\n",
      "    torch.cuda.current_device(),\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 552, in current_device\n",
      "    _lazy_init()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 229, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW\n",
      "\u001b[2m\u001b[36m(train pid=2373)\u001b[0m /home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "\u001b[2m\u001b[36m(train pid=2373)\u001b[0m   return torch._C._cuda_getDeviceCount() > 0\n",
      "2023-04-09 22:06:29,865\tERROR trial_runner.py:1062 -- Trial train_12206_00074: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=1868, ip=141.223.107.22, repr=train)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_16139/26714430.py\", line 94, in train\n",
      "  File \"/home/piai/Documents/POC-Project/src/train.py\", line 10, in training_loop\n",
      "    for batch_idx, (X, Y, _, items_index) in enumerate(dataloader):\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 435, in __iter__\n",
      "    return self._get_iterator()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 381, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1046, in __init__\n",
      "    torch.cuda.current_device(),\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 552, in current_device\n",
      "    _lazy_init()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 229, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW\n",
      "\u001b[2m\u001b[36m(train pid=2507)\u001b[0m /home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "\u001b[2m\u001b[36m(train pid=2507)\u001b[0m   return torch._C._cuda_getDeviceCount() > 0\n",
      "2023-04-09 22:31:33,783\tERROR trial_runner.py:1062 -- Trial train_12206_00076: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=2373, ip=141.223.107.22, repr=train)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_16139/26714430.py\", line 94, in train\n",
      "  File \"/home/piai/Documents/POC-Project/src/train.py\", line 10, in training_loop\n",
      "    for batch_idx, (X, Y, _, items_index) in enumerate(dataloader):\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 435, in __iter__\n",
      "    return self._get_iterator()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 381, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1046, in __init__\n",
      "    torch.cuda.current_device(),\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 552, in current_device\n",
      "    _lazy_init()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 229, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=3273)\u001b[0m /home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "\u001b[2m\u001b[36m(train pid=3273)\u001b[0m   return torch._C._cuda_getDeviceCount() > 0\n",
      "2023-04-09 22:33:34,374\tERROR trial_runner.py:1062 -- Trial train_12206_00078: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=3273, ip=141.223.107.22, repr=train)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_16139/26714430.py\", line 94, in train\n",
      "  File \"/home/piai/Documents/POC-Project/src/train.py\", line 10, in training_loop\n",
      "    for batch_idx, (X, Y, _, items_index) in enumerate(dataloader):\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 435, in __iter__\n",
      "    return self._get_iterator()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 381, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1046, in __init__\n",
      "    torch.cuda.current_device(),\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 552, in current_device\n",
      "    _lazy_init()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 229, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW\n",
      "\u001b[2m\u001b[36m(train pid=3402)\u001b[0m /home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "\u001b[2m\u001b[36m(train pid=3402)\u001b[0m   return torch._C._cuda_getDeviceCount() > 0\n",
      "2023-04-09 22:37:14,332\tERROR trial_runner.py:1062 -- Trial train_12206_00077: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=2507, ip=141.223.107.22, repr=train)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_16139/26714430.py\", line 94, in train\n",
      "  File \"/home/piai/Documents/POC-Project/src/train.py\", line 10, in training_loop\n",
      "    for batch_idx, (X, Y, _, items_index) in enumerate(dataloader):\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 435, in __iter__\n",
      "    return self._get_iterator()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 381, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1046, in __init__\n",
      "    torch.cuda.current_device(),\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 552, in current_device\n",
      "    _lazy_init()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 229, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW\n",
      "\u001b[2m\u001b[36m(train pid=3552)\u001b[0m /home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "\u001b[2m\u001b[36m(train pid=3552)\u001b[0m   return torch._C._cuda_getDeviceCount() > 0\n",
      "2023-04-09 22:38:02,842\tERROR trial_runner.py:1062 -- Trial train_12206_00079: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=3402, ip=141.223.107.22, repr=train)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_16139/26714430.py\", line 94, in train\n",
      "  File \"/home/piai/Documents/POC-Project/src/train.py\", line 10, in training_loop\n",
      "    for batch_idx, (X, Y, _, items_index) in enumerate(dataloader):\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 435, in __iter__\n",
      "    return self._get_iterator()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 381, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1046, in __init__\n",
      "    torch.cuda.current_device(),\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 552, in current_device\n",
      "    _lazy_init()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 229, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=3662)\u001b[0m /home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "\u001b[2m\u001b[36m(train pid=3662)\u001b[0m   return torch._C._cuda_getDeviceCount() > 0\n",
      "2023-04-09 22:50:40,120\tERROR trial_runner.py:1062 -- Trial train_12206_00081: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=3662, ip=141.223.107.22, repr=train)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_16139/26714430.py\", line 94, in train\n",
      "  File \"/home/piai/Documents/POC-Project/src/train.py\", line 10, in training_loop\n",
      "    for batch_idx, (X, Y, _, items_index) in enumerate(dataloader):\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 435, in __iter__\n",
      "    return self._get_iterator()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 381, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1046, in __init__\n",
      "    torch.cuda.current_device(),\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 552, in current_device\n",
      "    _lazy_init()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 229, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW\n",
      "\u001b[2m\u001b[36m(train pid=3940)\u001b[0m /home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "\u001b[2m\u001b[36m(train pid=3940)\u001b[0m   return torch._C._cuda_getDeviceCount() > 0\n",
      "2023-04-09 22:52:59,937\tERROR trial_runner.py:1062 -- Trial train_12206_00080: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=3552, ip=141.223.107.22, repr=train)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_16139/26714430.py\", line 94, in train\n",
      "  File \"/home/piai/Documents/POC-Project/src/train.py\", line 10, in training_loop\n",
      "    for batch_idx, (X, Y, _, items_index) in enumerate(dataloader):\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 435, in __iter__\n",
      "    return self._get_iterator()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 381, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1046, in __init__\n",
      "    torch.cuda.current_device(),\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 552, in current_device\n",
      "    _lazy_init()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 229, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW\n",
      "\u001b[2m\u001b[36m(train pid=4067)\u001b[0m /home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "\u001b[2m\u001b[36m(train pid=4067)\u001b[0m   return torch._C._cuda_getDeviceCount() > 0\n",
      "2023-04-09 23:17:56,102\tERROR trial_runner.py:1062 -- Trial train_12206_00082: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=3940, ip=141.223.107.22, repr=train)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_16139/26714430.py\", line 94, in train\n",
      "  File \"/home/piai/Documents/POC-Project/src/train.py\", line 10, in training_loop\n",
      "    for batch_idx, (X, Y, _, items_index) in enumerate(dataloader):\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 435, in __iter__\n",
      "    return self._get_iterator()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 381, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1046, in __init__\n",
      "    torch.cuda.current_device(),\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 552, in current_device\n",
      "    _lazy_init()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 229, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=4526)\u001b[0m /home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "\u001b[2m\u001b[36m(train pid=4526)\u001b[0m   return torch._C._cuda_getDeviceCount() > 0\n",
      "2023-04-09 23:20:14,935\tERROR trial_runner.py:1062 -- Trial train_12206_00084: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=4526, ip=141.223.107.22, repr=train)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_16139/26714430.py\", line 94, in train\n",
      "  File \"/home/piai/Documents/POC-Project/src/train.py\", line 10, in training_loop\n",
      "    for batch_idx, (X, Y, _, items_index) in enumerate(dataloader):\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 435, in __iter__\n",
      "    return self._get_iterator()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 381, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1046, in __init__\n",
      "    torch.cuda.current_device(),\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 552, in current_device\n",
      "    _lazy_init()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 229, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW\n",
      "\u001b[2m\u001b[36m(train pid=4661)\u001b[0m /home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "\u001b[2m\u001b[36m(train pid=4661)\u001b[0m   return torch._C._cuda_getDeviceCount() > 0\n",
      "2023-04-09 23:23:40,205\tERROR trial_runner.py:1062 -- Trial train_12206_00083: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=4067, ip=141.223.107.22, repr=train)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_16139/26714430.py\", line 94, in train\n",
      "  File \"/home/piai/Documents/POC-Project/src/train.py\", line 10, in training_loop\n",
      "    for batch_idx, (X, Y, _, items_index) in enumerate(dataloader):\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 435, in __iter__\n",
      "    return self._get_iterator()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 381, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1046, in __init__\n",
      "    torch.cuda.current_device(),\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 552, in current_device\n",
      "    _lazy_init()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 229, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW\n",
      "\u001b[2m\u001b[36m(train pid=4814)\u001b[0m /home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "\u001b[2m\u001b[36m(train pid=4814)\u001b[0m   return torch._C._cuda_getDeviceCount() > 0\n",
      "2023-04-09 23:25:03,282\tERROR trial_runner.py:1062 -- Trial train_12206_00085: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=4661, ip=141.223.107.22, repr=train)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_16139/26714430.py\", line 94, in train\n",
      "  File \"/home/piai/Documents/POC-Project/src/train.py\", line 10, in training_loop\n",
      "    for batch_idx, (X, Y, _, items_index) in enumerate(dataloader):\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 435, in __iter__\n",
      "    return self._get_iterator()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 381, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1046, in __init__\n",
      "    torch.cuda.current_device(),\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 552, in current_device\n",
      "    _lazy_init()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 229, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=4934)\u001b[0m /home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "\u001b[2m\u001b[36m(train pid=4934)\u001b[0m   return torch._C._cuda_getDeviceCount() > 0\n",
      "2023-04-09 23:37:21,795\tERROR trial_runner.py:1062 -- Trial train_12206_00087: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=4934, ip=141.223.107.22, repr=train)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_16139/26714430.py\", line 94, in train\n",
      "  File \"/home/piai/Documents/POC-Project/src/train.py\", line 10, in training_loop\n",
      "    for batch_idx, (X, Y, _, items_index) in enumerate(dataloader):\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 435, in __iter__\n",
      "    return self._get_iterator()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 381, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1046, in __init__\n",
      "    torch.cuda.current_device(),\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 552, in current_device\n",
      "    _lazy_init()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 229, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW\n",
      "\u001b[2m\u001b[36m(train pid=5208)\u001b[0m /home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "\u001b[2m\u001b[36m(train pid=5208)\u001b[0m   return torch._C._cuda_getDeviceCount() > 0\n",
      "2023-04-09 23:39:18,233\tERROR trial_runner.py:1062 -- Trial train_12206_00086: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=4814, ip=141.223.107.22, repr=train)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_16139/26714430.py\", line 94, in train\n",
      "  File \"/home/piai/Documents/POC-Project/src/train.py\", line 10, in training_loop\n",
      "    for batch_idx, (X, Y, _, items_index) in enumerate(dataloader):\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 435, in __iter__\n",
      "    return self._get_iterator()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 381, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1046, in __init__\n",
      "    torch.cuda.current_device(),\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 552, in current_device\n",
      "    _lazy_init()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 229, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW\n",
      "\u001b[2m\u001b[36m(train pid=5340)\u001b[0m /home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "\u001b[2m\u001b[36m(train pid=5340)\u001b[0m   return torch._C._cuda_getDeviceCount() > 0\n",
      "2023-04-10 00:04:48,971\tERROR trial_runner.py:1062 -- Trial train_12206_00088: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=5208, ip=141.223.107.22, repr=train)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_16139/26714430.py\", line 94, in train\n",
      "  File \"/home/piai/Documents/POC-Project/src/train.py\", line 10, in training_loop\n",
      "    for batch_idx, (X, Y, _, items_index) in enumerate(dataloader):\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 435, in __iter__\n",
      "    return self._get_iterator()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 381, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1046, in __init__\n",
      "    torch.cuda.current_device(),\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 552, in current_device\n",
      "    _lazy_init()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 229, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=5796)\u001b[0m /home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "\u001b[2m\u001b[36m(train pid=5796)\u001b[0m   return torch._C._cuda_getDeviceCount() > 0\n",
      "2023-04-10 00:06:51,723\tERROR trial_runner.py:1062 -- Trial train_12206_00090: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=5796, ip=141.223.107.22, repr=train)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_16139/26714430.py\", line 94, in train\n",
      "  File \"/home/piai/Documents/POC-Project/src/train.py\", line 10, in training_loop\n",
      "    for batch_idx, (X, Y, _, items_index) in enumerate(dataloader):\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 435, in __iter__\n",
      "    return self._get_iterator()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 381, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1046, in __init__\n",
      "    torch.cuda.current_device(),\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 552, in current_device\n",
      "    _lazy_init()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 229, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW\n",
      "\u001b[2m\u001b[36m(train pid=6026)\u001b[0m /home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "\u001b[2m\u001b[36m(train pid=6026)\u001b[0m   return torch._C._cuda_getDeviceCount() > 0\n",
      "2023-04-10 00:10:12,436\tERROR trial_runner.py:1062 -- Trial train_12206_00089: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=5340, ip=141.223.107.22, repr=train)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_16139/26714430.py\", line 94, in train\n",
      "  File \"/home/piai/Documents/POC-Project/src/train.py\", line 10, in training_loop\n",
      "    for batch_idx, (X, Y, _, items_index) in enumerate(dataloader):\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 435, in __iter__\n",
      "    return self._get_iterator()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 381, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1046, in __init__\n",
      "    torch.cuda.current_device(),\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 552, in current_device\n",
      "    _lazy_init()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 229, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW\n",
      "\u001b[2m\u001b[36m(train pid=6177)\u001b[0m /home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "\u001b[2m\u001b[36m(train pid=6177)\u001b[0m   return torch._C._cuda_getDeviceCount() > 0\n",
      "2023-04-10 00:11:32,220\tERROR trial_runner.py:1062 -- Trial train_12206_00091: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=6026, ip=141.223.107.22, repr=train)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_16139/26714430.py\", line 94, in train\n",
      "  File \"/home/piai/Documents/POC-Project/src/train.py\", line 10, in training_loop\n",
      "    for batch_idx, (X, Y, _, items_index) in enumerate(dataloader):\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 435, in __iter__\n",
      "    return self._get_iterator()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 381, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1046, in __init__\n",
      "    torch.cuda.current_device(),\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 552, in current_device\n",
      "    _lazy_init()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 229, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=6292)\u001b[0m /home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "\u001b[2m\u001b[36m(train pid=6292)\u001b[0m   return torch._C._cuda_getDeviceCount() > 0\n",
      "2023-04-10 00:24:11,725\tERROR trial_runner.py:1062 -- Trial train_12206_00093: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=6292, ip=141.223.107.22, repr=train)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_16139/26714430.py\", line 94, in train\n",
      "  File \"/home/piai/Documents/POC-Project/src/train.py\", line 10, in training_loop\n",
      "    for batch_idx, (X, Y, _, items_index) in enumerate(dataloader):\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 435, in __iter__\n",
      "    return self._get_iterator()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 381, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1046, in __init__\n",
      "    torch.cuda.current_device(),\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 552, in current_device\n",
      "    _lazy_init()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 229, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW\n",
      "\u001b[2m\u001b[36m(train pid=6564)\u001b[0m /home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "\u001b[2m\u001b[36m(train pid=6564)\u001b[0m   return torch._C._cuda_getDeviceCount() > 0\n",
      "2023-04-10 00:25:53,729\tERROR trial_runner.py:1062 -- Trial train_12206_00092: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=6177, ip=141.223.107.22, repr=train)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_16139/26714430.py\", line 94, in train\n",
      "  File \"/home/piai/Documents/POC-Project/src/train.py\", line 10, in training_loop\n",
      "    for batch_idx, (X, Y, _, items_index) in enumerate(dataloader):\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 435, in __iter__\n",
      "    return self._get_iterator()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 381, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1046, in __init__\n",
      "    torch.cuda.current_device(),\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 552, in current_device\n",
      "    _lazy_init()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 229, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW\n",
      "\u001b[2m\u001b[36m(train pid=6692)\u001b[0m /home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "\u001b[2m\u001b[36m(train pid=6692)\u001b[0m   return torch._C._cuda_getDeviceCount() > 0\n",
      "2023-04-10 00:51:44,601\tERROR trial_runner.py:1062 -- Trial train_12206_00094: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=6564, ip=141.223.107.22, repr=train)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_16139/26714430.py\", line 94, in train\n",
      "  File \"/home/piai/Documents/POC-Project/src/train.py\", line 10, in training_loop\n",
      "    for batch_idx, (X, Y, _, items_index) in enumerate(dataloader):\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 435, in __iter__\n",
      "    return self._get_iterator()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 381, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1046, in __init__\n",
      "    torch.cuda.current_device(),\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 552, in current_device\n",
      "    _lazy_init()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 229, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=7144)\u001b[0m /home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "\u001b[2m\u001b[36m(train pid=7144)\u001b[0m   return torch._C._cuda_getDeviceCount() > 0\n",
      "2023-04-10 00:53:46,348\tERROR trial_runner.py:1062 -- Trial train_12206_00096: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=7144, ip=141.223.107.22, repr=train)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_16139/26714430.py\", line 94, in train\n",
      "  File \"/home/piai/Documents/POC-Project/src/train.py\", line 10, in training_loop\n",
      "    for batch_idx, (X, Y, _, items_index) in enumerate(dataloader):\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 435, in __iter__\n",
      "    return self._get_iterator()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 381, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1046, in __init__\n",
      "    torch.cuda.current_device(),\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 552, in current_device\n",
      "    _lazy_init()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 229, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW\n",
      "\u001b[2m\u001b[36m(train pid=7270)\u001b[0m /home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "\u001b[2m\u001b[36m(train pid=7270)\u001b[0m   return torch._C._cuda_getDeviceCount() > 0\n",
      "2023-04-10 00:56:39,225\tERROR trial_runner.py:1062 -- Trial train_12206_00095: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=6692, ip=141.223.107.22, repr=train)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_16139/26714430.py\", line 94, in train\n",
      "  File \"/home/piai/Documents/POC-Project/src/train.py\", line 10, in training_loop\n",
      "    for batch_idx, (X, Y, _, items_index) in enumerate(dataloader):\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 435, in __iter__\n",
      "    return self._get_iterator()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 381, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1046, in __init__\n",
      "    torch.cuda.current_device(),\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 552, in current_device\n",
      "    _lazy_init()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 229, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW\n",
      "\u001b[2m\u001b[36m(train pid=7406)\u001b[0m /home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "\u001b[2m\u001b[36m(train pid=7406)\u001b[0m   return torch._C._cuda_getDeviceCount() > 0\n",
      "2023-04-10 00:58:42,145\tERROR trial_runner.py:1062 -- Trial train_12206_00097: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=7270, ip=141.223.107.22, repr=train)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_16139/26714430.py\", line 94, in train\n",
      "  File \"/home/piai/Documents/POC-Project/src/train.py\", line 10, in training_loop\n",
      "    for batch_idx, (X, Y, _, items_index) in enumerate(dataloader):\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 435, in __iter__\n",
      "    return self._get_iterator()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 381, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1046, in __init__\n",
      "    torch.cuda.current_device(),\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 552, in current_device\n",
      "    _lazy_init()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 229, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train pid=7531)\u001b[0m /home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "\u001b[2m\u001b[36m(train pid=7531)\u001b[0m   return torch._C._cuda_getDeviceCount() > 0\n",
      "2023-04-10 01:11:04,328\tERROR trial_runner.py:1062 -- Trial train_12206_00099: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=7531, ip=141.223.107.22, repr=train)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_16139/26714430.py\", line 94, in train\n",
      "  File \"/home/piai/Documents/POC-Project/src/train.py\", line 10, in training_loop\n",
      "    for batch_idx, (X, Y, _, items_index) in enumerate(dataloader):\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 435, in __iter__\n",
      "    return self._get_iterator()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 381, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1046, in __init__\n",
      "    torch.cuda.current_device(),\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 552, in current_device\n",
      "    _lazy_init()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 229, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW\n",
      "\u001b[2m\u001b[36m(train pid=7806)\u001b[0m /home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "\u001b[2m\u001b[36m(train pid=7806)\u001b[0m   return torch._C._cuda_getDeviceCount() > 0\n",
      "2023-04-10 01:12:21,520\tERROR trial_runner.py:1062 -- Trial train_12206_00098: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=7406, ip=141.223.107.22, repr=train)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_16139/26714430.py\", line 94, in train\n",
      "  File \"/home/piai/Documents/POC-Project/src/train.py\", line 10, in training_loop\n",
      "    for batch_idx, (X, Y, _, items_index) in enumerate(dataloader):\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 435, in __iter__\n",
      "    return self._get_iterator()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 381, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1046, in __init__\n",
      "    torch.cuda.current_device(),\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 552, in current_device\n",
      "    _lazy_init()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 229, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW\n",
      "\u001b[2m\u001b[36m(train pid=7920)\u001b[0m /home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "\u001b[2m\u001b[36m(train pid=7920)\u001b[0m   return torch._C._cuda_getDeviceCount() > 0\n",
      "2023-04-10 01:38:08,620\tERROR trial_runner.py:1062 -- Trial train_12206_00100: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=7806, ip=141.223.107.22, repr=train)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_16139/26714430.py\", line 94, in train\n",
      "  File \"/home/piai/Documents/POC-Project/src/train.py\", line 10, in training_loop\n",
      "    for batch_idx, (X, Y, _, items_index) in enumerate(dataloader):\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 435, in __iter__\n",
      "    return self._get_iterator()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 381, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1046, in __init__\n",
      "    torch.cuda.current_device(),\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 552, in current_device\n",
      "    _lazy_init()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 229, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-10 01:42:58,767\tERROR trial_runner.py:1062 -- Trial train_12206_00101: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=7920, ip=141.223.107.22, repr=train)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 406, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/tmp/ipykernel_16139/26714430.py\", line 94, in train\n",
      "  File \"/home/piai/Documents/POC-Project/src/train.py\", line 10, in training_loop\n",
      "    for batch_idx, (X, Y, _, items_index) in enumerate(dataloader):\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 435, in __iter__\n",
      "    return self._get_iterator()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 381, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1046, in __init__\n",
      "    torch.cuda.current_device(),\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 552, in current_device\n",
      "    _lazy_init()\n",
      "  File \"/home/piai/anaconda3/envs/POC-env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 229, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW\n",
      "2023-04-10 01:42:58,861\tERROR tune.py:794 -- Trials did not complete: [train_12206_00057, train_12206_00058, train_12206_00059, train_12206_00060, train_12206_00061, train_12206_00062, train_12206_00063, train_12206_00064, train_12206_00065, train_12206_00066, train_12206_00067, train_12206_00068, train_12206_00069, train_12206_00070, train_12206_00071, train_12206_00072, train_12206_00073, train_12206_00074, train_12206_00075, train_12206_00076, train_12206_00077, train_12206_00078, train_12206_00079, train_12206_00080, train_12206_00081, train_12206_00082, train_12206_00083, train_12206_00084, train_12206_00085, train_12206_00086, train_12206_00087, train_12206_00088, train_12206_00089, train_12206_00090, train_12206_00091, train_12206_00092, train_12206_00093, train_12206_00094, train_12206_00095, train_12206_00096, train_12206_00097, train_12206_00098, train_12206_00099, train_12206_00100, train_12206_00101]\n",
      "2023-04-10 01:42:58,862\tINFO tune.py:798 -- Total run time: 220123.41 seconds (220123.34 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "results = tuner.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08aabe4",
   "metadata": {},
   "source": [
    "# Evaluating the best Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aaa2da49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-09T16:42:59.106865Z",
     "start_time": "2023-04-09T16:42:59.042129Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial config: {'Network': <class 'models.unet.UNet'>, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Learning Rate': 0.0001, 'Batch Size': 4, 'Loss Function': BorderedLoss(\n",
      "  (border_loss): CrossEntropyLoss()\n",
      "  (volume_loss): JaccardLoss\n",
      "), 'Negative Mining': True, 'Smooth Labeling': False, 'Input Pipeline': InputPipeline(\n",
      "  (layer_transformer): ModuleList(\n",
      "    (0): SobelFilter\n",
      "  )\n",
      ")}\n",
      "Best trial final validation loss: 0.08369708806276321\n",
      "Best trial final validation CrackIoU: 0.7667993903160095\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest trial final validation CrackIoU: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(best_result\u001b[38;5;241m.\u001b[39mmetrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCrackIoU\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[0;32m----> 7\u001b[0m     \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(test_data, result)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(test_data, result):\n\u001b[1;32m      3\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m     inpip \u001b[38;5;241m=\u001b[39m \u001b[43mconfig\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput Pipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m LOAD_DATA_ON_GPU:\n\u001b[1;32m      7\u001b[0m         inpip \u001b[38;5;241m=\u001b[39m inpip\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'config' is not defined"
     ]
    }
   ],
   "source": [
    "best_result = results.get_best_result(metric=\"CrackIoU\", mode=\"max\", scope=\"all\")  # Get best result object\n",
    "print(\"Best trial config: {}\".format(best_result.config))\n",
    "print(\"Best trial final validation loss: {}\".format(best_result.metrics[\"Loss\"]))\n",
    "print(\"Best trial final validation CrackIoU: {}\".format(best_result.metrics[\"CrackIoU\"]))\n",
    "\n",
    "for result in results:\n",
    "    evaluate(test_data=test_data, result=result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8633d3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d599c84a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "POC-env",
   "language": "python",
   "name": "poc-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122.844,
   "position": {
    "height": "40px",
    "left": "1576px",
    "right": "20px",
    "top": "120px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
